<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 7 Multiple linear regression | Workshop 4: Linear models</title>
  <meta name="description" content="Linear models" />
  <meta name="generator" content="bookdown 0.24 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 7 Multiple linear regression | Workshop 4: Linear models" />
  <meta property="og:type" content="book" />
  <meta property="og:url" content="https://github.com/qcbsRworkshops/" />
  <meta property="og:image" content="https://github.com/qcbsRworkshops//assets/images/logo/csbq_logo_accueil.png" />
  <meta property="og:description" content="Linear models" />
  <meta name="github-repo" content="qcbsRworkshops/workshop04" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 7 Multiple linear regression | Workshop 4: Linear models" />
  
  <meta name="twitter:description" content="Linear models" />
  <meta name="twitter:image" content="https://github.com/qcbsRworkshops//assets/images/logo/csbq_logo_accueil.png" />

<meta name="author" content="Developed and maintained by the contributors of the QCBS R Workshop Series" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  <link rel="shortcut icon" href="assets/images/favicon.ico" type="image/x-icon" />
<link rel="prev" href="analysis-of-covariance-ancova.html"/>
<link rel="next" href="summary.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<script src="libs/accessible-code-block-0.0.1/empty-anchor.js"></script>
<link href="libs/anchor-sections-1.0.1/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.0.1/anchor-sections.js"></script>


<style type="text/css">
code.sourceCode > span { display: inline-block; line-height: 1.25; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  background-color: #f8f8f8; }
@media screen {
code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ef2929; } /* Alert */
code span.an { color: #8f5902; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #c4a000; } /* Attribute */
code span.bn { color: #0000cf; } /* BaseN */
code span.cf { color: #204a87; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4e9a06; } /* Char */
code span.cn { color: #000000; } /* Constant */
code span.co { color: #8f5902; font-style: italic; } /* Comment */
code span.cv { color: #8f5902; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #8f5902; font-weight: bold; font-style: italic; } /* Documentation */
code span.dt { color: #204a87; } /* DataType */
code span.dv { color: #0000cf; } /* DecVal */
code span.er { color: #a40000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #0000cf; } /* Float */
code span.fu { color: #000000; } /* Function */
code span.im { } /* Import */
code span.in { color: #8f5902; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #204a87; font-weight: bold; } /* Keyword */
code span.op { color: #ce5c00; font-weight: bold; } /* Operator */
code span.ot { color: #8f5902; } /* Other */
code span.pp { color: #8f5902; font-style: italic; } /* Preprocessor */
code span.sc { color: #000000; } /* SpecialChar */
code span.ss { color: #4e9a06; } /* SpecialString */
code span.st { color: #4e9a06; } /* String */
code span.va { color: #000000; } /* Variable */
code span.vs { color: #4e9a06; } /* VerbatimString */
code span.wa { color: #8f5902; font-weight: bold; font-style: italic; } /* Warning */
</style>


<link rel="stylesheet" href="assets/qcbs-style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="toc-logo"><a href="./"><img src="assets/images/csbq_logo_gray_accueil.png"></a></li>
<link rel="icon" type="image/png" href="assets/images/favicon.ico"/>

<li class="divider"></li>
<li class="part"><span><b>QCBS R Workshop Series</b></span></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a><ul>
<li class="chapter" data-level="0.1" data-path="index.html"><a href="index.html#code-of-conduct"><i class="fa fa-check"></i><b>0.1</b> Code of conduct</a><ul>
<li class="chapter" data-level="0.1.1" data-path="index.html"><a href="index.html#expected-behaviour"><i class="fa fa-check"></i><b>0.1.1</b> Expected behaviour</a></li>
<li class="chapter" data-level="0.1.2" data-path="index.html"><a href="index.html#unacceptable-behaviour"><i class="fa fa-check"></i><b>0.1.2</b> Unacceptable behaviour</a></li>
</ul></li>
<li class="chapter" data-level="0.2" data-path="index.html"><a href="index.html#contributors"><i class="fa fa-check"></i><b>0.2</b> Contributors</a></li>
<li class="chapter" data-level="0.3" data-path="index.html"><a href="index.html#contributing"><i class="fa fa-check"></i><b>0.3</b> Contributing</a></li>
</ul></li>
<li class="part"><span><b>Linear models in <code>R</code></b></span></li>
<li class="chapter" data-level="1" data-path="learning-objectives.html"><a href="learning-objectives.html"><i class="fa fa-check"></i><b>1</b> Learning objectives</a></li>
<li class="chapter" data-level="2" data-path="preparing-for-the-workshop.html"><a href="preparing-for-the-workshop.html"><i class="fa fa-check"></i><b>2</b> Preparing for the workshop</a></li>
<li class="chapter" data-level="3" data-path="the-linear-model.html"><a href="the-linear-model.html"><i class="fa fa-check"></i><b>3</b> The linear model</a><ul>
<li class="chapter" data-level="3.1" data-path="the-linear-model.html"><a href="the-linear-model.html#what-is-a-linear-model"><i class="fa fa-check"></i><b>3.1</b> What is a linear model?</a><ul>
<li class="chapter" data-level="3.1.1" data-path="the-linear-model.html"><a href="the-linear-model.html#example-abundance-and-mass-of-bird-species"><i class="fa fa-check"></i><b>3.1.1</b> Example: Abundance and mass of bird species</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="the-linear-model.html"><a href="the-linear-model.html#formulation-of-a-linear-model"><i class="fa fa-check"></i><b>3.2</b> Formulation of a linear model</a></li>
<li class="chapter" data-level="3.3" data-path="the-linear-model.html"><a href="the-linear-model.html#evaluation-of-the-linear-model"><i class="fa fa-check"></i><b>3.3</b> Evaluation of the linear model</a></li>
<li class="chapter" data-level="3.4" data-path="the-linear-model.html"><a href="the-linear-model.html#assumptions-of-the-linear-model"><i class="fa fa-check"></i><b>3.4</b> Assumptions of the linear model</a><ul>
<li class="chapter" data-level="3.4.1" data-path="the-linear-model.html"><a href="the-linear-model.html#normal-distribution-of-the-residuals"><i class="fa fa-check"></i><b>3.4.1</b> Normal distribution of the residuals</a></li>
<li class="chapter" data-level="3.4.2" data-path="the-linear-model.html"><a href="the-linear-model.html#homoskedasticity"><i class="fa fa-check"></i><b>3.4.2</b> Homoskedasticity</a></li>
<li class="chapter" data-level="3.4.3" data-path="the-linear-model.html"><a href="the-linear-model.html#independence-of-the-residuals"><i class="fa fa-check"></i><b>3.4.3</b> Independence of the residuals</a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="the-linear-model.html"><a href="the-linear-model.html#notation-for-linear-models"><i class="fa fa-check"></i><b>3.5</b> Notation for linear models</a><ul>
<li class="chapter" data-level="3.5.1" data-path="the-linear-model.html"><a href="the-linear-model.html#mathematical-notation"><i class="fa fa-check"></i><b>3.5.1</b> Mathematical notation</a></li>
<li class="chapter" data-level="3.5.2" data-path="the-linear-model.html"><a href="the-linear-model.html#r-notation"><i class="fa fa-check"></i><b>3.5.2</b> R notation</a></li>
</ul></li>
<li class="chapter" data-level="3.6" data-path="the-linear-model.html"><a href="the-linear-model.html#fitting-a-linear-model"><i class="fa fa-check"></i><b>3.6</b> Fitting a linear model</a><ul>
<li class="chapter" data-level="3.6.1" data-path="the-linear-model.html"><a href="the-linear-model.html#model-estimation"><i class="fa fa-check"></i><b>3.6.1</b> Model estimation</a></li>
</ul></li>
<li class="chapter" data-level="3.7" data-path="the-linear-model.html"><a href="the-linear-model.html#learning-objectives-1"><i class="fa fa-check"></i><b>3.7</b> Learning objectives</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="linear-regression-in-r.html"><a href="linear-regression-in-r.html"><i class="fa fa-check"></i><b>4</b> Linear regression in R</a><ul>
<li class="chapter" data-level="4.1" data-path="linear-regression-in-r.html"><a href="linear-regression-in-r.html#model-formulation"><i class="fa fa-check"></i><b>4.1</b> Model formulation</a><ul>
<li class="chapter" data-level="4.1.1" data-path="linear-regression-in-r.html"><a href="linear-regression-in-r.html#model-equation"><i class="fa fa-check"></i><b>4.1.1</b> Model equation</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="linear-regression-in-r.html"><a href="linear-regression-in-r.html#linear-regression-in-r-1"><i class="fa fa-check"></i><b>4.2</b> Linear regression in R</a><ul>
<li class="chapter" data-level="4.2.1" data-path="linear-regression-in-r.html"><a href="linear-regression-in-r.html#step-1-formulate-and-run-a-linear-model"><i class="fa fa-check"></i><b>4.2.1</b> Step 1: Formulate and run a linear model</a></li>
<li class="chapter" data-level="4.2.2" data-path="linear-regression-in-r.html"><a href="linear-regression-in-r.html#step-2-verify-assumptions-using-diagnostic-plots-of-the-residuals"><i class="fa fa-check"></i><b>4.2.2</b> Step 2: Verify assumptions using diagnostic plots of the residuals</a></li>
<li class="chapter" data-level="4.2.3" data-path="linear-regression-in-r.html"><a href="linear-regression-in-r.html#step-2.-verify-assumptions-of-lm1"><i class="fa fa-check"></i><b>4.2.3</b> <strong>Step 2</strong>. Verify assumptions of <code>lm1</code></a></li>
<li class="chapter" data-level="4.2.4" data-path="linear-regression-in-r.html"><a href="linear-regression-in-r.html#assumptions-not-met---what-is-wrong"><i class="fa fa-check"></i><b>4.2.4</b> Assumptions not met - what is wrong?</a></li>
<li class="chapter" data-level="4.2.5" data-path="linear-regression-in-r.html"><a href="linear-regression-in-r.html#assumptions-not-met---how-to-proceed"><i class="fa fa-check"></i><b>4.2.5</b> Assumptions not met - how to proceed?</a></li>
<li class="chapter" data-level="4.2.6" data-path="linear-regression-in-r.html"><a href="linear-regression-in-r.html#step-3.-analyze-parameter-estimates"><i class="fa fa-check"></i><b>4.2.6</b> <strong>Step 3.</strong> Analyze parameter estimates</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="linear-regression-in-r.html"><a href="linear-regression-in-r.html#model-interpretation"><i class="fa fa-check"></i><b>4.3</b> Model interpretation</a><ul>
<li class="chapter" data-level="4.3.1" data-path="linear-regression-in-r.html"><a href="linear-regression-in-r.html#finding-a-better-model-terrestrial-birds"><i class="fa fa-check"></i><b>4.3.1</b> Finding a better model: terrestrial birds</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="linear-regression-in-r.html"><a href="linear-regression-in-r.html#challenge-2"><i class="fa fa-check"></i><b>4.4</b> Challenge 2</a><ul>
<li class="chapter" data-level="4.4.1" data-path="linear-regression-in-r.html"><a href="linear-regression-in-r.html#solutions"><i class="fa fa-check"></i><b>4.4.1</b> Solutions</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="linear-regression-in-r.html"><a href="linear-regression-in-r.html#linear-regression-in-r-2"><i class="fa fa-check"></i><b>4.5</b> Linear regression in R</a></li>
<li class="chapter" data-level="4.6" data-path="linear-regression-in-r.html"><a href="linear-regression-in-r.html#variable-names"><i class="fa fa-check"></i><b>4.6</b> Variable names</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="t-test-and-anova.html"><a href="t-test-and-anova.html"><i class="fa fa-check"></i><b>5</b> t-test and ANOVA</a><ul>
<li class="chapter" data-level="5.1" data-path="t-test-and-anova.html"><a href="t-test-and-anova.html#analysis-of-variance-anova"><i class="fa fa-check"></i><b>5.1</b> Analysis of Variance (ANOVA)</a><ul>
<li class="chapter" data-level="5.1.1" data-path="t-test-and-anova.html"><a href="t-test-and-anova.html#types-of-anova"><i class="fa fa-check"></i><b>5.1.1</b> Types of ANOVA</a></li>
<li class="chapter" data-level="5.1.2" data-path="t-test-and-anova.html"><a href="t-test-and-anova.html#t-test"><i class="fa fa-check"></i><b>5.1.2</b> T-test</a></li>
<li class="chapter" data-level="5.1.3" data-path="t-test-and-anova.html"><a href="t-test-and-anova.html#running-an-anova"><i class="fa fa-check"></i><b>5.1.3</b> Running an ANOVA</a></li>
<li class="chapter" data-level="5.1.4" data-path="t-test-and-anova.html"><a href="t-test-and-anova.html#verifying-assumptions"><i class="fa fa-check"></i><b>5.1.4</b> Verifying assumptions</a></li>
<li class="chapter" data-level="5.1.5" data-path="t-test-and-anova.html"><a href="t-test-and-anova.html#model-output"><i class="fa fa-check"></i><b>5.1.5</b> Model output</a></li>
<li class="chapter" data-level="5.1.6" data-path="t-test-and-anova.html"><a href="t-test-and-anova.html#complementary-test"><i class="fa fa-check"></i><b>5.1.6</b> Complementary test</a></li>
<li class="chapter" data-level="5.1.7" data-path="t-test-and-anova.html"><a href="t-test-and-anova.html#plotting"><i class="fa fa-check"></i><b>5.1.7</b> Plotting</a></li>
<li class="chapter" data-level="5.1.8" data-path="t-test-and-anova.html"><a href="t-test-and-anova.html#going-further-contrasts"><i class="fa fa-check"></i><b>5.1.8</b> Going further: Contrasts</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="t-test-and-anova.html"><a href="t-test-and-anova.html#two-way-anova"><i class="fa fa-check"></i><b>5.2</b> Two-way ANOVA</a><ul>
<li class="chapter" data-level="5.2.1" data-path="t-test-and-anova.html"><a href="t-test-and-anova.html#running-a-two-way-anova"><i class="fa fa-check"></i><b>5.2.1</b> 4.1 Running a two-way ANOVA</a></li>
<li class="chapter" data-level="5.2.2" data-path="t-test-and-anova.html"><a href="t-test-and-anova.html#interaction-plot"><i class="fa fa-check"></i><b>5.2.2</b> 4.2 Interaction plot</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="t-test-and-anova.html"><a href="t-test-and-anova.html#unbalanced-anova-advanced-section-optional"><i class="fa fa-check"></i><b>5.3</b> Unbalanced ANOVA (advanced section/ optional)</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="analysis-of-covariance-ancova.html"><a href="analysis-of-covariance-ancova.html"><i class="fa fa-check"></i><b>6</b> Analysis of covariance (ANCOVA)</a><ul>
<li class="chapter" data-level="6.0.1" data-path="analysis-of-covariance-ancova.html"><a href="analysis-of-covariance-ancova.html#assumptions-1"><i class="fa fa-check"></i><b>6.0.1</b> 6.1 Assumptions</a></li>
<li class="chapter" data-level="6.0.2" data-path="analysis-of-covariance-ancova.html"><a href="analysis-of-covariance-ancova.html#types-of-ancova"><i class="fa fa-check"></i><b>6.0.2</b> 6.2 Types of ANCOVA</a></li>
<li class="chapter" data-level="6.0.3" data-path="analysis-of-covariance-ancova.html"><a href="analysis-of-covariance-ancova.html#running-an-ancova"><i class="fa fa-check"></i><b>6.0.3</b> 6.3 Running an ANCOVA</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="multiple-linear-regression.html"><a href="multiple-linear-regression.html"><i class="fa fa-check"></i><b>7</b> Multiple linear regression</a><ul>
<li class="chapter" data-level="7.0.1" data-path="multiple-linear-regression.html"><a href="multiple-linear-regression.html#model-formulation-1"><i class="fa fa-check"></i><b>7.0.1</b> Model formulation</a></li>
<li class="chapter" data-level="7.1" data-path="multiple-linear-regression.html"><a href="multiple-linear-regression.html#assumptions-2"><i class="fa fa-check"></i><b>7.1</b> Assumptions</a><ul>
<li class="chapter" data-level="7.1.1" data-path="multiple-linear-regression.html"><a href="multiple-linear-regression.html#if-variables-are-collinear"><i class="fa fa-check"></i><b>7.1.1</b> If variables are collinear</a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="multiple-linear-regression.html"><a href="multiple-linear-regression.html#multiple-linear-regression-in-r"><i class="fa fa-check"></i><b>7.2</b> Multiple linear regression in R</a><ul>
<li class="chapter" data-level="7.2.1" data-path="multiple-linear-regression.html"><a href="multiple-linear-regression.html#the-data"><i class="fa fa-check"></i><b>7.2.1</b> The data</a></li>
<li class="chapter" data-level="7.2.2" data-path="multiple-linear-regression.html"><a href="multiple-linear-regression.html#verify-assumptions"><i class="fa fa-check"></i><b>7.2.2</b> Verify assumptions</a></li>
<li class="chapter" data-level="7.2.3" data-path="multiple-linear-regression.html"><a href="multiple-linear-regression.html#linear-regression"><i class="fa fa-check"></i><b>7.2.3</b> Linear regression</a></li>
<li class="chapter" data-level="7.2.4" data-path="multiple-linear-regression.html"><a href="multiple-linear-regression.html#find-the-best-fit-model"><i class="fa fa-check"></i><b>7.2.4</b> Find the best-fit model</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="multiple-linear-regression.html"><a href="multiple-linear-regression.html#polynomial-regression-additional-material"><i class="fa fa-check"></i><b>7.3</b> Polynomial regression (additional material)</a></li>
<li class="chapter" data-level="7.4" data-path="multiple-linear-regression.html"><a href="multiple-linear-regression.html#variation-partitioning-additional-material"><i class="fa fa-check"></i><b>7.4</b> Variation Partitioning (additional material)</a></li>
</ul></li>
<li class="part"><span><b>Final considerations</b></span></li>
<li class="chapter" data-level="8" data-path="summary.html"><a href="summary.html"><i class="fa fa-check"></i><b>8</b> Summary</a></li>
<li class="chapter" data-level="9" data-path="additional-resources.html"><a href="additional-resources.html"><i class="fa fa-check"></i><b>9</b> Additional resources</a></li>
<li class="chapter" data-level="10" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i><b>10</b> References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/qcbsRworkshops" target="blank">QCBS R Workshop Series</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Workshop 4: Linear models</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<!------------------------ Hero Image Container --------------------------> 

<head>
  <meta name="viewport" content="width=device-width,minimum-scale=1.0,maximum-scale=10.0,initial-scale=1.0">
  <script src="https://kit.fontawesome.com/6a26f47516.js"></script>
  <script src="assets/qcbs-hideOutput.js"></script>
  <link href="assets/qcbs-style.css" rel="stylesheet">
</head>


<!-- 
<div class="hero-image-container"> 
  <img class= "hero-image" src="assets/images/jean-philippe-delberghe-75xPHEQBmvA-unsplash_hero_image.jpg">
</div>
--!>
<div id="multiple-linear-regression" class="section level1">
<h1><span class="header-section-number">Chapter 7</span> Multiple linear regression</h1>
<p><img src="images/schema_multReg.png" /></p>
<p>A multiple regression tests the effects of several continuous explanatory variables on a continuous response variable. It differs from simple linear regression by having <em>more than one explanatory variable</em>.</p>
<div id="model-formulation-1" class="section level3">
<h3><span class="header-section-number">7.0.1</span> Model formulation</h3>
<p><strong>Variables</strong></p>
<p>The multiple linear regression is defined by the variables <span class="math inline">\(y\)</span> representing the response variable (<strong>continuous</strong>) and <span class="math inline">\(x\)</span> for the explanatory variables (<strong>continuous</strong> or <strong>categorical</strong>).</p>
<p><strong>The assumed relationship</strong></p>
<p>The relationship between the response variable and the predictors is defined in the same way as for simple regression. The difference is in the addition of <span class="math inline">\(\beta\)</span> parameters for the additional variables:</p>
<p><span class="math display">\[y_i = \beta_0 + \beta_1x_{1,i}+ \beta_2x_{2,i}+ \beta_3x_{3,i}+...+ \beta_kx_{k,i} + \epsilon_i\]</span></p>
<ul>
<li>The parameter <span class="math inline">\(\beta_0\)</span> is <strong>the intercept</strong> (or constant)</li>
<li>The parameter <span class="math inline">\(\beta_1\)</span> quantifies <strong>the effect</strong> of <span class="math inline">\(x\)</span> on <span class="math inline">\(y\)</span></li>
<li>The residual <span class="math inline">\(\epsilon_i\)</span> represents the <strong>unexplained</strong> variation</li>
<li>The <strong>predicted value</strong> of <span class="math inline">\(y_i\)</span> is defined as: <span class="math inline">\(\hat{y}_i = \beta_0 + \beta_1x_{1,i}+ \beta_2x_{2,i}+ \beta_3x_{3,i}+...+\beta_kx_{k,i}\)</span>.</li>
</ul>
<p>The unexplained variation or error remains normally distributed, centered on zero with a variance of <span class="math inline">\(\sigma^2\)</span> :</p>
<p><span class="math display">\[epsilon_i \sim \mathcal{N}(0,\,\sigma^2)\]</span></p>
</div>
<div id="assumptions-2" class="section level2">
<h2><span class="header-section-number">7.1</span> Assumptions</h2>
<hr />
<p>In the case of multiple linear regressions, two conditions are added to the usual conditions for linear models. First, there must be a <strong>linear relationship</strong> between <strong>each</strong> explanatory variable and the response variable. Second, the explanatory variables are independent of each other (there is no <strong>colinearity</strong>).</p>
<div id="if-variables-are-collinear" class="section level3">
<h3><span class="header-section-number">7.1.1</span> If variables are collinear</h3>
<p>In case of collinearity, there are some solutions:</p>
<ul>
<li>Keep only one of the variables collinear</li>
<li>Try a multidimensional analysis (see <a href="https://r.qcbs.ca/workshops/r-workshop-09/">Workshop 9</a>)</li>
<li>Try a pseudo-orthogonal analysis</li>
</ul>
</div>
</div>
<div id="multiple-linear-regression-in-r" class="section level2">
<h2><span class="header-section-number">7.2</span> Multiple linear regression in R</h2>
<hr />
<div id="the-data" class="section level3">
<h3><span class="header-section-number">7.2.1</span> The data</h3>
<p>Using the <code>Dickcissel</code> dataset we will compare the relative importance of climate (<code>clTma</code>), productivity (<code>NDVI</code>) and soil cover (<code>grass</code>) as predictors of dickcissel abundance (<code>abund</code>).</p>
<div class="sourceCode" id="cb160"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb160-1"><a href="multiple-linear-regression.html#cb160-1"></a>Dickcissel =<span class="st"> </span><span class="kw">read.csv</span>(<span class="st">&quot;data/dickcissel.csv&quot;</span>)</span>
<span id="cb160-2"><a href="multiple-linear-regression.html#cb160-2"></a><span class="kw">str</span>(Dickcissel)</span></code></pre></div>
<pre><code>## &#39;data.frame&#39;:    646 obs. of  15 variables:
##  $ abund    : num  5 0.2 0.4 0 0 0 0 0 0 0 ...
##  $ Present  : chr  &quot;Absent&quot; &quot;Absent&quot; &quot;Absent&quot; &quot;Present&quot; ...
##  $ clDD     : num  5543 5750 5395 5920 6152 ...
##  $ clFD     : num  83.5 67.5 79.5 66.7 57.6 59.2 59.5 51.5 47.4 46.3 ...
##  $ clTmi    : num  9 9.6 8.6 11.9 11.6 10.8 10.8 11.6 13.6 13.5 ...
##  $ clTma    : num  32.1 31.4 30.9 31.9 32.4 32.1 32.3 33 33.5 33.4 ...
##  $ clTmn    : num  15.2 15.7 14.8 16.2 16.8 ...
##  $ clP      : num  140 147 148 143 141 ...
##  $ NDVI     : int  -56 -44 -36 -49 -42 -49 -48 -50 -64 -58 ...
##  $ broadleaf: num  0.3866 0.9516 0.9905 0.0506 0.2296 ...
##  $ conif    : num  0.0128 0.0484 0 0.9146 0.7013 ...
##  $ grass    : num  0 0 0 0 0 0 0 0 0 0 ...
##  $ crop     : num  0.2716 0 0 0.0285 0.044 ...
##  $ urban    : num  0.2396 0 0 0 0.0157 ...
##  $ wetland  : num  0 0 0 0 0 0 0 0 0 0 ...</code></pre>
</div>
<div id="verify-assumptions" class="section level3">
<h3><span class="header-section-number">7.2.2</span> Verify assumptions</h3>
<p>First, we must verify the presence of <strong>colinearity</strong> between all the explanatory and interest variables:</p>
<div class="explanation">
<p>An observable pattern between two explanatory variables may indicate that they are <strong>colinear</strong>! You must avoid this, or their effects on the response variable will be confounded.</p>
</div>
</div>
<div id="linear-regression" class="section level3">
<h3><span class="header-section-number">7.2.3</span> Linear regression</h3>
<p>Now, let’s run the multiple regression of abundance (<code>abund</code>) against the variables <code>clTma + NDVI + grass</code> :</p>
<div class="sourceCode" id="cb162"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb162-1"><a href="multiple-linear-regression.html#cb162-1"></a><span class="co"># Multiple regression</span></span>
<span id="cb162-2"><a href="multiple-linear-regression.html#cb162-2"></a>lm.mult &lt;-<span class="st"> </span><span class="kw">lm</span>(abund <span class="op">~</span><span class="st"> </span>clTma <span class="op">+</span><span class="st"> </span>NDVI <span class="op">+</span><span class="st"> </span>grass, <span class="dt">data =</span> Dickcissel)</span>
<span id="cb162-3"><a href="multiple-linear-regression.html#cb162-3"></a><span class="kw">summary</span>(lm.mult)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = abund ~ clTma + NDVI + grass, data = Dickcissel)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -35.327 -11.029  -4.337   2.150 180.725 
## 
## Coefficients:
##              Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept) -83.60813   11.57745  -7.222 1.46e-12 ***
## clTma         3.27299    0.40677   8.046 4.14e-15 ***
## NDVI          0.13716    0.05486   2.500   0.0127 *  
## grass        10.41435    4.68962   2.221   0.0267 *  
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 22.58 on 642 degrees of freedom
## Multiple R-squared:  0.117,  Adjusted R-squared:  0.1128 
## F-statistic: 28.35 on 3 and 642 DF,  p-value: &lt; 2.2e-16</code></pre>
<p>Then, let us check the other assumptions, as for the simple linear regression:</p>
<div class="sourceCode" id="cb164"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb164-1"><a href="multiple-linear-regression.html#cb164-1"></a><span class="co"># Assumptions</span></span>
<span id="cb164-2"><a href="multiple-linear-regression.html#cb164-2"></a><span class="kw">par</span>(<span class="dt">mfrow =</span> <span class="kw">c</span>(<span class="dv">2</span>, <span class="dv">2</span>), <span class="dt">mar =</span> <span class="kw">c</span>(<span class="fl">3.9</span>, <span class="dv">4</span>, <span class="fl">1.2</span>, <span class="fl">1.1</span>), <span class="dt">oma =</span> <span class="kw">c</span>(<span class="dv">0</span>, <span class="dv">0</span>,</span>
<span id="cb164-3"><a href="multiple-linear-regression.html#cb164-3"></a>    <span class="dv">0</span>, <span class="dv">0</span>))</span>
<span id="cb164-4"><a href="multiple-linear-regression.html#cb164-4"></a><span class="kw">plot</span>(lm.mult)</span></code></pre></div>
<p><img src="book-en_files/figure-html/unnamed-chunk-101-1.png" width="768" /></p>
</div>
<div id="find-the-best-fit-model" class="section level3">
<h3><span class="header-section-number">7.2.4</span> Find the best-fit model</h3>
<p>There is a principle of primary importance in model selection. It is the <strong>principle of parsimony</strong>. That is, explain the most variation with the least number of terms. We could therefore remove the least significant variable.</p>
<div class="sourceCode" id="cb165"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb165-1"><a href="multiple-linear-regression.html#cb165-1"></a><span class="kw">summary</span>(lm.mult)<span class="op">$</span>coefficients</span></code></pre></div>
<pre><code>##                Estimate Std. Error   t value     Pr(&gt;|t|)
## (Intercept) -83.6081274 11.5774529 -7.221634 1.458749e-12
## clTma         3.2729872  0.4067706  8.046272 4.135118e-15
## NDVI          0.1371634  0.0548603  2.500231 1.265953e-02
## grass        10.4143451  4.6896157  2.220725 2.671787e-02</code></pre>
<p>All 3 variables are important. We keep everything!</p>
<p>The model explains 11.28% of the variability in dickcissel abundance <span class="math inline">\(R²_{adj} = 0.11\)</span>.</p>
<div class="noway">
<p>However, this information is not valid, because the conditions for applying the linear model are not met.</p>
</div>
<p>It is important to note that the response variable does not vary linearly with the explanatory variables:</p>
<div class="sourceCode" id="cb167"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb167-1"><a href="multiple-linear-regression.html#cb167-1"></a><span class="kw">par</span>(<span class="dt">mfrow =</span> <span class="kw">c</span>(<span class="dv">1</span>, <span class="dv">3</span>), <span class="dt">mar =</span> <span class="kw">c</span>(<span class="dv">4</span>, <span class="dv">4</span>, <span class="fl">0.5</span>, <span class="fl">0.5</span>), <span class="dt">cex =</span> <span class="dv">1</span>)</span>
<span id="cb167-2"><a href="multiple-linear-regression.html#cb167-2"></a><span class="kw">plot</span>(abund <span class="op">~</span><span class="st"> </span>clTma, <span class="dt">data =</span> Dickcissel)</span>
<span id="cb167-3"><a href="multiple-linear-regression.html#cb167-3"></a><span class="kw">plot</span>(abund <span class="op">~</span><span class="st"> </span>NDVI, <span class="dt">data =</span> Dickcissel)</span>
<span id="cb167-4"><a href="multiple-linear-regression.html#cb167-4"></a><span class="kw">plot</span>(abund <span class="op">~</span><span class="st"> </span>grass, <span class="dt">data =</span> Dickcissel)</span></code></pre></div>
<p><img src="book-en_files/figure-html/unnamed-chunk-103-1.png" width="1056" /></p>
</div>
</div>
<div id="polynomial-regression-additional-material" class="section level2">
<h2><span class="header-section-number">7.3</span> Polynomial regression (additional material)</h2>
<p>As we noticed in the section on <strong>multiple linear regression</strong>, <code>abund</code> was non-linearly related to some variables</p>
<p>To test for non-linear relationships, polynomial models of different degrees are compared.</p>
<p>A polynomial model looks like this:</p>
<p><span class="math display">\[\underbrace{2x^4}+\underbrace{3x}-\underbrace{2}\]</span></p>
<p>This polynomial has <strong>3 terms</strong>.<br />
</p>
<p>For a polynomial with one variable (<span class="math inline">\(x\)</span>), the <em>degree</em> is the largest exponent of that variable. This is a the <em>degree 4 polynomial</em>:</p>
<p><span class="math display">\[2x^\overbrace{4} + 3x - 2\]</span></p>
<p>When you know a degree, you can also give it a name:</p>
<table>
<thead>
<tr>
<th style="text-align:right;">
Degree
</th>
<th style="text-align:left;">
Name
</th>
<th style="text-align:left;">
Example
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:right;">
0
</td>
<td style="text-align:left;">
Constant
</td>
<td style="text-align:left;">
<span class="math inline">\(3\)</span>
</td>
</tr>
<tr>
<td style="text-align:right;">
1
</td>
<td style="text-align:left;">
Linear
</td>
<td style="text-align:left;">
<span class="math inline">\(x+9\)</span>
</td>
</tr>
<tr>
<td style="text-align:right;">
2
</td>
<td style="text-align:left;">
Quadratic
</td>
<td style="text-align:left;">
<span class="math inline">\(x^2-x+4\)</span>
</td>
</tr>
<tr>
<td style="text-align:right;">
3
</td>
<td style="text-align:left;">
Cubic
</td>
<td style="text-align:left;">
<span class="math inline">\(x^3-x^2+5\)</span>
</td>
</tr>
<tr>
<td style="text-align:right;">
4
</td>
<td style="text-align:left;">
Quartic
</td>
<td style="text-align:left;">
<span class="math inline">\(6x^4-x^3+x-2\)</span>
</td>
</tr>
<tr>
<td style="text-align:right;">
5
</td>
<td style="text-align:left;">
Quintic
</td>
<td style="text-align:left;">
<span class="math inline">\(x^5-3x^3+x^2+8\)</span>
</td>
</tr>
</tbody>
</table>
<p>Now we can fix our problem with the <code>Dickcissel</code> dataset by testing the non-linear relationship between max abundance and temperature by comparing three sets of nested polynomial models (of degrees 0, 1, and 3):</p>
<div class="sourceCode" id="cb168"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb168-1"><a href="multiple-linear-regression.html#cb168-1"></a>lm.linear &lt;-<span class="st"> </span><span class="kw">lm</span>(abund <span class="op">~</span><span class="st"> </span>clDD, <span class="dt">data =</span> Dickcissel)</span>
<span id="cb168-2"><a href="multiple-linear-regression.html#cb168-2"></a>lm.quad &lt;-<span class="st"> </span><span class="kw">lm</span>(abund <span class="op">~</span><span class="st"> </span>clDD <span class="op">+</span><span class="st"> </span><span class="kw">I</span>(clDD<span class="op">^</span><span class="dv">2</span>), <span class="dt">data =</span> Dickcissel)</span>
<span id="cb168-3"><a href="multiple-linear-regression.html#cb168-3"></a>lm.cubic &lt;-<span class="st"> </span><span class="kw">lm</span>(abund <span class="op">~</span><span class="st"> </span>clDD <span class="op">+</span><span class="st"> </span><span class="kw">I</span>(clDD<span class="op">^</span><span class="dv">2</span>) <span class="op">+</span><span class="st"> </span><span class="kw">I</span>(clDD<span class="op">^</span><span class="dv">3</span>), <span class="dt">data =</span> Dickcissel)</span></code></pre></div>
<p>By comparing the polynomial models and determine which nested model we should keep:</p>
<div class="sourceCode" id="cb169"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb169-1"><a href="multiple-linear-regression.html#cb169-1"></a><span class="kw">summary</span>(lm.linear)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = abund ~ clDD, data = Dickcissel)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -17.062 -10.608  -7.758  -2.487 193.128 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)   
## (Intercept) 1.864566   2.757554   0.676  0.49918   
## clDD        0.001870   0.000588   3.180  0.00154 **
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 23.81 on 644 degrees of freedom
## Multiple R-squared:  0.01546,    Adjusted R-squared:  0.01393 
## F-statistic: 10.11 on 1 and 644 DF,  p-value: 0.001545</code></pre>
<div class="sourceCode" id="cb171"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb171-1"><a href="multiple-linear-regression.html#cb171-1"></a><span class="kw">summary</span>(lm.quad)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = abund ~ clDD + I(clDD^2), data = Dickcissel)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -14.057 -12.253  -8.674   1.495 190.129 
## 
## Coefficients:
##               Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept) -1.968e+01  5.954e+00  -3.306    0.001 ** 
## clDD         1.297e-02  2.788e-03   4.651 4.00e-06 ***
## I(clDD^2)   -1.246e-06  3.061e-07  -4.070 5.28e-05 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 23.53 on 643 degrees of freedom
## Multiple R-squared:  0.04018,    Adjusted R-squared:  0.0372 
## F-statistic: 13.46 on 2 and 643 DF,  p-value: 1.876e-06</code></pre>
<div class="sourceCode" id="cb173"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb173-1"><a href="multiple-linear-regression.html#cb173-1"></a><span class="kw">summary</span>(lm.cubic)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = abund ~ clDD + I(clDD^2) + I(clDD^3), data = Dickcissel)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -14.417 -12.247  -8.394   1.473 189.955 
## 
## Coefficients:
##               Estimate Std. Error t value Pr(&gt;|t|)
## (Intercept) -1.465e+01  1.206e+01  -1.215    0.225
## clDD         8.612e-03  9.493e-03   0.907    0.365
## I(clDD^2)   -1.628e-07  2.277e-06  -0.071    0.943
## I(clDD^3)   -8.063e-11  1.680e-10  -0.480    0.631
## 
## Residual standard error: 23.54 on 642 degrees of freedom
## Multiple R-squared:  0.04053,    Adjusted R-squared:  0.03605 
## F-statistic:  9.04 on 3 and 642 DF,  p-value: 7.202e-06</code></pre>
<p><em>Which one should you keep?</em></p>
</div>
<div id="variation-partitioning-additional-material" class="section level2">
<h2><span class="header-section-number">7.4</span> Variation Partitioning (additional material)</h2>
<p>Some of the selected explanatory variables in the <strong>multiple linear regression</strong> section were highly correlated./</p>
<p>Collinearity between explanatory variables can be assessed using the variance inflation factor <code>vif()</code> function of package <code>car</code>.<br />
</p>
<p>Variable with <code>VIF &gt; 5</code> are considered collinearity.<br />
</p>
<div class="sourceCode" id="cb175"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb175-1"><a href="multiple-linear-regression.html#cb175-1"></a>mod &lt;-<span class="st"> </span><span class="kw">lm</span>(clDD <span class="op">~</span><span class="st"> </span>clFD <span class="op">+</span><span class="st"> </span>clTmi <span class="op">+</span><span class="st"> </span>clTma <span class="op">+</span><span class="st"> </span>clP <span class="op">+</span><span class="st"> </span>grass, <span class="dt">data =</span> Dickcissel)</span>
<span id="cb175-2"><a href="multiple-linear-regression.html#cb175-2"></a>car<span class="op">::</span><span class="kw">vif</span>(mod)</span></code></pre></div>
<pre><code>##      clFD     clTmi     clTma       clP     grass 
## 13.605855  9.566169  4.811837  3.196599  1.165775</code></pre>
<p>In this example, <code>clDD</code> is correlated with <code>clFD</code>,<code>clTmi</code> and <code>clTma</code>.<br />
</p>
<p>Instead of removing variable from the modal, we can reduce effect of colinearity by grouoping variables together. You can use <code>varpart()</code> to partition the variation in max abundance with all land cover variables (<code>"broadleaf"</code>,<code>"conif"</code>,<code>"grass"</code>,<code>"crop"</code>, <code>"urban"</code>,<code>"wetland"</code>) in one set and all climate variables in the other set (<code>"clDD"</code>,<code>"clFD"</code>,<code>"clTmi"</code>,<code>"clTma"</code>,<code>"clP"</code>). We can leave out NDVI for now.</p>
<div class="sourceCode" id="cb177"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb177-1"><a href="multiple-linear-regression.html#cb177-1"></a><span class="kw">library</span>(vegan)</span>
<span id="cb177-2"><a href="multiple-linear-regression.html#cb177-2"></a>part.lm =<span class="st"> </span><span class="kw">varpart</span>(Dickcissel<span class="op">$</span>abund, Dickcissel[, <span class="kw">c</span>(<span class="st">&quot;clDD&quot;</span>, <span class="st">&quot;clFD&quot;</span>,</span>
<span id="cb177-3"><a href="multiple-linear-regression.html#cb177-3"></a>    <span class="st">&quot;clTmi&quot;</span>, <span class="st">&quot;clTma&quot;</span>, <span class="st">&quot;clP&quot;</span>)], Dickcissel[, <span class="kw">c</span>(<span class="st">&quot;broadleaf&quot;</span>, <span class="st">&quot;conif&quot;</span>,</span>
<span id="cb177-4"><a href="multiple-linear-regression.html#cb177-4"></a>    <span class="st">&quot;grass&quot;</span>, <span class="st">&quot;crop&quot;</span>, <span class="st">&quot;urban&quot;</span>, <span class="st">&quot;wetland&quot;</span>)])</span>
<span id="cb177-5"><a href="multiple-linear-regression.html#cb177-5"></a>part.lm</span></code></pre></div>
<pre><code>## 
## Partition of variance in RDA 
## 
## Call: varpart(Y = Dickcissel$abund, X = Dickcissel[, c(&quot;clDD&quot;, &quot;clFD&quot;,
## &quot;clTmi&quot;, &quot;clTma&quot;, &quot;clP&quot;)], Dickcissel[, c(&quot;broadleaf&quot;, &quot;conif&quot;,
## &quot;grass&quot;, &quot;crop&quot;, &quot;urban&quot;, &quot;wetland&quot;)])
## 
## Explanatory tables:
## X1:  Dickcissel[, c(&quot;clDD&quot;, &quot;clFD&quot;, &quot;clTmi&quot;, &quot;clTma&quot;, &quot;clP&quot;)]
## X2:  Dickcissel[, c(&quot;broadleaf&quot;, &quot;conif&quot;, &quot;grass&quot;, &quot;crop&quot;, &quot;urban&quot;, &quot;wetland&quot;)] 
## 
## No. of explanatory tables: 2 
## Total variation (SS): 370770 
##             Variance: 574.84 
## No. of observations: 646 
## 
## Partition table:
##                      Df R.squared Adj.R.squared Testable
## [a+b] = X1            5   0.31414       0.30878     TRUE
## [b+c] = X2            6   0.03654       0.02749     TRUE
## [a+b+c] = X1+X2      11   0.32378       0.31205     TRUE
## Individual fractions                                    
## [a] = X1|X2           5                 0.28456     TRUE
## [b]                   0                 0.02423    FALSE
## [c] = X2|X1           6                 0.00327     TRUE
## [d] = Residuals                         0.68795    FALSE
## ---
## Use function &#39;rda&#39; to test significance of fractions of interest</code></pre>
<p><strong>Note</strong>: Collinear variables do not have to be removed prior to partitioning.<br />
</p>
<p>With <code>showvarpart()</code>, we can visualise hpow these two groups (land cover and climate) explain variation in <code>abund</code>.</p>
<p>For example:</p>
<div class="sourceCode" id="cb179"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb179-1"><a href="multiple-linear-regression.html#cb179-1"></a><span class="kw">par</span>(<span class="dt">mar =</span> <span class="kw">rep</span>(<span class="fl">0.5</span>, <span class="dv">4</span>))</span>
<span id="cb179-2"><a href="multiple-linear-regression.html#cb179-2"></a><span class="kw">showvarparts</span>(<span class="dv">2</span>)</span></code></pre></div>
<p><img src="book-en_files/figure-html/unnamed-chunk-109-1.png" width="672" /></p>
<div class="sourceCode" id="cb180"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb180-1"><a href="multiple-linear-regression.html#cb180-1"></a><span class="st">`</span><span class="dt">?</span><span class="st">`</span>(showvarparts)</span>
<span id="cb180-2"><a href="multiple-linear-regression.html#cb180-2"></a><span class="co"># With two explanatory tables, the fractions explained</span></span>
<span id="cb180-3"><a href="multiple-linear-regression.html#cb180-3"></a><span class="co"># uniquely by each of the two tables are ‘[a]’ and ‘[c]’,</span></span>
<span id="cb180-4"><a href="multiple-linear-regression.html#cb180-4"></a><span class="co"># and their joint effect is ‘[b]’ following Borcard et al.</span></span>
<span id="cb180-5"><a href="multiple-linear-regression.html#cb180-5"></a><span class="co"># (1992).</span></span></code></pre></div>
<p>Let’s try with our dataset <code>Dickcissel</code> and our model.</p>
<div class="sourceCode" id="cb181"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb181-1"><a href="multiple-linear-regression.html#cb181-1"></a><span class="kw">plot</span>(part.lm, <span class="dt">digits =</span> <span class="dv">2</span>, <span class="dt">bg =</span> <span class="kw">rgb</span>(<span class="dv">48</span>, <span class="dv">225</span>, <span class="dv">210</span>, <span class="dv">80</span>, <span class="dt">maxColorValue =</span> <span class="dv">225</span>),</span>
<span id="cb181-2"><a href="multiple-linear-regression.html#cb181-2"></a>    <span class="dt">col =</span> <span class="st">&quot;turquoise4&quot;</span>)</span></code></pre></div>
<p><img src="book-en_files/figure-html/unnamed-chunk-111-1.png" width="672" /></p>
<p>Proportion of variance explained by:<br />
- Climate alone is 28.5% (given by X1|X2).<br />
- Land cover alone is ~0% (X2|X1).<br />
- Both combined is 2.4%.<br />
</p>
<p>Unexplained variation by these groups (residuals) is 68.8%.</p>
<p>We can now test the significance of each fraction:</p>
<ul>
<li>Climate</li>
</ul>
<div class="sourceCode" id="cb182"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb182-1"><a href="multiple-linear-regression.html#cb182-1"></a>out<span class="fl">.1</span> =<span class="st"> </span><span class="kw">rda</span>(Dickcissel<span class="op">$</span>abund, Dickcissel[, <span class="kw">c</span>(<span class="st">&quot;clDD&quot;</span>, <span class="st">&quot;clFD&quot;</span>,</span>
<span id="cb182-2"><a href="multiple-linear-regression.html#cb182-2"></a>    <span class="st">&quot;clTmi&quot;</span>, <span class="st">&quot;clTma&quot;</span>, <span class="st">&quot;clP&quot;</span>)], Dickcissel[, <span class="kw">c</span>(<span class="st">&quot;broadleaf&quot;</span>, <span class="st">&quot;conif&quot;</span>,</span>
<span id="cb182-3"><a href="multiple-linear-regression.html#cb182-3"></a>    <span class="st">&quot;grass&quot;</span>, <span class="st">&quot;crop&quot;</span>, <span class="st">&quot;urban&quot;</span>, <span class="st">&quot;wetland&quot;</span>)])</span></code></pre></div>
<ul>
<li>Land cover</li>
</ul>
<div class="sourceCode" id="cb183"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb183-1"><a href="multiple-linear-regression.html#cb183-1"></a>out<span class="fl">.2</span> =<span class="st"> </span><span class="kw">rda</span>(Dickcissel<span class="op">$</span>abund, Dickcissel[, <span class="kw">c</span>(<span class="st">&quot;broadleaf&quot;</span>, <span class="st">&quot;conif&quot;</span>,</span>
<span id="cb183-2"><a href="multiple-linear-regression.html#cb183-2"></a>    <span class="st">&quot;grass&quot;</span>, <span class="st">&quot;crop&quot;</span>, <span class="st">&quot;urban&quot;</span>, <span class="st">&quot;wetland&quot;</span>)], Dickcissel[, <span class="kw">c</span>(<span class="st">&quot;clDD&quot;</span>,</span>
<span id="cb183-3"><a href="multiple-linear-regression.html#cb183-3"></a>    <span class="st">&quot;clFD&quot;</span>, <span class="st">&quot;clTmi&quot;</span>, <span class="st">&quot;clTma&quot;</span>, <span class="st">&quot;clP&quot;</span>)])</span></code></pre></div>
<div class="sourceCode" id="cb184"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb184-1"><a href="multiple-linear-regression.html#cb184-1"></a><span class="co"># Climate</span></span>
<span id="cb184-2"><a href="multiple-linear-regression.html#cb184-2"></a><span class="kw">anova</span>(out<span class="fl">.1</span>, <span class="dt">step =</span> <span class="dv">1000</span>, <span class="dt">perm.max =</span> <span class="dv">1000</span>)</span></code></pre></div>
<pre><code>## Permutation test for rda under reduced model
## Permutation: free
## Number of permutations: 999
## 
## Model: rda(X = Dickcissel$abund, Y = Dickcissel[, c(&quot;clDD&quot;, &quot;clFD&quot;, &quot;clTmi&quot;, &quot;clTma&quot;, &quot;clP&quot;)], Z = Dickcissel[, c(&quot;broadleaf&quot;, &quot;conif&quot;, &quot;grass&quot;, &quot;crop&quot;, &quot;urban&quot;, &quot;wetland&quot;)])
##           Df Variance      F Pr(&gt;F)    
## Model      5   165.12 53.862  0.001 ***
## Residual 634   388.72                  
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<div class="sourceCode" id="cb186"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb186-1"><a href="multiple-linear-regression.html#cb186-1"></a><span class="co"># Land cover</span></span>
<span id="cb186-2"><a href="multiple-linear-regression.html#cb186-2"></a><span class="kw">anova</span>(out<span class="fl">.2</span>, <span class="dt">step =</span> <span class="dv">1000</span>, <span class="dt">perm.max =</span> <span class="dv">1000</span>)</span></code></pre></div>
<pre><code>## Permutation test for rda under reduced model
## Permutation: free
## Number of permutations: 999
## 
## Model: rda(X = Dickcissel$abund, Y = Dickcissel[, c(&quot;broadleaf&quot;, &quot;conif&quot;, &quot;grass&quot;, &quot;crop&quot;, &quot;urban&quot;, &quot;wetland&quot;)], Z = Dickcissel[, c(&quot;clDD&quot;, &quot;clFD&quot;, &quot;clTmi&quot;, &quot;clTma&quot;, &quot;clP&quot;)])
##           Df Variance      F Pr(&gt;F)
## Model      6     5.54 1.5063  0.167
## Residual 634   388.72</code></pre>
<p>The land cover fraction is non-significant once climate data is accounted for, which is not surprising given the low variation explained by the land cover.</p>
<p>Thanks to variation partitioning, we were able to account for the collinearity of our variables and still test the effect of the climate and land cover in a simple and easy way!</p>

</div>
</div>



ANCOVA! But never forget to correctly specify your model and verify its
statistical assumptions before interpreting its results according to the
ecological background of your data.</p>
</div>
<hr>
<center> 
  <div class="footer">
      All the content of the workshop series is under a <a href="https://creativecommons.org/licenses/by-nc/2.0/">Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License</a>.
  </div>
</center>
            </section>

          </div>
        </div>
      </div>
<a href="analysis-of-covariance-ancova.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="summary.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": true,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": false
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "section"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
