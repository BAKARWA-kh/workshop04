<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 7 Multiple regression | Workshop 4: Linear models</title>
  <meta name="description" content="Linear models" />
  <meta name="generator" content="bookdown 0.22 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 7 Multiple regression | Workshop 4: Linear models" />
  <meta property="og:type" content="book" />
  <meta property="og:url" content="https://github.com/qcbsRworkshops/" />
  <meta property="og:image" content="https://github.com/qcbsRworkshops//assets/images/logo/csbq_logo_accueil.png" />
  <meta property="og:description" content="Linear models" />
  <meta name="github-repo" content="qcbsRworkshops/workshop04" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 7 Multiple regression | Workshop 4: Linear models" />
  
  <meta name="twitter:description" content="Linear models" />
  <meta name="twitter:image" content="https://github.com/qcbsRworkshops//assets/images/logo/csbq_logo_accueil.png" />

<meta name="author" content="Developed and maintained by the contributors of the QCBS R Workshop Series" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  <link rel="shortcut icon" href="assets/images/favicon.ico" type="image/x-icon" />
<link rel="prev" href="analysis-of-covariance-ancova.html"/>
<link rel="next" href="summary.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<script src="libs/accessible-code-block-0.0.1/empty-anchor.js"></script>
<link href="libs/anchor-sections-1.0.1/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.0.1/anchor-sections.js"></script>


<style type="text/css">
code.sourceCode > span { display: inline-block; line-height: 1.25; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  background-color: #f8f8f8; }
@media screen {
code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ef2929; } /* Alert */
code span.an { color: #8f5902; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #c4a000; } /* Attribute */
code span.bn { color: #0000cf; } /* BaseN */
code span.cf { color: #204a87; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4e9a06; } /* Char */
code span.cn { color: #000000; } /* Constant */
code span.co { color: #8f5902; font-style: italic; } /* Comment */
code span.cv { color: #8f5902; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #8f5902; font-weight: bold; font-style: italic; } /* Documentation */
code span.dt { color: #204a87; } /* DataType */
code span.dv { color: #0000cf; } /* DecVal */
code span.er { color: #a40000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #0000cf; } /* Float */
code span.fu { color: #000000; } /* Function */
code span.im { } /* Import */
code span.in { color: #8f5902; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #204a87; font-weight: bold; } /* Keyword */
code span.op { color: #ce5c00; font-weight: bold; } /* Operator */
code span.ot { color: #8f5902; } /* Other */
code span.pp { color: #8f5902; font-style: italic; } /* Preprocessor */
code span.sc { color: #000000; } /* SpecialChar */
code span.ss { color: #4e9a06; } /* SpecialString */
code span.st { color: #4e9a06; } /* String */
code span.va { color: #000000; } /* Variable */
code span.vs { color: #4e9a06; } /* VerbatimString */
code span.wa { color: #8f5902; font-weight: bold; font-style: italic; } /* Warning */
</style>


<link rel="stylesheet" href="assets/qcbs-style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="toc-logo"><a href="./"><img src="assets/images/csbq_logo_gray_accueil.png"></a></li>
<link rel="icon" type="image/png" href="assets/images/favicon.ico"/>

<li class="divider"></li>
<li class="part"><span><b>QCBS R Workshop Series</b></span></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a><ul>
<li class="chapter" data-level="0.1" data-path="index.html"><a href="index.html#code-of-conduct"><i class="fa fa-check"></i><b>0.1</b> Code of conduct</a><ul>
<li class="chapter" data-level="0.1.1" data-path="index.html"><a href="index.html#expected-behaviour"><i class="fa fa-check"></i><b>0.1.1</b> Expected behaviour</a></li>
<li class="chapter" data-level="0.1.2" data-path="index.html"><a href="index.html#unacceptable-behaviour"><i class="fa fa-check"></i><b>0.1.2</b> Unacceptable behaviour</a></li>
</ul></li>
<li class="chapter" data-level="0.2" data-path="index.html"><a href="index.html#contributors"><i class="fa fa-check"></i><b>0.2</b> Contributors</a></li>
<li class="chapter" data-level="0.3" data-path="index.html"><a href="index.html#contributing"><i class="fa fa-check"></i><b>0.3</b> Contributing</a></li>
</ul></li>
<li class="part"><span><b>Introduction to <code>R</code></b></span></li>
<li class="chapter" data-level="1" data-path="learning-objectives.html"><a href="learning-objectives.html"><i class="fa fa-check"></i><b>1</b> Learning objectives</a></li>
<li class="chapter" data-level="2" data-path="preparing-for-the-workshop.html"><a href="preparing-for-the-workshop.html"><i class="fa fa-check"></i><b>2</b> Preparing for the workshop</a></li>
<li class="chapter" data-level="3" data-path="linear-models.html"><a href="linear-models.html"><i class="fa fa-check"></i><b>3</b> Linear models</a><ul>
<li class="chapter" data-level="3.1" data-path="linear-models.html"><a href="linear-models.html#what-is-a-linear-model"><i class="fa fa-check"></i><b>3.1</b> What is a linear model?</a><ul>
<li class="chapter" data-level="3.1.1" data-path="linear-models.html"><a href="linear-models.html#defining-mean-and-variation"><i class="fa fa-check"></i><b>3.1.1</b> Defining mean and variation</a></li>
<li class="chapter" data-level="3.1.2" data-path="linear-models.html"><a href="linear-models.html#linear-models-1"><i class="fa fa-check"></i><b>3.1.2</b> Linear models</a></li>
<li class="chapter" data-level="3.1.3" data-path="linear-models.html"><a href="linear-models.html#linear-model-assumptions"><i class="fa fa-check"></i><b>3.1.3</b> Linear model assumptions</a></li>
<li class="chapter" data-level="3.1.4" data-path="linear-models.html"><a href="linear-models.html#test-statistics-and-p-values"><i class="fa fa-check"></i><b>3.1.4</b> Test statistics and p-values</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="linear-regression-in-r.html"><a href="linear-regression-in-r.html"><i class="fa fa-check"></i><b>4</b> Linear regression in R</a><ul>
<li class="chapter" data-level="4.1" data-path="linear-regression-in-r.html"><a href="linear-regression-in-r.html#simple-linear-regression"><i class="fa fa-check"></i><b>4.1</b> Simple linear regression</a></li>
<li class="chapter" data-level="4.2" data-path="linear-regression-in-r.html"><a href="linear-regression-in-r.html#work-flow"><i class="fa fa-check"></i><b>4.2</b> Work flow</a><ul>
<li class="chapter" data-level="4.2.1" data-path="linear-regression-in-r.html"><a href="linear-regression-in-r.html#running-a-linear-model"><i class="fa fa-check"></i><b>4.2.1</b> 2.1 Running a linear model</a></li>
<li class="chapter" data-level="4.2.2" data-path="linear-regression-in-r.html"><a href="linear-regression-in-r.html#verifying-assumptions"><i class="fa fa-check"></i><b>4.2.2</b> Verifying assumptions</a></li>
<li class="chapter" data-level="4.2.3" data-path="linear-regression-in-r.html"><a href="linear-regression-in-r.html#normalizing-data"><i class="fa fa-check"></i><b>4.2.3</b> Normalizing data</a></li>
<li class="chapter" data-level="4.2.4" data-path="linear-regression-in-r.html"><a href="linear-regression-in-r.html#data-transformation"><i class="fa fa-check"></i><b>4.2.4</b> Data transformation</a></li>
<li class="chapter" data-level="4.2.5" data-path="linear-regression-in-r.html"><a href="linear-regression-in-r.html#model-output"><i class="fa fa-check"></i><b>4.2.5</b> Model output</a></li>
<li class="chapter" data-level="4.2.6" data-path="linear-regression-in-r.html"><a href="linear-regression-in-r.html#subsetting"><i class="fa fa-check"></i><b>4.2.6</b> Subsetting</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="linear-regression-in-r.html"><a href="linear-regression-in-r.html#challenge-1"><i class="fa fa-check"></i><b>4.3</b> CHALLENGE 1</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="t-test-and-anova.html"><a href="t-test-and-anova.html"><i class="fa fa-check"></i><b>5</b> t-test and ANOVA</a><ul>
<li class="chapter" data-level="5.1" data-path="t-test-and-anova.html"><a href="t-test-and-anova.html#analysis-of-variance-anova"><i class="fa fa-check"></i><b>5.1</b> Analysis of Variance (ANOVA)</a><ul>
<li class="chapter" data-level="5.1.1" data-path="t-test-and-anova.html"><a href="t-test-and-anova.html#types-of-anova"><i class="fa fa-check"></i><b>5.1.1</b> 3.1 Types of ANOVA</a></li>
<li class="chapter" data-level="5.1.2" data-path="t-test-and-anova.html"><a href="t-test-and-anova.html#t-test"><i class="fa fa-check"></i><b>5.1.2</b> 3.2 T-test</a></li>
<li class="chapter" data-level="5.1.3" data-path="t-test-and-anova.html"><a href="t-test-and-anova.html#running-an-anova"><i class="fa fa-check"></i><b>5.1.3</b> 3.3 Running an ANOVA</a></li>
<li class="chapter" data-level="5.1.4" data-path="t-test-and-anova.html"><a href="t-test-and-anova.html#verifying-assumptions-1"><i class="fa fa-check"></i><b>5.1.4</b> 3.4 Verifying assumptions</a></li>
<li class="chapter" data-level="5.1.5" data-path="t-test-and-anova.html"><a href="t-test-and-anova.html#model-output-1"><i class="fa fa-check"></i><b>5.1.5</b> 3.5 Model output</a></li>
<li class="chapter" data-level="5.1.6" data-path="t-test-and-anova.html"><a href="t-test-and-anova.html#complementary-test"><i class="fa fa-check"></i><b>5.1.6</b> 3.6 Complementary test</a></li>
<li class="chapter" data-level="5.1.7" data-path="t-test-and-anova.html"><a href="t-test-and-anova.html#plotting"><i class="fa fa-check"></i><b>5.1.7</b> 3.7 Plotting</a></li>
<li class="chapter" data-level="5.1.8" data-path="t-test-and-anova.html"><a href="t-test-and-anova.html#going-further-contrasts"><i class="fa fa-check"></i><b>5.1.8</b> Going further: Contrasts</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="t-test-and-anova.html"><a href="t-test-and-anova.html#two-way-anova"><i class="fa fa-check"></i><b>5.2</b> 4. Two-way ANOVA</a><ul>
<li class="chapter" data-level="5.2.1" data-path="t-test-and-anova.html"><a href="t-test-and-anova.html#running-a-two-way-anova"><i class="fa fa-check"></i><b>5.2.1</b> 4.1 Running a two-way ANOVA</a></li>
<li class="chapter" data-level="5.2.2" data-path="t-test-and-anova.html"><a href="t-test-and-anova.html#interaction-plot"><i class="fa fa-check"></i><b>5.2.2</b> 4.2 Interaction plot</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="t-test-and-anova.html"><a href="t-test-and-anova.html#unbalanced-anova-advanced-section-optional"><i class="fa fa-check"></i><b>5.3</b> 5. Unbalanced ANOVA (advanced section/ optional)</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="analysis-of-covariance-ancova.html"><a href="analysis-of-covariance-ancova.html"><i class="fa fa-check"></i><b>6</b> Analysis of covariance (ANCOVA)</a><ul>
<li class="chapter" data-level="6.0.1" data-path="analysis-of-covariance-ancova.html"><a href="analysis-of-covariance-ancova.html#assumptions-1"><i class="fa fa-check"></i><b>6.0.1</b> 6.1 Assumptions</a></li>
<li class="chapter" data-level="6.0.2" data-path="analysis-of-covariance-ancova.html"><a href="analysis-of-covariance-ancova.html#types-of-ancova"><i class="fa fa-check"></i><b>6.0.2</b> 6.2 Types of ANCOVA</a></li>
<li class="chapter" data-level="6.0.3" data-path="analysis-of-covariance-ancova.html"><a href="analysis-of-covariance-ancova.html#running-an-ancova"><i class="fa fa-check"></i><b>6.0.3</b> 6.3 Running an ANCOVA</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="multiple-regression.html"><a href="multiple-regression.html"><i class="fa fa-check"></i><b>7</b> Multiple regression</a><ul>
<li class="chapter" data-level="7.0.1" data-path="multiple-regression.html"><a href="multiple-regression.html#assumptions-2"><i class="fa fa-check"></i><b>7.0.1</b> 7.1 Assumptions</a></li>
<li class="chapter" data-level="7.0.2" data-path="multiple-regression.html"><a href="multiple-regression.html#dickcissel-dataset"><i class="fa fa-check"></i><b>7.0.2</b> 7.2 Dickcissel dataset</a></li>
<li class="chapter" data-level="7.0.3" data-path="multiple-regression.html"><a href="multiple-regression.html#going-further-polynomial-regression"><i class="fa fa-check"></i><b>7.0.3</b> Going further: Polynomial regression</a></li>
<li class="chapter" data-level="7.0.4" data-path="multiple-regression.html"><a href="multiple-regression.html#stepwise-regression"><i class="fa fa-check"></i><b>7.0.4</b> 7.4 Stepwise regression</a></li>
<li class="chapter" data-level="7.1" data-path="multiple-regression.html"><a href="multiple-regression.html#going-further-variance-partitioning"><i class="fa fa-check"></i><b>7.1</b> Going further: Variance partitioning</a></li>
</ul></li>
<li class="part"><span><b>Final considerations</b></span></li>
<li class="chapter" data-level="8" data-path="summary.html"><a href="summary.html"><i class="fa fa-check"></i><b>8</b> Summary</a></li>
<li class="chapter" data-level="9" data-path="additional-resources.html"><a href="additional-resources.html"><i class="fa fa-check"></i><b>9</b> Additional resources</a></li>
<li class="chapter" data-level="10" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i><b>10</b> References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/qcbsRworkshops" target="blank">QCBS R Workshop Series</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Workshop 4: Linear models</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<!------------------------ Hero Image Container --------------------------> 

<head>
  <meta name="viewport" content="width=device-width,minimum-scale=1.0,maximum-scale=10.0,initial-scale=1.0">
  <script src="https://kit.fontawesome.com/6a26f47516.js"></script>
  <script src="assets/qcbs-hideOutput.js"></script>
  <link href="assets/qcbs-style.css" rel="stylesheet">
</head>



<div class="hero-image-container"> 
  <img class= "hero-image" src="assets/images/jean-philippe-delberghe-75xPHEQBmvA-unsplash_hero_image.jpg">
</div>
<div id="multiple-regression" class="section level1">
<h1><span class="header-section-number">Chapter 7</span> Multiple regression</h1>
<p>Multiple regression tests the effects of several continuous explanatory
variables on a response variable.</p>
<div id="assumptions-2" class="section level3">
<h3><span class="header-section-number">7.0.1</span> 7.1 Assumptions</h3>
<p>In addition to the usual assumptions of linear models, it is important
to test for orthogonality because it will affect model interpretation.
Variables are not orthogonal when explanatory variables are collinear.
If one explanatory variable is correlated to another, they are likely to
explain the same variability of the response variable, and the effect of
one variable will be masked by the other.</p>
<p>If you see any pattern between two explanatory variables, they are
collinear. Collinearity must be avoided as the effect of each
explanatory variable will be confounded! Possible solutions are:</p>
<ol style="list-style-type: decimal">
<li>Keep only <strong>one</strong> of the collinear variables,</li>
<li>Try multidimensional analysis <em><a href="http://qcbs.ca/wiki/r_workshop9">(see
workshop 9)</a></em>,</li>
<li>Try a pseudo-orthogonal analysis.</li>
</ol>
<p>Collinearity between explanatory variables can be assessed based on the
variance inflation factor using the <code>vif</code> function of package ‘HH’:</p>
<div class="sourceCode" id="cb56"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb56-1"><a href="multiple-regression.html#cb56-1"></a><span class="kw">vif</span>(clDD <span class="op">~</span><span class="st"> </span>clFD <span class="op">+</span><span class="st"> </span>clTmi <span class="op">+</span><span class="st"> </span>clTma <span class="op">+</span><span class="st"> </span>clP <span class="op">+</span><span class="st"> </span>grass, <span class="dt">data =</span> Dickcissel)</span></code></pre></div>
<p>which gives the following output:</p>
<pre><code>  clFD        clTmi       clTma           clP         grass
 13.605855    9.566169    4.811837    3.196599    1.165775</code></pre>
<p>As variance inflation factor higher than 5 represents collinear
variables, the R output shows that <em>clDD</em>, <em>clFD</em> and <em>clTmi</em> are highly
collinear. Only one of these explanatory variables can thus be retained
in the final regression model.</p>
</div>
<div id="dickcissel-dataset" class="section level3">
<h3><span class="header-section-number">7.0.2</span> 7.2 Dickcissel dataset</h3>
<p>The Dickcissel dataset explores environmental variables that drive the
abundance and presence/ absence of a grassland bird with peak abundances
in Kansas, USA. It contains 15 variables:</p>
<table style="width:98%;">
<colgroup>
<col width="28%" />
<col width="39%" />
<col width="30%" />
</colgroup>
<thead>
<tr class="header">
<th align="left">Variable Name</th>
<th align="left">Description</th>
<th align="left">Type</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">abund</td>
<td align="left">The number of individuals<br />
observed at each route</td>
<td align="left">Continuous/ numeric</td>
</tr>
<tr class="even">
<td align="left">Present</td>
<td align="left">Presence/ absence of the<br />
species</td>
<td align="left">Boolean ("Present"/ "Absent")</td>
</tr>
<tr class="odd">
<td align="left">broadleaf, conif, crop, grass,<br />
shrub, urban, wetland</td>
<td align="left">Land use variables within 20 km radius<br />
of the center route</td>
<td align="left">Continuous/ numeric</td>
</tr>
<tr class="even">
<td align="left">NDVI</td>
<td align="left">Vegetation index (a measure of productivity)</td>
<td align="left">Interger</td>
</tr>
<tr class="odd">
<td align="left">clDD, clFD, clTma, clTmi, clP</td>
<td align="left">Climate date (DD = degree days,<br />
FD = frost days, Tma = max temperature,<br />
Tmi = min temperature,<br />
P = precipitation)</td>
<td align="left">Continuous/ numeric</td>
</tr>
</tbody>
</table>
<p>In R, multiple regression are implemented using the <code>lm</code> function and
its results are viewed using the <code>summary</code> function. Using, for example,
the Dickcissel data, we can test the effects of <em>climate</em>,
<em>productivity</em> and <em>land cover</em> on the <em>abundance</em> of the Dickcissel
species abundance by applying the model:</p>
<hr />
<p>CHALLENGE 5</p>
<p>Is a transformation needed for the response variable <em>abund</em>?</p>
<p>++++ Challenge 5: Solution|</p>
<div class="sourceCode" id="cb58"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb58-1"><a href="multiple-regression.html#cb58-1"></a><span class="kw">hist</span>(Dickcissel<span class="op">$</span>abund, <span class="dt">main =</span> <span class="st">&quot;&quot;</span>, <span class="dt">xlab =</span> <span class="st">&quot;Dickcissel abundance&quot;</span>)</span>
<span id="cb58-2"><a href="multiple-regression.html#cb58-2"></a><span class="kw">shapiro.test</span>(Dickcissel<span class="op">$</span>abund)</span>
<span id="cb58-3"><a href="multiple-regression.html#cb58-3"></a><span class="kw">skewness</span>(Dickcissel<span class="op">$</span>abund)</span>
<span id="cb58-4"><a href="multiple-regression.html#cb58-4"></a><span class="kw">summary</span>(Dickcissel<span class="op">$</span>abund)</span></code></pre></div>
<p>There are numerous zeros in the <em>abund</em> distribution. We can try adding
a constant to the log10() transformation given the severe skewness:</p>
<div class="sourceCode" id="cb59"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb59-1"><a href="multiple-regression.html#cb59-1"></a><span class="kw">hist</span>(<span class="kw">log10</span>(Dickcissel<span class="op">$</span>abund <span class="op">+</span><span class="st"> </span><span class="fl">0.1</span>), <span class="dt">main =</span> <span class="st">&quot;&quot;</span>, <span class="dt">xlab =</span> <span class="kw">expression</span>(<span class="st">&quot;log&quot;</span>[<span class="dv">10</span>] <span class="op">*</span></span>
<span id="cb59-2"><a href="multiple-regression.html#cb59-2"></a><span class="st">    &quot;(Dickcissel Abundance + 0.1)&quot;</span>))</span>
<span id="cb59-3"><a href="multiple-regression.html#cb59-3"></a><span class="kw">shapiro.test</span>(<span class="kw">log10</span>(Dickcissel<span class="op">$</span>abund <span class="op">+</span><span class="st"> </span><span class="fl">0.1</span>))</span>
<span id="cb59-4"><a href="multiple-regression.html#cb59-4"></a><span class="kw">skewness</span>(<span class="kw">log10</span>(Dickcissel<span class="op">$</span>abund <span class="op">+</span><span class="st"> </span><span class="fl">0.1</span>))</span></code></pre></div>
<p>The resulting transformed distribution is still non-normal.</p>
<p>++++</p>
<hr />
<p>As you likely noticed in Challenge 5, the <em>abund</em> variable could not be
normalized, suggesting that we might need to relax the assumptions of a
normally distributed response variable and move on to <a href="http://qcbs.ca/wiki/r_workshop7">Generalized
Linear Models</a>, but that will wait
until later!</p>
<p>For now, let’s simply use the untransformed <em>abund</em> and compare the
relative importance of the three variables (<em>climate</em>, <em>productivity</em>,
and <em>land cover</em>) on <em>abund</em></p>
<div class="sourceCode" id="cb60"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb60-1"><a href="multiple-regression.html#cb60-1"></a>lm.mult &lt;-<span class="st"> </span><span class="kw">lm</span>(abund <span class="op">~</span><span class="st"> </span>clTma <span class="op">+</span><span class="st"> </span>NDVI <span class="op">+</span><span class="st"> </span>grass, <span class="dt">data =</span> Dickcissel)</span>
<span id="cb60-2"><a href="multiple-regression.html#cb60-2"></a><span class="kw">summary</span>(lm.mult)</span></code></pre></div>
<p>The R output enables one to visualize the significant explanatory
variables:</p>
<pre><code>lm(formula = abund ~ clTma + NDVI + grass, data = Dickcissel)
Residuals:
 Min          1Q          Median          3Q           Max
-35.327   -11.029     -4.337      2.150       180.725
Coefficients:
              Estimate    Std. Error  t value     Pr(&gt;|t|)
(Intercept)   -83.60813       11.57745    -7.222      1.46e-12 ***
clTma         3.27299     0.40677     8.046       4.14e-15 ***
NDVI          0.13716     0.05486     2.500       0.0127 *
grass         10.41435        4.68962     2.221       0.0267 *
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1
Residual standard error: 22.58 on 642 degrees of freedom
Multiple R-squared:  0.117,     Adjusted R-squared:  0.1128
F-statistic: 28.35 on 3 and 642 DF,  p-value: &lt; 2.2e-16</code></pre>
<p>In this case, the three explanatory variables significantly influence
the abundance of the Dickcissel species, the most significant one being
the climate (p-value=4.14e-15). Altogether these variables explain
11.28% of the Dickcissel abundance variability (Adjusted R-squared=
0.1128). The overall model is also significant and explains the
Dickcissel abundance variability better than a null model (p-value: &lt;
2.2e-16).</p>
<p>A plot of the response variable as a function of each explanatory
variable can be used to represent graphically the model results:</p>
<div class="sourceCode" id="cb62"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb62-1"><a href="multiple-regression.html#cb62-1"></a><span class="kw">plot</span>(abund <span class="op">~</span><span class="st"> </span>clTma, <span class="dt">data =</span> Dickcissel, <span class="dt">pch =</span> <span class="dv">19</span>, <span class="dt">col =</span> <span class="st">&quot;orange&quot;</span>)</span>
<span id="cb62-2"><a href="multiple-regression.html#cb62-2"></a><span class="kw">plot</span>(abund <span class="op">~</span><span class="st"> </span>NDVI, <span class="dt">data =</span> Dickcissel, <span class="dt">pch =</span> <span class="dv">19</span>, <span class="dt">col =</span> <span class="st">&quot;skyblue&quot;</span>)</span>
<span id="cb62-3"><a href="multiple-regression.html#cb62-3"></a><span class="kw">plot</span>(abund <span class="op">~</span><span class="st"> </span>grass, <span class="dt">data =</span> Dickcissel, <span class="dt">pch =</span> <span class="dv">19</span>, <span class="dt">col =</span> <span class="st">&quot;green&quot;</span>)</span></code></pre></div>
<p><img src="images/lm_fig%2013.png" width="850" /></p>
</div>
<div id="going-further-polynomial-regression" class="section level3">
<h3><span class="header-section-number">7.0.3</span> Going further: Polynomial regression</h3>
<p>Response variables are not always linearly related to
explanatory variables. In this case, linear regression that fits a
straight line through the two variables is unable to correctly represent
the data. Instead, polynomial regression that fits a polynomial curves
between the response variable and the explanatory variables can be used
to represent non-linear relationship based on the mathematical model:</p>
<p><span class="math inline">\({y_i} = {β_0} + {β_1}{x_i} + {β_2}![](images/x_i}^2} + {β_3}{{x_i}^3} + {ε_i}&gt; for a polynomial of Degree 3\\ &lt;m&gt; {y_i} = {β_0} + {β_1}{x_i} + {β_2}{{x_i}^2} + {ε_i}\)</span>&gt; for a polynomial of Degree 2</p>
<p>where</p>
<p>β<sub>0</sub> is the intercept of the regression line,\
β<sub>1</sub> is effect of the variable x,\
β<sub>2</sub> is effect of the variable x<sub>2</sub>,\
β<sub>3</sub> is effect of the variable x<sub>3</sub>,\
ε<sub>i</sub> are the residuals of the model (i.e. the unexplained variation).</p>
<p>The Degree is the largest exponent of that variable. When you know a Degree, you can also give the polynomial a name/</p>
<p>{{/polynomial_degree.png){width=“250”}</p>
<p>In R, these models are implemented with the <code>lm</code> function and can be
compared to a linear regression with the <code>anova</code> function:</p>
<div class="sourceCode" id="cb63"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb63-1"><a href="multiple-regression.html#cb63-1"></a>lm.linear &lt;-<span class="st"> </span><span class="kw">lm</span>(abund <span class="op">~</span><span class="st"> </span>clDD, <span class="dt">data =</span> Dickcissel)</span>
<span id="cb63-2"><a href="multiple-regression.html#cb63-2"></a>lm.quad &lt;-<span class="st"> </span><span class="kw">lm</span>(abund <span class="op">~</span><span class="st"> </span>clDD <span class="op">+</span><span class="st"> </span><span class="kw">I</span>(clDD<span class="op">^</span><span class="dv">2</span>), <span class="dt">data =</span> Dickcissel)</span>
<span id="cb63-3"><a href="multiple-regression.html#cb63-3"></a>lm.cubic &lt;-<span class="st"> </span><span class="kw">lm</span>(abund <span class="op">~</span><span class="st"> </span>clDD <span class="op">+</span><span class="st"> </span><span class="kw">I</span>(clDD<span class="op">^</span><span class="dv">2</span>) <span class="op">+</span><span class="st"> </span><span class="kw">I</span>(clDD<span class="op">^</span><span class="dv">3</span>), <span class="dt">data =</span> Dickcissel)</span></code></pre></div>
<hr />
<p><strong>CHALLENGE 7</strong></p>
<p>Compare the different polynomial models in the previous example, and
determine which model is the most appropriate. Extract the adjusted R
squared, the regression coefficients, and the p-values of this chosen
model.</p>
<p>++++ Challenge 7: Solution|</p>
<div class="sourceCode" id="cb64"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb64-1"><a href="multiple-regression.html#cb64-1"></a><span class="kw">anova</span>(lm.linear, lm.quad, lm.cubic)  <span class="co"># list models in increasing complexity</span></span>
<span id="cb64-2"><a href="multiple-regression.html#cb64-2"></a><span class="co"># We should take the lowest line that has a significant</span></span>
<span id="cb64-3"><a href="multiple-regression.html#cb64-3"></a><span class="co"># p-value</span></span>
<span id="cb64-4"><a href="multiple-regression.html#cb64-4"></a></span>
<span id="cb64-5"><a href="multiple-regression.html#cb64-5"></a><span class="co"># Examine the summary</span></span>
<span id="cb64-6"><a href="multiple-regression.html#cb64-6"></a><span class="kw">summary</span>(lm.quad)</span>
<span id="cb64-7"><a href="multiple-regression.html#cb64-7"></a><span class="co"># Regression coefficients</span></span>
<span id="cb64-8"><a href="multiple-regression.html#cb64-8"></a><span class="kw">summary</span>(lm.quad)<span class="op">$</span>coefficients[, <span class="dv">1</span>]</span>
<span id="cb64-9"><a href="multiple-regression.html#cb64-9"></a><span class="co"># Estimate p-values</span></span>
<span id="cb64-10"><a href="multiple-regression.html#cb64-10"></a><span class="kw">summary</span>(lm.quad)<span class="op">$</span>coefficients[, <span class="dv">4</span>]</span>
<span id="cb64-11"><a href="multiple-regression.html#cb64-11"></a><span class="co"># R2-adj</span></span>
<span id="cb64-12"><a href="multiple-regression.html#cb64-12"></a><span class="kw">summary</span>(lm.quad)<span class="op">$</span>adj.r.squared</span></code></pre></div>
<p>++++</p>
<hr />
<p>The model comparison shows that the quadratic regression (i.e. the
polynomial of degree 2) is the best model. The cubic term can thus be
dropped from the final model:</p>
<pre><code>Analysis of Variance Table
Model 1: abund ~ clDD
Model 2: abund ~ clDD + I(clDD^2)
Model 3: abund ~ clDD + I(clDD^2) + I(clDD^3)
Model     Res.Df      RSS             Df  Sum of Sq        F          Pr(&gt;F)
1         644     365039
2         643     355871      1       9168.3      16.5457         5.34e-05 ***
3         642     355743      1       127.7       0.2304      0.6314</code></pre>
<p>The R output for the final model is:</p>
<pre><code>Call: lm(formula = abund ~ clDD + I(clDD^2), data = Dickcissel)
Residuals:
    Min           1Q          Median          3Q          Max
   -14.057        -12.253     -8.674      1.495       190.129
Coefficients:
              Estimate    Std. Error  t value     Pr(&gt;|t|)
(Intercept)   -1.968e+01      5.954e+00   -3.306      0.001 **
clDD          1.297e-02   2.788e-03       4.651       4.00e-06 ***
I(clDD^2)     -1.246e-06      3.061e-07   -4.070      5.28e-05 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1
Residual standard error: 23.53 on 643 degrees of freedom
Multiple R-squared:  0.04018,   Adjusted R-squared:  0.0372
F-statistic: 13.46 on 2 and 643 DF,  p-value: 1.876e-06</code></pre>
<p>In this example, the linear term influenced the response variable more
than the quadratic term, as their p-values are respectively 4.00e-06 and
5.28e-05. They explained together 3.72% of the abundance variability
(Adjusted R-squared).</p>
</div>
<div id="stepwise-regression" class="section level3">
<h3><span class="header-section-number">7.0.4</span> 7.4 Stepwise regression</h3>
<p>To obtain a final multiple regression model, users can first
implement a full regression model containing all the explanatory
variables and then drop the non-significant variable using a stepwise
selection procedure. In this method, non-significant variables are
successively dropped one by one from the model and the goodness-of-fit
of each successive model are compared based on AIC <a href="http://en.wikipedia.org/wiki/Akaike_information_criterion">(Akaike’s
Information
Criterion)</a>,
until all the explanatory variables of the model are significant. Note
that a lower AIC value indicates a better goodness of fit (i.e., the
best model is the one with the lowest AIC). In R, stepwise selection is
implemented using the function <code>step</code>:</p>
<div class="sourceCode" id="cb67"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb67-1"><a href="multiple-regression.html#cb67-1"></a>lm.full &lt;-<span class="st"> </span><span class="kw">lm</span>(abund <span class="op">~</span><span class="st"> </span>. <span class="op">-</span><span class="st"> </span>Present, <span class="dt">data =</span> Dickcissel)</span>
<span id="cb67-2"><a href="multiple-regression.html#cb67-2"></a>lm.step &lt;-<span class="st"> </span><span class="kw">step</span>(lm.full)</span>
<span id="cb67-3"><a href="multiple-regression.html#cb67-3"></a><span class="kw">summary</span>(lm.step)</span></code></pre></div>
<p>According to the stepwise selection, only 6 significant explanatory
variables among the 13 tested are retained in the final model:</p>
<pre><code> Call:    lm(formula = abund ~ clDD + clFD + clTmi + clTma + clP + grass,  data = Dickcissel)
 Residuals:
  Min         1Q          Median          3Q          Max
  -30.913     -9.640      -3.070      4.217       172.133
Coefficients:
              Estimate    Std. Error  t value     Pr(&gt;|t|)
(Intercept)   -4.457e+02      3.464e+01   -12.868     &lt; 2e-16 ***
clDD          5.534e-02   8.795e-03       6.292       5.83e-10 ***
clFD          1.090e+00   1.690e-01       6.452       2.19e-10 ***
clTmi         -6.717e+00      7.192e-01   -9.339      &lt; 2e-16 ***
clTma         3.172e+00   1.288e+00       2.463       0.014030 *
clP           1.562e-01   4.707e-02       3.318       0.000959 ***
grass         1.066e+01   4.280e+00       2.490       0.013027 *
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1
Residual standard error: 19.85 on 639 degrees of freedom
Multiple R-squared:  0.3207,    Adjusted R-squared:  0.3144
F-statistic: 50.29 on 6 and 639 DF,  p-value: &lt; 2.2e-16</code></pre>
<p>The model now accounts for 31.44% of the Dickcissel abundance
variability, the clTmi being the most significant explanatory variable.<br />
Nevertheless, some of the selected explanatory variables are highly
correlated and should be dropped from the final model in order to remove
uninformative variables.</p>
</div>
<div id="going-further-variance-partitioning" class="section level2">
<h2><span class="header-section-number">7.1</span> Going further: Variance partitioning</h2>
<p>To assess the relative contribution of two (or more)
explanatory datasets to a response variable, the <code>varpart</code> function of
vegan package can be used. This function partitions the explained
variance of a response variable to compare the contribution of various
sets of explanatory variables. For example, the contribution of land
cover variables on the first hand, and of climate variables on the other
hand on Dickcissel abundance can be implemented using:</p>
<div class="sourceCode" id="cb69"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb69-1"><a href="multiple-regression.html#cb69-1"></a>part.lm =<span class="st"> </span><span class="kw">varpart</span>(Dickcissel<span class="op">$</span>abund, Dickcissel[, <span class="kw">c</span>(<span class="st">&quot;clDD&quot;</span>, <span class="st">&quot;clFD&quot;</span>,</span>
<span id="cb69-2"><a href="multiple-regression.html#cb69-2"></a>    <span class="st">&quot;clTmi&quot;</span>, <span class="st">&quot;clTma&quot;</span>, <span class="st">&quot;clP&quot;</span>)], Dickcissel[, <span class="kw">c</span>(<span class="st">&quot;broadleaf&quot;</span>, <span class="st">&quot;conif&quot;</span>,</span>
<span id="cb69-3"><a href="multiple-regression.html#cb69-3"></a>    <span class="st">&quot;grass&quot;</span>, <span class="st">&quot;crop&quot;</span>, <span class="st">&quot;urban&quot;</span>, <span class="st">&quot;wetland&quot;</span>)])</span>
<span id="cb69-4"><a href="multiple-regression.html#cb69-4"></a>part.lm</span></code></pre></div>
<p>The R output of this function enables one to visualize the variance
partitioning results:</p>
<pre><code>Partition of variation in RDA
Call: varpart(Y = Dickcissel$abund, X = Dickcissel[, c(&quot;clDD&quot;, &quot;clFD&quot;, &quot;clTmi&quot;, &quot;clTma&quot;, &quot;clP&quot;)],
Dickcissel[, c(&quot;broadleaf&quot;, &quot;conif&quot;, &quot;grass&quot;, &quot;crop&quot;, &quot;urban&quot;, &quot;wetland&quot;)])
Explanatory tables:
X1:  Dickcissel[, c(&quot;clDD&quot;, &quot;clFD&quot;, &quot;clTmi&quot;, &quot;clTma&quot;, &quot;clP&quot;)]
X2:  Dickcissel[, c(&quot;broadleaf&quot;, &quot;conif&quot;, &quot;grass&quot;, &quot;crop&quot;, &quot;urban&quot;, &quot;wetland&quot;)]
No. of explanatory tables: 2
Total variation (SS): 370770
Variance: 574.84
No. of observations: 646
Partition table:
                     Df       R.squared       Adj.R.squared        Testable
[a+b] = X1           5        0.31414         0.30878              TRUE
[b+c] = X2           6        0.03654         0.02749              TRUE
[a+b+c] = X1+X2      11       0.32378         0.31205              TRUE
Individual fractions
[a] = X1|X2          5                        0.28456              TRUE
[b]                  0                        0.02423              FALSE
[c] = X2|X1          6                        0.00327              TRUE
[d] = Residuals                               0.68795              FALSE
---</code></pre>
<p>Use function <code>rda</code> to test significance of fractions of interest</p>
<p>This R output shows that the two explanatory datasets explain 31.205%
(<span class="math display">\[a+b+c\]</span> = X1+X2) of the Dickcissel abundance variability, while the
climate dataset contributes to 28.46% of the Dickcissel abundance
variability (<span class="math display">\[a\]</span> = X1|X2) and the land cover dataset only contributes
to 0.33% of the Dickcissel abundance variability (<span class="math display">\[c\]</span> = X2|X1). The
interaction of these two datasets also explained 2.42% (<span class="math display">\[b\]</span>) of the
variability. The significance of each fraction can be tested using
partial RDA and permutational ANOVA using the functions <code>rda</code> and
<code>anova</code>:</p>
<div class="sourceCode" id="cb71"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb71-1"><a href="multiple-regression.html#cb71-1"></a><span class="co"># Climate set</span></span>
<span id="cb71-2"><a href="multiple-regression.html#cb71-2"></a>out<span class="fl">.1</span> =<span class="st"> </span><span class="kw">rda</span>(Dickcissel<span class="op">$</span>abund, Dickcissel[, <span class="kw">c</span>(<span class="st">&quot;clDD&quot;</span>, <span class="st">&quot;clFD&quot;</span>,</span>
<span id="cb71-3"><a href="multiple-regression.html#cb71-3"></a>    <span class="st">&quot;clTmi&quot;</span>, <span class="st">&quot;clTma&quot;</span>, <span class="st">&quot;clP&quot;</span>)], Dickcissel[, <span class="kw">c</span>(<span class="st">&quot;broadleaf&quot;</span>, <span class="st">&quot;conif&quot;</span>,</span>
<span id="cb71-4"><a href="multiple-regression.html#cb71-4"></a>    <span class="st">&quot;grass&quot;</span>, <span class="st">&quot;crop&quot;</span>, <span class="st">&quot;urban&quot;</span>, <span class="st">&quot;wetland&quot;</span>)])</span>
<span id="cb71-5"><a href="multiple-regression.html#cb71-5"></a><span class="kw">anova</span>(out<span class="fl">.1</span>, <span class="dt">step =</span> <span class="dv">1000</span>, <span class="dt">perm.max =</span> <span class="dv">1000</span>)</span>
<span id="cb71-6"><a href="multiple-regression.html#cb71-6"></a></span>
<span id="cb71-7"><a href="multiple-regression.html#cb71-7"></a><span class="co"># Land cover set</span></span>
<span id="cb71-8"><a href="multiple-regression.html#cb71-8"></a>out<span class="fl">.2</span> =<span class="st"> </span><span class="kw">rda</span>(Dickcissel<span class="op">$</span>abund, Dickcissel[, <span class="kw">c</span>(<span class="st">&quot;broadleaf&quot;</span>, <span class="st">&quot;conif&quot;</span>,</span>
<span id="cb71-9"><a href="multiple-regression.html#cb71-9"></a>    <span class="st">&quot;grass&quot;</span>, <span class="st">&quot;crop&quot;</span>, <span class="st">&quot;urban&quot;</span>, <span class="st">&quot;wetland&quot;</span>)], Dickcissel[, <span class="kw">c</span>(<span class="st">&quot;clDD&quot;</span>,</span>
<span id="cb71-10"><a href="multiple-regression.html#cb71-10"></a>    <span class="st">&quot;clFD&quot;</span>, <span class="st">&quot;clTmi&quot;</span>, <span class="st">&quot;clTma&quot;</span>, <span class="st">&quot;clP&quot;</span>)])</span>
<span id="cb71-11"><a href="multiple-regression.html#cb71-11"></a><span class="kw">anova</span>(out<span class="fl">.2</span>, <span class="dt">step =</span> <span class="dv">1000</span>, <span class="dt">perm.max =</span> <span class="dv">1000</span>)</span></code></pre></div>
<p>with the following R ouputs:</p>
<pre><code>Climate set
Permutation test for rda under reduced model
Model: rda(X = Dickcissel$abund, Y = Dickcissel[, c(&quot;clDD&quot;, &quot;clFD&quot;, &quot;clTmi&quot;, &quot;clTma&quot;, &quot;clP&quot;)],
       Z = Dickcissel[, c(&quot;broadleaf&quot;, &quot;conif&quot;, &quot;grass&quot;, &quot;crop&quot;, &quot;urban&quot;, &quot;wetland&quot;)])
          Df      Var      F     N.Perm   Pr(&gt;F)
Model         5   165.12   53.862    999      0.001 ***
Residual  634     388.72

Land cover set
Permutation test for rda under reduced model
Model: rda(X = Dickcissel$abund, Y=Dickcissel[, c(&quot;broadleaf&quot;, &quot;conif&quot;, &quot;grass&quot;, &quot;crop&quot;, &quot;urban&quot;, &quot;wetland&quot;)],
        Z = Dickcissel[, c(&quot;clDD&quot;, &quot;clFD&quot;, &quot;clTmi&quot;, &quot;clTma&quot;, &quot;clP&quot;)])
          Df      Var      F     N.Perm   Pr(&gt;F)
Model         6       5.54     1.5063    999      0.152
Residual  634     388.72</code></pre>
<p>In this case, the fraction of variance explained by the climate set is
significant (p-value=0.001) while the fraction explained by the land
cover set is not (p-value=0.152).</p>
<p>The results of variance partitioning are generally graphically
represented using Venn diagrams on which each explanatory datasets is
represented by a circle inside which their corresponding fraction of
explained variance is annotated:</p>
<div class="sourceCode" id="cb73"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb73-1"><a href="multiple-regression.html#cb73-1"></a><span class="kw">showvarparts</span>(<span class="dv">2</span>)</span>
<span id="cb73-2"><a href="multiple-regression.html#cb73-2"></a><span class="kw">plot</span>(part.lm, <span class="dt">digits =</span> <span class="dv">2</span>, <span class="dt">bg =</span> <span class="kw">rgb</span>(<span class="dv">48</span>, <span class="dv">225</span>, <span class="dv">210</span>, <span class="dv">80</span>, <span class="dt">maxColorValue =</span> <span class="dv">225</span>),</span>
<span id="cb73-3"><a href="multiple-regression.html#cb73-3"></a>    <span class="dt">col =</span> <span class="st">&quot;turquoise4&quot;</span>)</span></code></pre></div>
<p><img src="images//varpart.png" width="300" /></p>

</div>
</div>



ANCOVA! But never forget to correctly specify your model and verify its
statistical assumptions before interpreting its results according to the
ecological background of your data.</p>
</div>
<hr>
<center> 
  <div class="footer">
      All the content of the workshop series is under a <a href="https://creativecommons.org/licenses/by-nc/2.0/">Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License</a>.
  </div>
</center>
            </section>

          </div>
        </div>
      </div>
<a href="analysis-of-covariance-ancova.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="summary.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": true,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": false
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "section"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
