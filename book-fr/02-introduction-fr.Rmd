## 1. Aperçu

### 1.1 Définir la moyenne et la variation

En science, on s'intéresse souvent à déterminer les relations entre des
variables. Dans cet atelier, nous apprendrons comment utiliser des
modèles linéaires, un ensemble de modèles qui quantifie les relations
entre des variables.

On commencera par définir deux concepts-clés pour comprendre les modèles
linéaires: la moyenne et la variation. La **moyenne** est une mesure de
la valeur moyenne d'une population. Supposons que nous avons une
variable aléatoire x, comme la grandeur des personnes dans une salle, et
que nous voulons représenter les patrons de cette variable. En premier
lieu, on peut utiliser la moyenne (qui peut être calculée de plusieurs
manières).

Par contre, la moyenne ne peut pas représenter une population au
complet. On peut aussi décrire une population à l'aide de mesures de
variation. La **variation** est la dispersion (ou l'écart) des
observations autour de la moyenne. Par exemple, il y a peu de variation
si tout le monde dans une salle ont presque la même grandeur, et
beaucoup de variation si plusieurs personnes sont de grandeurs très
différentes. L'écart moyen, la variance, l'écart type, et le
coefficient de variation (ou l'écart type relatif) sont tous des
mesures de variation que nous définirons ci-dessous. On peut mesurer
l'écart de chaque élément par rapport à la moyenne:

Avec l'écart de tous les éléments, on peut calculer l'**écart moyen**:

Afin de transformer tous les variables en valeurs positives sans
utiliser de valeurs absolues, on peut mettre chaque valeur au carré. On
obtient alors la **variance**:

Par contre, en mettant toutes les valeurs au carré, on change les unités
de nos variables. Si on reprend notre exemple des grandeurs de personnes
dans la salle, la variance sera en m^2^, une unité qui n'est plus
pertinente pour notre question initiale. Pour transformer ces valeurs en
unités appropriées, on peut calculer l'**écart type**:

Finalement, pour exprimer le **coefficient de variation** (également
nommé l'écart type relatif) en pourcentage, nous avons:

### 1.2 Les modèles linéaires

Dans les modèles linéaires, on utilise les concepts de moyenne et de
variation pour décrire la relation entre deux variables. On dit
\"modèles linéaires\", parce qu'ils décrivent la relation entre
variables avec une droite:

$ {y_i} = {β_0} + {β_1}{x\_{i1}} + \... + {β_p}{x\_{ip}} + {ε_i}
\</m\>

où\
${y_i}$est la variable réponse,\
${β_0}$est l'ordonnée à l'origine de la droite de
régression,\
${β_1}$est le coefficient de variation de la 1^ère^ variable
explicative,\
${β_p}$est le coefficient de variation de la p^ème^ variable
explicative,\
${x_i1}$est la variable explicative continue pour la première
observation,\
${x_ip}$est la variable explicative continue pour la p^ième^
observation,\\\\\
${ε_i}$sont les résidus du modèle (i.e. la variance
inexpliquée).\
La **variable réponse** ($y\</m\>) est la variable que nous voulons
expliquer, ou la variable dépendante. Il n'y a qu'une variable
réponse. Les **variables explicatives** ($x\</m\>) sont des
variables qui peuvent (potentiellement) expliquer la variable réponse.
Celles-ci sont les variables indépendantes. On peut inclure une ou
plusieurs variables explicatives. Par exemple, supposons que nous
voulons expliquer la variation en grandeur des personnes dans cette
salle. La grandeur est la variable réponse. Des variables explicatives
peuvent être l'âge ou le sexe.

Dans les modèles linéaires, les variables réponses doivent être
continues, mais les variables explicatives peuvent être continues ou
catégoriques. Une **variable continue** a une infinité de valeurs
possibles. Une **variable catégorique** a un nombre limité de valeurs
possibles. L'âge, la température, et la latitude sont des variables
continues. Le sexe, le stade de développement, et le pays sont des
variables catégoriques. Pour les variables explicatives continues, le
modèle linéaire évalue s'il y a une corrélation significative entre la
variable réponse et la ou les variables explicatives. Pour les variables
explicatives catégoriques, le modèle linéaire évalue si la valeur
moyenne de la variable réponse diffère significativement entre les
différents niveaux (ou groupes) des variables explicatives. Ceci
deviendra plus clair en explorant les types de modèles linéaires dans
les sections suivantes.

Dans presque tous les cas, les variables explicatives n'expliquent pas
toute la variation dans la variable réponse. Par exemple, le sexe et
l'âge ne ne seront pas assez pour prédire la grandeur de chaque
personne parfaitement. La variation qui reste inexpliquée sont les
**résidus**, ou l'erreur.

Le but d'un modèle linéaire est de trouver la meilleure estimation des
paramètres (les variables β), puis d'évaluer la qualité de
l'ajustement (\"*goodness of fit*\") du modèle. Plusieurs méthodes ont
été développées pour calculer l'intercept et les coefficient de modèles
linéaires. Le choix approprié dépend du modèle. Le concept général de
ces méthodes consiste de minimiser les résidus.

Selon le type et le nombre de variables explicatives considérées,
différents outils statistiques peuvent être utilisés pour évaluer ces
relations entre variables. Le tableau ci-dessous liste les 5 types
d'analyses statistiques abordées dans cet atelier:

  -------------------------------------------------------------------------------------------------------------------
  Analyse statistique          Type de variable\   Type de variable\   Nombre de\                        Nombre de\
                               réponse Y           explicative X       variables explicatives            niveaux k
  ---------------------------- ------------------- ------------------- --------------------------------- ------------
  Régression linéaire simple   Continue            Continue            1                                 

  Test de t                    :::                 Catégorique         1                                 2

  ANOVA                        :::                 Catégorique         1 (ANOVA à un facteur), 2\        3 ou plus
                                                                       (ANOVA à deux facteurs) ou plus   

  ANCOVA                       :::                 Continue\           2 ou plus                         2 ou plus
                                                   ET catégorique                                        

  Régression multiple          :::                 Continue            2 ou plus                         
  -------------------------------------------------------------------------------------------------------------------

### 1.3 Conditions de base du modèle linéaire

Pour être valide, les modèles linéaires s'appuient sur 4 conditions de
base. Si les 4 conditions ne sont pas respectées, les résultats du
modèle ne peuvent pas être interprétés de façon valable.

1.  Les résidus sont **indépendants**
2.  Les résidus suivent une **distribution normale**
3.  Les résidus ont une **moyenne de 0**
4.  Les résidus sont **homoscédastiques** (i.e. leur variance est
    constante)

Notez que ces 4 conditions concernent les résidus, et non les variables
réponses ou explicatives. Les résidus doivent être indépendants,
c'est-à-dire qu'il n'y a pas de structure manquante dans le modèle
(comme une autocorrélation spatiale ou temporelle). Les résidus doivent
aussi suivre une distribution normale avec une moyenne de 0, signifiant
que la majorité des résidus ont une valeur proche de 0 (i.e. l'erreur
est très petite) et que la distribution est symmétrique (i.e. la
variable réponse est sous-estimée autant qu'elle est surestimée). Les
residus doivent être homoscédastiques, c'est-à-dire que l'erreur ne
change pas beaucoup quand les variables explicatives changent de valeur.

Dans les section suivantes, nous ne répétons pas les conditions
ci-dessus pour chaque modèle. **Prenez conscience, par contre, que ces
conditions de base s'appliquent à tous les modèles linéaires, incluant
tous ceux qui seront abordés ci-dessous.**

### 1.4 Statistiques de tests et p-values

Une fois que le modèle a été exécuté dans R, on reçoit une **sortie du
modèle** composé de plusieurs éléments. Comprendre chacun de ces
éléments et identifier les éléments pertinents de la sortie demande un
peu de pratique. La sortie inclut une estimation des paramètres (les
variables β), ainsi que des statistiques de tests. Le statistique de
test dépend du modèle linéaire employé (t est le statistique de test
pour la régression linéaire et le test de t, et F est le statistique de
test pour l'ANOVA).

Dans un modèle linéaire, l'**hypothèse nulle** est typiquement qu'il
n'y a aucune relation entre deux variables continues, out qu'il n'y a
pas de différence entre les niveaux d'une variable catégorique. **Plus
la valeur absolue d'un statistique de test est grande, moins il est
probable que l'hypothèse nulle soit valide**. La probabilité exacte se
trouve dans la sortie du modèle, et s'appelle le **\"p-value\"**. On
peut penser au p-value comme la probabilité que l'hypothèse nulle est
valide, malgré que c'est une simplification. *(Plus précisément, le
p-value est la probabilité que, étant donné que l'hypothèse nulle est
valide, la magnitude du statistique de test serait plus grande ou égale
à le statistique de test réellement observé.)* Par convention, si un
p-value est **inférieur à 0.05 (5%)**, l'hypothèse nulle est rejetée.
Cette valeur de seuil s'appelle **α** (alpha). Si on rejette
l'hypothèse nulle, on dit alors que l'hypothèse contraire est
soutenue: il y a une relation significative entre variables ou une
différence significative entre groupes. **Notez qu'on ne \"prouve\" pas
d'hypothèses**, mais qu'on les soutient ou on les rejette.