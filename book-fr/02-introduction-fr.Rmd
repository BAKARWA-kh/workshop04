## Aperçu

Les ateliers précédents ont explorés l'utilisation de `R` pour manipuler et représenter des données. Cependant, on s'intéresse souvent en science à déterminer les relations entre des variables. Cet atelier bâti sur les connaissances acquises préalablement et s'intéresse à la régression linéaire comme premier pas dans l'univers de l'analyse statistique. 

La régression linéaire se découle en multiple variantes telles que le Test de t et l'analyse de variance. Ces méthodes rendent possible la quatification de relations entre variables.

.center[
![:scale 80%](images/schema.png)
]

### Objectifs d'apprentissage

------------------------------------------------------------------------

* Apprendre la structure d'un modèle linéaire et ses différentes variantes.
* Apprendre comment faire un modèle linéaire dans R avec `lm()` et `anova()`
* Apprendre comment identifier un modèle dont les conditions d'application ne sont pas rencontrées et comment règler le problème.

### Qu'est-ce qu'un modèle linéaire ?

------------------------------------------------------------------------

Le modèle linéaire décrit la relation entre une variable **réponse** et une ou plusieurs autres variables **prédictrices**. Elle est utilisée pour analyser une **hypothèse bien formulée**, souvent associée à une question de recherche plus générale. La régression détermine si les variables sont correllées en inférent la **direction** et la **force** d'une relation, et notre **confiance** dans les estimations de l'effet.

Un travail scientifique important est nécessaire pour formuler un modèle linéaire. Puisque le modèle analyse une hypothèse, il est recommandé de formuler clairement les attentes concernant la direction et la force d'une relation en tant que prédictions avant d'effectuer un modèle linéaire. 

------------------------------------------------------------------------

#### Exemple : Abondance et masse des espèces d'oiseaux

**Hypothèse**

> Pour différentes espèces d'oiseaux, la masse moyenne d'un individu a un effet sur l'abondance maximale de l'espèce, en raison de contraintes écologiques (sources de nourriture, disponibilité de l'habitat, etc.).

**Prédiction**

> Les espèces caractérisées par des individus plus grands ont une abondance maximale plus faible.

Nous hypothétisons donc que les oiseaux caractérisés par une masse plus imprtante ont besoin de plus de nourriture et d'espace : la variable réponse est l'abondance maximale, et le prédicteur le poids moyen d'un individu. 

En fonction de notre prédiction, nous pouvons nous attendre à ce que la direction de la relation entre la variable réponse et le prédicteur soit inverse ou 'négative', de façon à ce qu'une masse plus élevée entraîne une abondance plus faible. Cependant, nous ne pouvons pas formuler d'attentes sur la force de la relation !

------------------------------------------------------------------------

**Les données**

L'exemple suivant explore le jeu de données "birdsdiet" :

```{r}
# Importez le jeu de données "bidsdiet" et le sauver dans l'objet "bird"
bird <- read.csv("data/birdsdiet.csv", stringsAsFactors = TRUE)
```

Le jeu de données bird contient sept variables :

```{r}
# Explorez les variables du jeu de données "bird"
str(bird)
```

Notez que Family, Diet, Passerine, et Aquatic sont toutes des variables catégoriques, malgré le fait qu'ils soient encodés de façons différentes (chaîne de caractères, catégorique, binaire).

Les variables d'intérêt au test de l'hypothèse sont :

* "MaxAbund" : La plus grande abondance observée sur un site en Amérique du Nord (continu / numérique)
* "Masse" : La taille du corps moyenne en grammes (continue / numérique)

------------------------------------------------------------------------

**Concepts de base**

Il existe deux concepts-clés pour comprendre les modèles linéaires: la **localisation** et la **variation**. 
Attention! Ces concepts sont centraux à la compréhension des autres concepts présentés dans l'atelier.

La **localisation** est une mesure de tendance centrale d'une population. Elle peut être mesurée entre-autres avec la **moyenne arithmétique** $\bar{x} = \frac{1}{n} \sum_{i=1}^{n} x_{i}$ : 

```{r}
# Moyenne de l'abondance maximale observée
mean(bird$MaxAbund)
```

ou la **médiane** :

```{r}
# Médiane de l'abondance maximale observée
median(bird$MaxAbund)
```

Par contre, la moyenne ne peut pas caractériser une population au complet. Nous pouvons donc aussi décrire une population à l'aide de mesures de variation. La **variation** est la dispersion (ou l'écart) des observations autour de la moyenne. Elle se mesure avec la **variance** $\sigma^2 = \frac{1}{n} \sum_{i=1}^{n} {(x_{i} - \bar{x})}^2$. La variance est la somme de l'écart élevée au carrée entre chaque valeur et la moyenne. L'élévation de l'écart au carré permet de transformer les valeurs en valeurs positives sans utiliser de valeurs absolues.

```{r}
# Variance de l'abondance maximale observée
var(bird$MaxAbund)
```

Par contre, en élevant toutes les valeurs au carré, on change les unités de nos variables. Dans cet exemple, la variance est donnée en abondance^2, une unité qui n'est plus pertinente pour notre question initiale. Pour transformer ces valeurs en unités appropriées, nous pouvons calculer l'**écart type** $\sigma$.

```{r}
# Écart type de l'abondance maximale observée
sd(bird$MaxAbund)
```

------------------------------------------------------------------------

**Exploration visuelle**

La figure suivante trace la variable réponse en fonction du prédicteur : 

```{r}
# Tracer la réponse en fonction du prédicteur
plot(bird$Mass, bird$MaxAbund)
```
 
Cette figure présente la variation de l'abondance maximale en fonction de la masse de l'oiseau. Nons somme intéressés à quantifier cette relation. Autrement dit, nous somme intéressés à quantifier l'effet de la masse des espèce d'oiseaux sur leur abondance maximale. Cependant, comment trouver la "meilleure" estimation de la relation ?
 
```{r, echo=FALSE}
plot(bird$Mass, bird$MaxAbund)
abline(coef = c(70, -.03),  lwd = 1.5, lty = 2, col = palette()[2])
abline(coef = c(20, -.005), lwd = 1.5, lty = 2, col = palette()[4])
abline(coef = c(200, -.1),  lwd = 1.5, lty = 2, col = palette()[6])
```

La "meilleure" estimation est la ligne qui minimise la somme des carrés. Cela se clarifiera dans les prochaines sections. Notez que la "meilleure" estimation peut également être l'absence de relation, similaire à la ligne bleue dans la figure.

------------------------------------------------------------------------

## Formulation d'un modèle linéaire

Le modèle linéaire décrit la "meilleure" relation entre une variable réponse ("MaxAbund") et une ou plusieurs prédicteurs (ici "Mass"). La variable réponse est la variable que nous voulons expliquer, ou la variable dépendante. Il n'y a qu'une variable réponse. Les variables explicatives sont des variables qui peuvent (potentiellement) expliquer la variable réponse. On peut inclure une ou plusieurs variables explicatives.

Dans un modèle linéaire, nous définissons une observation de la variable **réponse** $y$, comme étant $y_i$. Dans notre exemple, cela représente une observation d'abondance maximale pour une espèce $i$. 

Une observation correspondante du **prédicteur** $x$ est définie comme $x_i$ et représente, par exemple, le poids moyen d'un individu d'une espèce $i$.

Dans les modèles linéaires, on utilise les concepts de moyenne et de variation pour décrire la relation entre deux variables. Nous disons "modèles linéaires", parce qu'ils décrivent la relation entre variables avec une droite. Cette droite représente la relation supposée:

$$ y_i = \beta_0 + \beta_1 \times x_i + \epsilon_i$$

* $y_i$ est la variable réponse
* $x_i$ est le prédicteur
* Le paramètre $\beta_0$ est **l'ordonnée à l'origine**
* Le paramètre $\beta_1$ quantifie **l'effet** de $x$ sur $y$
* Le résidu $\epsilon_i$ représent la variation **non expliquée**
* La **valeur prédite** de $y_i$ se définit comme : $\hat{y}_i = \beta_0 + \beta_1 \times x_i$

------------------------------------------------------------------------

### Évaluation du modèle linéaire

Le modèle linéaire évalue s'il y a une correlation significative entre la variable réponse et la ou les variables explicatives. Ceci est fait en évaluant si la valeur moyenne de la variable réponse diffère signifitivement entre les différentes valeurs des variables explicatives, comme pour la variation de l'abondance maximale des oiseaux en fonction de leur masse.

Pour les variables explicatives catégoriques, le modèle linéaire évalue si la valeur moyenne de la variable réponse diffère significativement entre les différents niveaux (ou groupes) des variables explicatives. Ceci deviendra plus clair en explorant les types de modèles linéaires dans les sections suivantes.

Dans presque tous les cas, les variables explicatives n'expliquent pas toute la variation dans la variable réponse. La variation qui reste inexpliquée sont les **résidus**, ou l'erreur.

------------------------------------------------------------------------

### Coditions d'application du modèle linéraire

Le modèle linéaire est défini celon l'équation que nous avons exploré précédemment:

$$ y_i = \beta_0 + \beta_1 \times x_i + \epsilon_i$$

Pour être valide, tous les modèles linéaires s'appuient sur 4 conditions de base. Si les 4 conditions ne sont pas respectées, les résultats du modèle ne peuvent pas être interprétés de façon valable.

* Relation linéaire entre la réponse et le prédicteur
* Les résidus suivent une distribution normale avec une moyenne de $0$
* Les résidus sont distribués de manière identique (*homoscédasticité*)
* Les résidus sont indépendants les uns des autres

:::explanation
Notez que ces 4 conditions concernent les résidus, et non les variables réponses ou explicatives. **Cela ne veut pas dire** que l'ensemble des valeurs observées $y$ doivent suivre une distribution normale !
:::

------------------------------------------------------------------------

##### Normalité des résidus

Pour que les résultats d'un modèle linéaire soient valides, les **résidus** $\epsilon$ doivent suivre une **distribution normale** avec une moyenne de $0$ et une variance de $\sigma^2$, de façon à ce que la majorité des résidus aient une valeur proche de 0 (i.e. l'erreur est très petite) et que leur distribution soit symmétrique (i.e. la variable réponse est sous-estimée autant qu'elle est surestimée) :

$$\epsilon_i \sim \mathcal{N}(0,\,\sigma^2)$$

**Cela veut dire :** Chaque obsevation $y_i$ suit une distribution normale, avec moyenne $\hat{y} = \beta_0 + \beta_1 \times x_i$ et variance $\sigma^2$: 

$$y_i \sim \mathcal{N}(\hat{y},\,\sigma^2)$$

------------------------------------------------------------------------

##### Homoscédasticité

De la même façon, les residus doivent être homoscédastiques. C'est-à-dire que l'erreur ne change pas beaucoup pour les différentes valeurs des variables explicatives. Tous les résidus $\epsilon$ suivent la même distribution, la **variance** $\sigma^2$ **reste constante**.

------------------------------------------------------------------------

##### Indépendance des résidus

Il est également essentiel qye les résidus soient indépendants, c'est-à-dire qu'il n'y a pas de structure manquante dans le modèle (comme une autocorrélation spatiale ou temporelle). Autrement dit, chaque résidu $\epsilon_i$ est **indépendant** de tout autre résidu.

------------------------------------------------------------------------

## Notation des modèles linéaires

Cette section vise à fournir une compréhension de base des différents types de description de modèles linéaires qu'il est possible de rencontrer. La première est la notation mathématique et la seconde la notation en `R`.

------------------------------------------------------------------------

### Notation mathématique 

La notation mathématique est la seule forme de notation appropriée pour la rédaction de manuscrits. Nous notons les observations individuelles à l'aide de l'équation de la droite telle que vue dans les sections précédentes et de l'équation pour la distribution des résidus:   

$$y_i = \beta_0 + \beta_1 \times x_i + \epsilon_i \quad \textrm{with} \quad \epsilon_i \sim \mathcal{N}(0,\,\sigma^2)$$

Pour noter l'ensemble des observations, nous suivons la notation matricielle et incluons l'intercept dans$\mathbf{X}$ et $\boldsymbol{\beta}$) :   

$$\mathbf{y}= \mathbf{X}\boldsymbol{\beta} + \mathbf{\epsilon} \quad \textrm{with} \quad \epsilon_i \sim \mathcal{N}(0,\,I_n\sigma^2)$$ 
------------------------------------------------------------------------

### Notation en R

Il est à noter que la notation R n'est pas adéquate pour préparer une publication.

En `R`, nous écrivons la formule du modèle comme :

```
y ~ 1 + x
```  

Ou encore plus simplement comme :
  
```
y ~ x
```  

qui inclut aussi la constante.
  
:::noway
Il ne faut jamais mélanger les différents types de notation !
:::

------------------------------------------------------------------------

## Effectuer une modèle linéaire
 
Nous avons vu qu'il est possible de définir un modèle linéaire avec cette équation :

$$ y_i = \beta_0 + \beta_1 \times x_i + \epsilon_i$$

Effectuer une modèle linéaire revient à trouver les "meilleures" estimations des paramètres $\beta_0,\, \beta_1$. C'est ce que nous appelons faire l'estimation du modèle.

Les "meilleurs" paramètres sont ceux qui minimisent la variation dans la variable réponse. La méthode la plus répendue pour minimiser la variation d'un modèle est de faire la somme des résidus au carré $\sum{\epsilon_i^2}$. Cette méthode est appelée la méthode de **moindres carrés ordinaire** (MCO).









### 1.1 Définir la moyenne et la variation

En science, on s'intéresse souvent à déterminer les relations entre des
variables. Dans cet atelier, nous apprendrons comment utiliser des
modèles linéaires, un ensemble de modèles qui quantifie les relations
entre des variables.

On commencera par définir deux concepts-clés pour comprendre les modèles
linéaires: la moyenne et la variation. La **moyenne** est une mesure de
de la localisation d'une population. Supposons que nous avons une
variable aléatoire x, comme la grandeur des personnes dans une salle, et
que nous voulons représenter les patrons de cette variable. En premier
lieu, on peut utiliser la moyenne arithmétique (qui peut être calculée de plusieurs
manières).

Par contre, la moyenne ne peut pas représenter une population au
complet. On peut aussi décrire une population à l'aide de mesures de
variation. La **variation** est la dispersion (ou l'écart) des
observations autour de la moyenne. Par exemple, il y a peu de variation
si tout le monde dans une salle ont presque la même grandeur, et
beaucoup de variation si plusieurs personnes sont de grandeurs très
différentes. L'écart moyen, la variance, l'écart type, et le
coefficient de variation (ou l'écart type relatif) sont tous des
mesures de variation que nous définirons ci-dessous. On peut mesurer
l'écart de chaque élément par rapport à la moyenne:

Avec l'écart de tous les éléments, on peut calculer l'**écart moyen**:

Afin de transformer tous les variables en valeurs positives sans
utiliser de valeurs absolues, on peut mettre chaque valeur au carré. On
obtient alors la **variance**:

Par contre, en mettant toutes les valeurs au carré, on change les unités
de nos variables. Si on reprend notre exemple des grandeurs de personnes
dans la salle, la variance sera en m^2^, une unité qui n'est plus
pertinente pour notre question initiale. Pour transformer ces valeurs en
unités appropriées, on peut calculer l'**écart type**:

Finalement, pour exprimer le **coefficient de variation** (également
nommé l'écart type relatif) en pourcentage, nous avons:

### 1.2 Les modèles linéaires

Dans les modèles linéaires, on utilise les concepts de moyenne et de
variation pour décrire la relation entre deux variables. On dit
\"modèles linéaires\", parce qu'ils décrivent la relation entre
variables avec une droite:

$ {y_i} = {β_0} + {β_1}{x\_{i1}} + \... + {β_p}{x\_{ip}} + {ε_i}
\</m\>

où\
${y_i}$est la variable réponse,\
${β_0}$est l'ordonnée à l'origine de la droite de
régression,\
${β_1}$est le coefficient de variation de la 1^ère^ variable
explicative,\
${β_p}$est le coefficient de variation de la p^ème^ variable
explicative,\
${x_i1}$est la variable explicative continue pour la première
observation,\
${x_ip}$est la variable explicative continue pour la p^ième^
observation,\\\\\
${ε_i}$sont les résidus du modèle (i.e. la variance
inexpliquée).\
La **variable réponse** ($y\</m\>) est la variable que nous voulons
expliquer, ou la variable dépendante. Il n'y a qu'une variable
réponse. Les **variables explicatives** ($x\</m\>) sont des
variables qui peuvent (potentiellement) expliquer la variable réponse.
Celles-ci sont les variables indépendantes. On peut inclure une ou
plusieurs variables explicatives. Par exemple, supposons que nous
voulons expliquer la variation en grandeur des personnes dans cette
salle. La grandeur est la variable réponse. Des variables explicatives
peuvent être l'âge ou le sexe.

Dans les modèles linéaires, les variables réponses doivent être
continues, mais les variables explicatives peuvent être continues ou
catégoriques. Une **variable continue** a une infinité de valeurs
possibles. Une **variable catégorique** a un nombre limité de valeurs
possibles. L'âge, la température, et la latitude sont des variables
continues. Le sexe, le stade de développement, et le pays sont des
variables catégoriques. Pour les variables explicatives continues, le
modèle linéaire évalue s'il y a une corrélation significative entre la
variable réponse et la ou les variables explicatives. Pour les variables
explicatives catégoriques, le modèle linéaire évalue si la valeur
moyenne de la variable réponse diffère significativement entre les
différents niveaux (ou groupes) des variables explicatives. Ceci
deviendra plus clair en explorant les types de modèles linéaires dans
les sections suivantes.

Dans presque tous les cas, les variables explicatives n'expliquent pas
toute la variation dans la variable réponse. Par exemple, le sexe et
l'âge ne ne seront pas assez pour prédire la grandeur de chaque
personne parfaitement. La variation qui reste inexpliquée sont les
**résidus**, ou l'erreur.

Le but d'un modèle linéaire est de trouver la meilleure estimation des
paramètres (les variables β), puis d'évaluer la qualité de
l'ajustement (\"*goodness of fit*\") du modèle. Plusieurs méthodes ont
été développées pour calculer l'intercept et les coefficient de modèles
linéaires. Le choix approprié dépend du modèle. Le concept général de
ces méthodes consiste de minimiser les résidus.

Selon le type et le nombre de variables explicatives considérées,
différents outils statistiques peuvent être utilisés pour évaluer ces
relations entre variables. Le tableau ci-dessous liste les 5 types
d'analyses statistiques abordées dans cet atelier:

  -------------------------------------------------------------------------------------------------------------------
  Analyse statistique          Type de variable\   Type de variable\   Nombre de\                        Nombre de\
                               réponse Y           explicative X       variables explicatives            niveaux k
  ---------------------------- ------------------- ------------------- --------------------------------- ------------
  Régression linéaire simple   Continue            Continue            1                                 

  Test de t                    :::                 Catégorique         1                                 2

  ANOVA                        :::                 Catégorique         1 (ANOVA à un facteur), 2\        3 ou plus
                                                                       (ANOVA à deux facteurs) ou plus   

  ANCOVA                       :::                 Continue\           2 ou plus                         2 ou plus
                                                   ET catégorique                                        

  Régression multiple          :::                 Continue            2 ou plus                         
  -------------------------------------------------------------------------------------------------------------------

### 1.3 Conditions de base du modèle linéaire

Pour être valide, les modèles linéaires s'appuient sur 4 conditions de
base. Si les 4 conditions ne sont pas respectées, les résultats du
modèle ne peuvent pas être interprétés de façon valable.

1.  Les résidus sont **indépendants**
2.  Les résidus suivent une **distribution normale**
3.  Les résidus ont une **moyenne de 0**
4.  Les résidus sont **homoscédastiques** (i.e. leur variance est
    constante)

Notez que ces 4 conditions concernent les résidus, et non les variables
réponses ou explicatives. Les résidus doivent être indépendants,
c'est-à-dire qu'il n'y a pas de structure manquante dans le modèle
(comme une autocorrélation spatiale ou temporelle). Les résidus doivent
aussi suivre une distribution normale avec une moyenne de 0, signifiant
que la majorité des résidus ont une valeur proche de 0 (i.e. l'erreur
est très petite) et que la distribution est symmétrique (i.e. la
variable réponse est sous-estimée autant qu'elle est surestimée). Les
residus doivent être homoscédastiques, c'est-à-dire que l'erreur ne
change pas beaucoup quand les variables explicatives changent de valeur.

Dans les section suivantes, nous ne répétons pas les conditions
ci-dessus pour chaque modèle. **Prenez conscience, par contre, que ces
conditions de base s'appliquent à tous les modèles linéaires, incluant
tous ceux qui seront abordés ci-dessous.**

### 1.4 Statistiques de tests et p-values

Une fois que le modèle a été exécuté dans R, on reçoit une **sortie du
modèle** composé de plusieurs éléments. Comprendre chacun de ces
éléments et identifier les éléments pertinents de la sortie demande un
peu de pratique. La sortie inclut une estimation des paramètres (les
variables β), ainsi que des statistiques de tests. Le statistique de
test dépend du modèle linéaire employé (t est le statistique de test
pour la régression linéaire et le test de t, et F est le statistique de
test pour l'ANOVA).

Dans un modèle linéaire, l'**hypothèse nulle** est typiquement qu'il
n'y a aucune relation entre deux variables continues, out qu'il n'y a
pas de différence entre les niveaux d'une variable catégorique. **Plus
la valeur absolue d'un statistique de test est grande, moins il est
probable que l'hypothèse nulle soit valide**. La probabilité exacte se
trouve dans la sortie du modèle, et s'appelle le **\"p-value\"**. On
peut penser au p-value comme la probabilité que l'hypothèse nulle est
valide, malgré que c'est une simplification. *(Plus précisément, le
p-value est la probabilité que, étant donné que l'hypothèse nulle est
valide, la magnitude du statistique de test serait plus grande ou égale
à le statistique de test réellement observé.)* Par convention, si un
p-value est **inférieur à 0.05 (5%)**, l'hypothèse nulle est rejetée.
Cette valeur de seuil s'appelle **α** (alpha). Si on rejette
l'hypothèse nulle, on dit alors que l'hypothèse contraire est
soutenue: il y a une relation significative entre variables ou une
différence significative entre groupes. **Notez qu'on ne \"prouve\" pas
d'hypothèses**, mais qu'on les soutient ou on les rejette.