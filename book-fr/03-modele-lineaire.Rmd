# Régression linéaire avec R

Dans l'exemple suivant, nous reprendrons les données d'abondance et de masse des oiseaux pour effectuer une régression linéaire en R. Basé sur l'hypothèse, nous formulons une formule qui nous permet d'exécuter le modèle et puis nous vérifions les conditions d'application de celui-ci. Nous verrons également comment interpréter la sortie du modèle et comment le représenter graphiquement.


## Formulation du modèle

------------------------------------------------------------------------

Les données sont composées de la masse moyenne des individus d'une espèce et l'abondance de ces espèces. Nous somme intéressé à quantifier la relation entre la masse d'un individu et l'abondance de l'espèce (ou l'effet de la masse sur l'abondance).

Nous avons formulé l'hypothèse que pour différentes espèces d'oiseaux, la **masse moyenne d'un individu a un effet sur l'abondance maximale** de l'espèce, en raison de contraintes écologiques (sources de nourriture, disponibilité de l'habitat, etc.).

### Équation du modèle

En notation mathématique, un modèle linéaire prend la forme de l'équation d'une droite pour laquelle la variable prédite est l'abondance maximale "MaxAbund" et la variable prédicteur est la masse des individus "Mass".

$$\textrm{MaxAbund}_i = \beta_0 + \beta_1 \times \textrm{Mass}_i + \epsilon_i \;, \quad \epsilon_i \sim \mathcal{N}(0, \sigma^2)$$

> Notez que le modèle linéaire a trois variables: $\beta_0$ , $\beta_1$ et $\sigma^1$. $\sigma^1$ défini la variance des données autour du modèle et est une variable de la distribution normale qui décrit la distribution des données autour du modèle (de part et d'autre de notre droite).

**Formule en R**

Dans le langage de programmation R, l'équation est traduite par :

```
MaxAbund ~ Mass
```
où la variable prédite est placée à gauche du tilde et la variable prédicteur est à droite.


## Régression linéaire avec R

------------------------------------------------------------------------

Effectuer une régression linéaire avec R se découpe en trois étapes:

1. Formuler et exécuter un modèle linéaire basé sur un hypothèse
2. Vérifier les conditions d'application du modèle linéaire
3. Examiner la sortie du modèle et si les conditions sont respectées
    * Analyser les paramètres de régression
    * Tracer le modèle
    * Effectuer des tests de signification sur les estimations des paramètres (si nécessaire)

Nous allons explorer chaque étape dans les sections suivantes.

Aussi, dans le cas ou les conditions ne sont pas respectées, nous verrons qu'il est possible d'envisager l'utilisation d'un *Modèle linéaire généralisé* (GLM) ou la transformation des données.

### **Étape 1.** Formuler et exécuter un modèle linéaire

La fonction `lm()` est utilisée pour ajuster un modèle linéaire, en fournissant la formule du modèle comme premier argument :

```{r eval=TRUE}
# Régression linéaire de l'abondance maximale en fonction de la masse
lm1 <- lm(MaxAbund ~ Mass, data = bird)
```

Avec cette ligne de code, nous définissons un nouvel objet `lm1` qui contient le modèle linéaire. Nous spécifions également deux arguments dans la fonction. Le premier `MaxAbund ~ Mass` est la formule du modèle et le second `bird` défini l'objet qui contient les variables.

> Avant d'utiliser une nouvelle fonction dans R, vous devriez vous référer à sa page d'aide (`?nomdelafonction`) afin de comprendre comment utiliser la fonction ainsi que les paramètres par défaut.

Regardons les estimations des paramètres :

```{r, eval=TRUE}
# Examen de la sortie de la régression
lm1
```

Comment les paramètres se comparent-ils à nos prédictions ? Vous remarquerez que le paramètre pour la masse est positif alors que nous avons prédit une relation négative (*Les espèces caractérisées par des individus plus grands ont une abondance maximale plus faible*).

Cependant, pouvons-nous nous fier aux estimations? Pour en être certain, il faut vérifier les conditions d'application !

### **Étape 2.** Vérifier les conditions d'application avec les graphiques diagnostics

Une méthode efficace pour vérifier le respect des conditions d'application du modèle est de procéder à un examen visuel. Quatres graphiques diagnostiques peuvent être produits d'un objet `lm`. Pour ce faire, nous utilisons ces commandes :

```{r, eval=FALSE, fig.height=6, fig.width=8}
par(mfrow=c(2,2))
plot(lm1)
```

```{r, echo=FALSE, fig.height=4.75, fig.width=5.5}
par(mfrow=c(2,2), mar = c(4,4,2,1.1), oma =c(0,0,0,0))
plot(lm1)
```

`par()` est une fonction qui permet de définir les paramètres du graphique. Ici, nous spécifions `mfrow=c(2,2)`  qui permet d'afficher une grille de 2 x 2 graphiques à la fois. Finalement, `plot()`produit les graphiques.

> Pour afficher une seule figure (parcelle) à la fois, nous pouvons spécifier `par(mfrow=1)`. 

#### Graphique #1 - Résidus vs valeurs prédites

Le premier graphique nous informe de la distribution des résidus en fonction des valeurs prédites par le modèle de régression linéaire. Chaque point représente la distance entre la variable réponse et la réponse prédite par le modèle. Il nous informe sur l'*indépendance* des résidus et sur leur *distribution*. Il faut se rappeler qu'avec la régression linéaire, nous avons besoin d'une distribution uniforme des résidus (condition d'*homoscédasticité*).

```{r, echo = FALSE, fig.height=5, fig.width=6.5}
  set.seed(1234564)
  x <- rnorm(100,10,10)
  y <- 2*x+0 + rnorm(100)
  lm <- lm(y~x)
  plot(lm, which = 1)
```

Sur l'axe des **y** nous retrouvons les résidus $\epsilon_i$ et sur l'axe des **x** les valeurs prédites $\hat{y_i} = \beta_0 + \beta_1 \times x_i$.

Dans une situation idéale, la dispersion des points ne présente pas de patron. 

* Si les résidus sont dispersés de façon **aléatoire autour de la ligne de 0**, la relation est linéaire et la moyenne des résidus est 0.
* Si les résidus forment une **bande horizontale** approximative autour de la ligne de 0, la variance des résidus est homogène (donc, ils sont homoscédastiques).
* Si les résidus sont organisés **en forme d'entonnoir**, les résidus ne sont pas homoscédastiques.

------------------------------------------------------------------------

**Alerte !** Il faut être alerté si la distribution des points est non-linéaire comme dans ces deux exemples :

```{r, echo=FALSE, fig.height=4.5, fig.width=8.5, warning=FALSE}
par(mfrow=c(1,2))
set.seed(1234564)
x = rnorm(100,10,10)
y = (x)^2 + rnorm(length(x),0,30)
lm=lm(y~scale(x))
plot(lm,which = 1, main = "Non-linéaire", col.main="red")
x = abs(rnorm(100,10,10))
y = (x) + rnorm(length(x), 0, x)
lm=lm(y~scale(x))
plot(lm,which = 1, main = "Hétéroscédastique", col.main="red")
```

Ces exemples présentent une relation non-linéaire et un exemple d'hétéroscédasticité qui est l'opposé de homoscédastique, ce qui signifie que la condition de normalité est non-respectée. 

Dans cette situation, il faut plutôt utiliser un **modèle linéaire généralisé** (MLG) qui permet d'autres distributions (Poisson, binomial, binomial négatif, etc.) ou essayer de **transformer** la variable réponse et/ou les prédicteurs.

------------------------------------------------------------------------

#### Graphique #2 - Échelle localisée

Le deuxième graphique diagnostique permet de vérifier si la *dispersion des résidus* augmente pour une valeur prédite donnée (i.e. si la dispersion des résidus est causée par la variable explicative). Si la dispersion augmente, la condition de base d'homoscédasticité n'est pas respectée.

```{r, echo=FALSE, fig.height=4.5, fig.width=6, warning=FALSE}
set.seed(1234564)
x <- 1:100
y <- x + rnorm(100,sd=5)
lm=lm(y~x)
plot(lm,which = 3)
```

Sur l'axe des **y** nous retrouvons la racine carrée des résidus standardisés $\sqrt{\frac{\epsilon_i}{\sigma}}$ et sur l'axe des **x** les valeurs prédites $\hat{y_i} = \beta_0 + \beta_1 \times x_i$.

Nous recherchons ici aussi une dispersion des points sans patron, donc un prédicteur distributé de manière égale.

------------------------------------------------------------------------

**Alerte !** Il faut être méfiant si la distribution des points présente une tendance marquée :

```{r, echo=FALSE, fig.height=4.5, fig.width=6, warning=FALSE}
set.seed(2)
x = abs(rnorm(100,10,10))
y = (x) + rnorm(length(x), 0, x)
lm=lm(y~scale(x))
plot(lm,which = 3)
```

Dans une situation comme celle-ci, nous ne pouvons nous fier aux résultats de modèle et devons plutôt essayer d'utiliser un **modèle linéaire généralisé** (MLG) qui permet d'autres distributions (Poisson, binomial, binomial négatif, etc.) ou de **transformer** la variable réponse et/ou les prédicteurs.

------------------------------------------------------------------------

#### Graphique #3 - Normal QQ

Le troisième graphique présente la distribution des résidus. Avec ce graphique quantile-quantile, nous pouvons évaluer la normalité des résidus. Ce graphique compare la distribution de probabilité des résidus du modèle à une distribution de probabilité de données normales. 

```{r, echo=FALSE, fig.height=4.5, fig.width=6, warning=FALSE}
set.seed(1234564)
x <- 1:100
y <- x + rnorm(100,sd=5)
lm=lm(y~x)
plot(lm, which = 2)
```

Sur l'axe des **y** nous retrouvons les résidus standardisés $\frac{\epsilon_i}{\sigma}$ et sur l'axe des **x** les quantiles d'une distribution normale standard $\mathcal{N}(0, \sigma^2)$.

Nous voulons voir les résidus standardisés près de la ligne 1:1. Ainsi, les résidus peuvent être considérés comme normalement distribués.

------------------------------------------------------------------------

**Alerte !** Il faut être méfiant si la distribution des points ne suit pas la ligne 1:1 :

```{r, echo=FALSE, fig.height=4.5, fig.width=6, warning=FALSE}
set.seed(2)
x = abs(rnorm(100,10,10))
y = (x) + rnorm(length(x), 0, x)
lm=lm(y~scale(x))
plot(lm, which = 2)
```

Dans ce cas-ci, les points ne sont pas bien alignés sur la droite, ce qui suggère que les résidus ne sont pas distribués normalement. Il faut plutôt essayer d'utiliser un **modèle linéaire généralisé** (MLG) qui permet d'autres distributions (Poisson, binomial, binomial négatif, etc.) ou de **transformer** la variable réponse et/ou les prédicteurs.

------------------------------------------------------------------------

#### Graphique #4 - Résidus vs effet de levier

Ce dernier graphique diagnostique présente les résidus et leur influence. Il permet de déterminer si certaines observations ont une forte influence. Bien que nous ne testons pas un test de condition de base, la présence de points avec une forte influence peut influencer notre interprétation des données. Si une ou certaines observations sont aberrantes (dont, si elles ont des valeurs très différentes des autres), le modèle peut être mal ajusté en raison de leur influence exagérée sur l'estimation du modèle. 

Le graphique des résidus vs effet de levier pésente les *points de levier* qui sont des observations extêmes du prédicteur et leur influence sur la régression. L'influence est quantifiée par la *ditance Cook*. **Une distance suppérieure à 0,5 est problématique**.

**Exemple d'effet de levier et d'influence**

Il ne s'agit pas ici de graphiques diagnostiques, mais de figures qui illustrent les concepts d'effet de levier et d'influence.

```{r, echo=FALSE, fig.height=8, fig.width=7.7, warning=FALSE}
par(mfrow=c(3, 1), mar = c(4, 15, 1, 3), cex = 1.2)
set.seed(1234564)
x <- 1:20
y <- rnorm(x, x, 2)
lm0 <- lm(y ~ x)
# plot 1
plot(x, y, ylim = c(-4, 22), xlab = '', ylab = ''); abline(lm0, col = 2); points(11, -3, pch = 15)
# add 20, 10 point to the new lm
xx <- c(x, 11); yy <- c(y, -3)
abline(lm(yy ~ xx), col = 2, lty = 3)
text(-20, 10, srt=0, adj = 0, labels = "* Pas d'effet de levier \n* Faible influence
", xpd = TRUE, cex = 1.5)
# plot 2
plot(x, y, ylim = c(-4, 32), xlim = c(0, 31), xlab = '', ylab = ''); abline(lm0, col = 2); points(30, 30, pch = 15)
# add 20, 10 point to the new lm
xx <- c(x, 30); yy <- c(y, 30)
abline(lm(yy ~ xx), col = 2, lty = 3)
text(-33, 15, srt=0, adj = 0, labels = "* Effet de levier \n* Pas d'influence", xpd = TRUE, cex = 1.5)
# plot 3
plot(x, y, ylim = c(-4, 32), xlim = c(0, 31), xlab = '', ylab = ''); abline(lm0, col = 2); points(30, 15, pch = 15)
# add 20, 10 point to the new lm
xx <- c(x, 30); yy <- c(y, 15)
abline(lm(yy ~ xx), col = 2, lty = 3)
text(-33, 15, srt=0, adj = 0, labels = '* Effet de levier \n* Influence élevée', xpd = TRUE, cex = 1.5)
```

Sur l'axe des **y** nous retrouvons la réponse et le prédicteur sur l'axe des **x**.

Le modèle ne devrait pas **pas dépendre fortement d'observations isolées**. Une influence élevée de points de levier cause le modèle à passer près des points de levier, car ils manquent d'observations voisines.

**Graphique #4**

Le graphique diagnostique présente Ssr l'axe des **y** les résidus standardisés $\frac{\epsilon_i}{\sigma}$ et l'effet de levier sur l'axe des **x**. La ligne pointillée rouge marque la distance de Cook de 0,5.

```{r, echo=FALSE, fig.height=4.5, fig.width=9, warning=FALSE}
par(mfrow=c(1,2))
set.seed(1234564)
x <- 1:100
y <- x + rnorm(100,sd=5)
lm=lm(y~x)
plot(lm, which = 5, main = "Aucune observation influente", col.main=palette()[3])
set.seed(1234564)
x = abs(rnorm(100,10,10))
y = (x) + rnorm(length(x), 0, x)
lm=lm(y~scale(x))
plot(lm, which = 5, main = "Effet de levier et faible influence",  col.main=palette()[3])
```

Nous voulons observer des résidus se situant à l'intérieur des lignes pointillées marquant la distance de Cook de 0,5.

------------------------------------------------------------------------

**Alerte !** Il faut être méfiant si un ou des points se trouvent à l'extérieur de la ligne pointillée :

```{r, echo=FALSE, fig.height=5, fig.width=8, warning=FALSE}
set.seed(1234564)
x = abs(rnorm(100,10,10))
y = (x) + rnorm(length(x), 0, x)
y[29] <- 100
lm=lm(y~scale(x))
plot(lm, which = 5, main = "Effet de levier et influence élevée")
```

Le 29 a un effet de levier et une distance de Cook de plus de 0,5. Il correspond à une donnée abérante. Il ne faut cependant jamais supprimer les valeurs aberrantes sans avoir des bonnes raisons de le faire ! Si (et seulement si!) ces observations correspondent à des
erreurs de mesure ou à des exceptions, elles peuvent être retirées du jeu de données.

------------------------------------------------------------------------

### **Étape 2**. Vérifier les conditions d'application pour `lm1`

Le modèle `lm1` respecte-t-il les conditions du modèle linéaire ?

```{r, echo=FALSE, fig.height=5.5, fig.width=7.5}
par(mfrow=c(2,2), mar = c(4,4,2,1.1), oma =c(0,0,0,0))
plot(lm1)
```

En se basant sur les connaissances acquises dans les sections précédentes, ces graphiques diagnostiques présentent de sérieux problèmes. 
* Les graphiques 1 et 2 présentent de fortes tendances,
* Le graphique 3 montre que les résidus ne suivent pas une distribution normale,
* Le graphique 4 met en évidence l'effet levier du point 32 et de son influence très élevée.

------------------------------------------------------------------------

### Conditions non-respectées - Quelle est la cause ?

Pour comprendre la source des problèmes du modèle linéaire, traçons le modèle avec les observations :

```{r, fig.height=4, fig.width=11}
par(mfrow = c(1,2))
coef(lm1) # constante et pente
plot(MaxAbund ~ Mass, data=bird) # graphique à gauche
abline(lm1) # ligne définie par les paramètres du modèle
hist(residuals(lm1)) # graphique à droite : distribution des résidus
```

À gauche nous avons les données ainsi que la droite représentant l'estimation du modèle (`MaxAbund ~ Mass`). À gauche, la distribution des résidus.

Nous pouvons verifier si les résidus suivent une distribution normale à l'aide d'un test de *Shapiro-Wilk* et d'un test d'asymétrie (*skewness*) :

```{r}
shapiro.test(residuals(lm1))

library(e1071)
skewness(residuals(lm1))
```

Les test de Shapiro-Wilk compare la distribution des données observées à une distribution normale. Les données observées peuvent être considérées comme normalement distribuées lorsque la valeur de p calculée par le test de Shapiro-Wilk est supérieure au seuil de significativité α (généralement 0.05). Ici, la valeur de p (`p-value`) retournée indique une distribution significativement différente d'une normale.

Le test d'asymétrie mesure le décalage des résidus. Une valeur positive représente un décalage vers la gauche et une valeur négative un décalage vers la droite. Ici, la valeur positive d'asymétrie indique que la distribution est décalée vers la gauche. 


------------------------------------------------------------------------

### Conditions non-respectées - Comment procéder ?

Clairement, les conditions d'application du modèle linéraire `lm1` ne sont pas respectées. Nous ne pouvons donc pas nous fier aux résultats du modèle. Il faut se tourner vers une autre alternative et il y a deux options lorsque les conditions d'application du modèle linéaire ne sont pas respectées.

**Utiliser un autre type de modèle**

Les ateliers R 6 à 8 du CSBQ explorent d'autres modèles qui pourraient être mieux adaptés à l'hypothèse et aux données.

**Transformer les données**

Il est également possible de modifier ses données, que ce soit la variable réponse ou les prédicteurs. Plusieurs types de transformations sont possibles et leur utilité dépend de la distribution de la variable et du type de modèle. Cependant, **la modification des variables est souvent délicate en pratique**. La transformation peut **régler certains** problèmes, mais peut en **créer d'autres**. 

> Il est à noter que les **résultats des tests de signification** sur les données transformées ne sont **pas automatiquement valables** pour les données non transformées.

------------------------------------------------------------------------

#### Défi 1: Un modèle sur variables transformées

Notre modèle présente de sérieux problèmes. Essayons une transformation logarithmique pour voir si ça peut corriger la situation. 

Premièrement, transformez données et exécutez une nouvelle régression linéaire sur ces données. Par la suite, vérifiez le respect des conditions d'application du nouveau modèle en utilisant les graphique diagnostics.

**Étape 1**

Débutons par la transformation des données de notre jeu de données :

```{r}
# Transformation logarithmique des données
bird$logMaxAbund <- log10(bird$MaxAbund)
bird$logMass <- log10(bird$Mass)
```

Avec ces données `logMaxAbund` et `logMass` transformées, nous exécutons une nouvelle régression linéaire et sauvegardons l'objet du modèle sous `lm2`.

```{r}
# Modèle linéaire sur les données transformées
lm2 <- lm(logMaxAbund ~ logMass, data = bird)
```

Nous pouvons observer que les paramètres s'alignent avec notre prédiciton. c'est-à-dire, que le coefficient `logMass` est négatif et donc que l'abondance décroit avec la masse de l'espèce. Cependant, il faut encore vérifier conditions d'application du modèle pour s'assurer de la validité des résultats.

**Étape 2** 

Vérifions les conditions pour `lm2` en utilisant les graphique diagnostics.

```{r, fig.height=5.5, fig.width=7.5}
par(mfrow=c(2,2), mar=c(3,4,1.15,1.2))
plot(lm2)
```

Les graphiques diagnostiques semblent beaucoup mieux, mais il reste des problèmes. Certains graphiques présentent encore des tendances marquées. Traçons le modèle avec les observations :

```{r, fig.height=4, fig.width=11,}
# Graphique du modèle et des observations
par(mfrow = c(1,2))
coef(lm2) # constante et pente
plot(logMaxAbund ~ logMass, data=bird) # graphique à gauche
abline(lm2) # ligne définie par les paramètres du modèle
hist(residuals(lm2)) # graphique à droite : distribution des résidus
```

Le modèle semble mieux expliquer les données et la distribution des résidus s'est beaucoup rapproché de la distribution normale.

------------------------------------------------------------------------

### **Étape 3.** Analyser les paramètres

La dernière étape d'une régression linéaire avec R est de vérifier les paramètres du modèle. Nous utilisons alors la commande `summary()` pour obtenir plus d'informations sure le modèle ajusté.

```{r, comment=""}
# Paramètres du modèle ajusté
summary(lm2)
```

La sortie de `summary()` présente plusieurs valeurs :
  1. `Coefficients` : Estimations des paramètres et leur écarts type
  2. `Pr(>|t|)` : Résultats d'un test de t visant à déterminer si les paramètres sont différents de 0
  3. `Adjusted R squared` (R au carré ajusté) : Dans quelle mesure le modèle explique-t-il les données ?
  4. `F-statistic` (statistique F) (ANOVA) : Le modèle est-il significativement différent d'un modèle sans prédicteur (modèle nul) ?
  
Nous aborderons dans la prochaine section les Tests de T et l'ANOVA. Nous pouvons cependant déjà en dégager que notre modèle n'est que marginalement meilleur que le modèle nul.

Avec l'objet `lm2`, nous pouvons aussi extraire les paramètres du modèle et les autres résultats :

```{r}
# Vecteurs de résidus et valeures prédites
e <- residuals(lm2)
y <- fitted(lm2)
coefficients(lm2) # coefficients
summary(lm2)$coefficients # coefficients avec test de t
summary(lm2)$adj.r.squared # R au carré ajusté
```

## Interprétation du modèle

------------------------------------------------------------------------

L'interprétation du modèle est l'étape finale lorsque nous obtenons un modèle qui respecte les conditions d'application. L'interprétation est l'évaluation de l'appuis du modèle pour l'hypothèse. Bref, nous répondons à la question: *Dans quelle mesure le modèle soutient-il notre hypothèse ?*

**Hypothèse**

> Pour différentes espèces d'oiseaux, la **masse moyenne d'un individu a un effet sur l'abondance maximale** de l'espèce, en raison de contraintes écologiques (sources de nourriture, disponibilité de l'habitat, etc.).

```{r, comment=""}
# Simmaire du modèle linéaire avec les données log-transformées
summary(lm2)
```

Le modèle `lm2` ne présente que très **peu preuves à l'appuis** de l'hypothèse. En regardant les paramètres du modèle comme nous l'avons vu précédemment, nous observons que le modèle explique peu de la réponse. 

Le faible `R au carré ajusté` indique qu'une faible partie de la variance de la variable réponse est expliquée par le modèle. La masse n'explique qu'une petite fraction de l'abondance des espèces.

Le `F-test` est à peine significatif ce qui indique que le modèle n'est que légèrement meilleur qu'un modèle sans variables prédictives.

Finallement, la taille d'effet estimé (le coefficient) du paramètre `logMass` est très près de zéro et n'est que marginallement significatif, c'est-à-dire qu'une augmentation ou une diminution de la masse des espèces n'entraine quasiment pas de changement dans leur abondance. 

Les résultats ne sont pas à la hauteur de ce que nous aimerions, peut-être devrions-nous formuler une hypothèse plus précise ?

### Trouver un meilleur modèle: oiseaux terrestres

Formulons une nouvelle hypothèse plus précise. Cette fois, concentrons-nous seulement sur les oiseaux terrestres. L'abondance des oiseaux aquatiques ne répond peut être pas de la même façon à la masse que les oiseaux terrestres.

**Nouvel hypothèse**

>  Pour différentes espèces d'oiseaux <span style="color:green">**terrestres**</span>, la **masse moyenne d'un individu a un effet sur l'abondance maximale** de l'espèce, en raison de contraintes écologiques (sources de nourriture, disponibilité de l'habitat, etc.).

Nous pouvons maintenant ajuster le modèle linéaire pour exclure les oiseaux aquatiques. Il suffit  :

```{r}
# Modèle linéaire avec oiseaux terrestres
lm3 <- lm(logMaxAbund~logMass, data=bird, subset=!bird$Aquatic)
# exclut les oiseaux aquatiques (!birdsAquatic == TRUE)
# ou de façon équivalente :
# lm3 <- lm(logMaxAbund~logMass, data=bird, subset=bird$Aquatic == 0)

# Sortie du modèle
lm3
```

Et vérifions les conditions d'application du modèle :

```{r, eval=FALSE, fig.height=5.5, fig.width=7.5}
par(mfrow=c(2,2))
plot(lm3)
```

```{r, echo=FALSE, fig.height=5.5, fig.width=7.5}
par(mfrow=c(2,2), mar = c(4,4,2,1.1), oma =c(0,0,0,0))
plot(lm3)
```

Au vu des graphiques diagnostiques, nous pouvons conclure qu les conditions d'application sont respectées !

Finalement, le modèle fournit des **preuves à l'appui** de notre hypothèse :

```{r, comment=""}
summary(lm3)
```

Le `R au carré ajusté` est de 0,25, ce qui indique que le modèle est raisonnablement bien ajusté aux données. Le modèle est bien meilleur qu'un modèle sans variables prédictives. Le `F-test` est significatif (< 0.05). Le `T-test` montre que l'estimation du paramètre "logMass" est clairement différente de 0 (*t-test*) et que la masse a un effet sur l'abondance des espèces.

------------------------------------------------------------------------

## Défi 2

Pour le deuxième défi, rassemblons toutes les étapes et essayons avec de nouvelles données :

1. Formuler une autre hypothèse similaire sur l'abondance maximale et la masse moyenne d'un individu, cette fois pour les **passereaux** ("passerine birds").
2. Ajuster un **modèle** pour évaluer cette hypothèse, en utilisant les variables transformées (c'est-à-dire `logMaxAbund` et `logMass`). Sauvegarder le modèle sous le nom de `lm4`.
3. **Vérifier les conditions d'application** du modèle linéaire à l'aide des graphiques diagnostics.
4. Interpréter les résultats : Le modèle fournit-il des **preuves à l'appui de l'hypothèse ?**

> Indice : Comme les espèces aquatiques, les passereaux (variable `Passerine` sont codées 0/1 (vérifier avec `str(bird)`)

### Solutions

**Hypothèse**

> Pour différentes espèces de <span style="color:green">**passereaux**</span>, la **masse moyenne d'un individu a un effet sur l'abondance maximale** de l'espèce, en raison de contraintes écologiques (sources de nourriture, disponibilité de l'habitat, etc.).

**Ajuster le modèle**

```{r}
lm4 <- lm(logMaxAbund ~ logMass, data=bird, subset=bird$Passerine == 1)
lm4
```

**Vérifier les conditions d'application**

```{r, eval=FALSE}
par(mfrow=c(2,2))
plot(lm4)
```

```{r,fig.height=6, fig.width=8, echo=FALSE}
par(mfrow=c(2,2), mar = c(4,4,2,1.1), oma =c(0,0,0,0))
plot(lm4)
```

**Vaut-il la peine d'interpréter les résultats ?**

```{r, comment=""}
summary(lm4)
```

Les résultats du modèle ne doivent pas être interprétés car les conditions d'application du modèle linéaire ne sont pas respectées!

## Régression linéaire avec R

------------------------------------------------------------------------

Effectuer une régression linéaire avec R se découpe en trois étapes:

1. Formuler et exécuter un modèle linéaire basé sur un hypothèse
2. Vérifier les conditions d'application du modèle linéaire
3. Examiner la sortie du modèle et si les conditions sont respectées
    * Analyser les paramètres de régression
    * Tracer le modèle
    * Effectuer des tests de signification sur les estimations des paramètres (si nécessaire)

Nous allons explorer chaque étape dans les sections suivantes.

Aussi, dans le cas ou les conditions ne sont pas respectées, nous verrons qu'il est possible d'envisager l'utilisation d'un *Modèle linéaire généralisé* (GLM) ou la transformation des données.

## Noms de variables

------------------------------------------------------------------------

Des termes différents sont utilisés pour la *réponse* et le *prédicteur*, en fonction du contexte et du domaine scientifique. Les termes ne sont pas toujours synonymes. Voici deux tableaux pour vous éclairer sur le jargon que vous rencontrerez.

|résponse          | prédicteur       |
|:-----------------|:-----------------|
|var. expliqué     |var. explicatif   |
|                  |covariable        |
|var. endogène     |var. exogène      |
|var. dépendante   |var. indépendante |

|response          | predictor        |
|:-----------------|:-----------------|
|                  |explanatory var.  |
|                  |covariate         |
|outcome           |                  |
|output var.       |input var.        |
|dependent var.    |independent var.  |


