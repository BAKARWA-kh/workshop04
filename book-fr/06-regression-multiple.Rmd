# Régression multiple

Une régression multiple teste les effets de plusieurs variables
explicatives continues sur une variable réponse continue.

### 7.1 Conditions de base

En plus des conditions de base habituelles des modèles linéaires, il est
important de tester pour **l'orthogonalité** parce que ceci influence
l'interprétation du modèle. Les variables sont orthogonales quand les
variables explicatives sont colinéaires. Si une variable explicative est
corrélée avec une autre variable, elles expliquent probablement la même
variabilité dans la variable réponse, et l'effet d'une variable sera
caché par l'autre.S'il existe une relation entre deux variables
explicatives, elles sont donc **colinéaires**.

La colinéarité doit être évitée, car il ne sera pas possible de
distinguer les effets propres à chaque variable. Voici quelques
solutions possibles :

1.  Gardez seulement **une** des variables colinéaires,
2.  Essayez une analyse multidimensionelle *[(voir
    l'atelier 9)](http://qcbs.ca/wiki/r_atelier9)*,
3.  Essayez une analyse pseudo-orthogonale.

La colinéarité entre variables explicatives peut être vérifiée à l'aide
du **facteur d'inflation de la variance** (VIF ou *\"variance inflation
factor\"*) en utilisant la fonction `vif` du paquet `HH`.

```{r, echo = TRUE, eval = FALSE}
vif(clDD ~ clFD + clTmi + clTma + clP + grass, data=Dickcissel)
```

qui produit la sortie suivante:

      clFD        clTmi       clTma           clP         grass
     13.605855    9.566169    4.811837    3.196599    1.165775

Les variables colinéaires ont un VIF plus grand que 5. La sortie R
montre alors que *clDD*, *clFD*, et *clTmi* sont fortement colinéaires.
Seulement une de ces variables explicatives peut être retenue dans le
modèle de régression final.

### 7.2 Jeu de données Dickcissel

Le jeu de données Dickcissel (du nom d'un petit oiseau granivore de la
famille des Cardinalidae) explore les effets de plusieurs variables
environnementales qui pourraient expliquer l'abondance et la présence
d'une espèce d'oiseau des prairies nord-américaines avec des pics
d'abondance au Kansas, É-U. Le jeu de données contient 15 variables :

  ----------------------------------------------------------------------------------------------------------------------------
  Nom de la variable                Description                                            Type
  --------------------------------- ------------------------------------------------------ -----------------------------------
  abund                             Le nombre d'individus\                                Continu/ numérique
                                    observé sur chaque route                               

  Present                           Présence/ absence\                                     Binaire (\"Présent\"/ \"Absent\")
                                    de l'espèce                                           

  broadleaf, conif, crop, grass,\   Variables du paysage à moins de 20 km de rayon\        Continu/ numérique
  shrub, urban, wetland             du centre de la route                                  

  NDVI                              Indice de végétation (une mesure de la productivité)   Nombre entier

  clDD, clFD, clTma, clTmi, clP     Données climatiques (DD = degrés jours,\               Continu/ numérique
                                    FD = jours de gel, Tma = température max,\             
                                    Tmi = température min,\                                
                                    P = précipitation)                                     
  ----------------------------------------------------------------------------------------------------------------------------

Dans R, une régression multiple est effectuée à l'aide de la fonction
`lm()` et les résultats peuvent être visualisés avec la fonction
`summary()`. En utilisant le jeu de données Dickcissel, on peut tester
les effets du *climat*, de la *productivité* et du *paysage* sur
l'*abondance* du Dickcissel à l'aide d'un modèle de régression
multiple.

------------------------------------------------------------------------

**DÉFI 5**

Est-il nécessaire de transformer la variable réponse *abund* ?

++++ Défi 5: Solution\|

```{r, echo = TRUE, eval = FALSE}
hist(Dickcissel$abund, main="", xlab="Dickcissel abundance")
shapiro.test(Dickcissel$abund)
skewness(Dickcissel$abund)
summary(Dickcissel$abund)
```

Il y a plusieurs zéros dans la distribution de la variable *abund*. On
peut ajouter une constante avant d'effectuer une transformation
logarithmique, étant donnée la forte asymétrie de la distribution :

```{r, echo = TRUE, eval = FALSE}
hist(log10(Dickcissel$abund+0.1), =main="", xlab=expression("log"[10]*"(Dickcissel Abundance + 0.1)"))
shapiro.test(log10(Dickcissel$abund+0.1))
skewness(log10(Dickcissel$abund+0.1))
```

La variable n'est toujours pas distribuée normalement après la
transformation.

++++

------------------------------------------------------------------------

Dans le défi 5, vous avez probablement remarqué que la variable réponse
*abund* n'a pas pu être normalisée. Il faudrait alors peut-être laisser
tomber la supposition de normalité et passer à un [modèle linéaire
généralisé](http://qcbs.ca/wiki/r_atelier7), mais ceci ira à plus tard !

Pour l'instant, nous allons utiliser la variable *abund*
non-transformée et comparer l'importance relative de trois variables
explicatives (*climat*, *productivité* et *paysage*) sur l'*abondance*.

```{r, echo = TRUE, eval = FALSE}
lm.mult <- lm(abund ~ clTma + NDVI + grass, data=Dickcissel)
summary(lm.mult)
```

La sortie de R indique quelles variables explicatives sont
significatives :

    lm(formula = abund ~ clTma + NDVI + grass, data = Dickcissel)
    Residuals:
     Min          1Q          Median          3Q           Max
    -35.327   -11.029     -4.337      2.150       180.725
    Coefficients:
                  Estimate    Std. Error  t value     Pr(>|t|)
    (Intercept)   -83.60813       11.57745    -7.222      1.46e-12 ***
    clTma         3.27299     0.40677     8.046       4.14e-15 ***
    NDVI          0.13716     0.05486     2.500       0.0127 *
    grass         10.41435        4.68962     2.221       0.0267 *
    ---
    Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1
    Residual standard error: 22.58 on 642 degrees of freedom
    Multiple R-squared:  0.117,     Adjusted R-squared:  0.1128
    F-statistic: 28.35 on 3 and 642 DF,  p-value: < 2.2e-16

Dans ce cas-ci, les trois variables explicatives ont une influence
significative sur l'abondance de Dickcissel, la plus significative
étant le climat (p = 4.14e-15). Ces trois variables expliquent 11.28% de
la variabilité de l'abondance de Dickcissel (R carré ajusté = 0.1128).
Le modèle global est également significatif et explique la variabilité
de l'abondance de Dickcissel mieux qu'un modèle nul (p \< 2.2e-16).

Un graphique de la variable réponse en fonction de chaque variable
explicative peut être utilisé pour représenter les résultats du modèle :

```{r, echo = TRUE, eval = FALSE}
plot(abund ~ clTma, data=Dickcissel, pch=19, col="orange")
plot(abund ~ NDVI, data=Dickcissel, pch=19, col="skyblue")
plot(abund ~ grass, data=Dickcissel, pch=19, col="green")
```

![](images/lm_fig 13.png){width="850"}

### Allons plus loin: Régression polynomiale

 Les relations entre variables réponses et variables
explicatives ne sont pas toujours linéaires. Dans ce cas, une régression
linéaire, qui correspond à une droite reliant deux variables, est
incapable de représenter la relation entre ces deux variables. Une
régression polynomiale permet de tracer une courbe polynomiale entre la
variable réponse et la variable explicative, et permet de représenter
une relation non linéaire basée sur le modèle mathématique suivant :

$ {y_i} = {β_0} + {β_1}{x_i} +
{β_2}![](images/x_i}^2} + {β_3}{{x_i}^3} + {ε_i} </m> pour un polynôme de degré 3\\
<m> {y_i} = {β_0} + {β_1}{x_i} + {β_2}{{x_i}^2} + {ε_i} </m> pour un polynôme de degré 2

où

β<sub>0</sub> est l'ordonnée à l'origine de la droite de régression,\\
β<sub>1</sub> est l'effet de la variable x,\\
β<sub>2</sub> est l'effet de la variable x au carré (x<sup>2</sup>),\\
β<sub>3</sub> est l'effet de la variable x au cube (x<sup>3</sup>),\\
ε<sub>i</sub> sont les résidus du modèle (i.e. la variation inexpliquée).

Le degré du polynôme est l'exposant le plus élevé de l'équation. En connaissant le degré du polynôme, on peut le qualifier /

{{/polynomial_degree.png){width="250"}

Dans R, ces modèles sont effectués avec la fonction `lm()` et peuvent
être comparés entre eux avec la fonction `anova()` :

```{r, echo = TRUE, eval = FALSE}
lm.linear <- lm(abund ~ clDD, data=Dickcissel)
lm.quad <- lm(abund ~ clDD + I(clDD^2), data=Dickcissel)
lm.cubic <- lm(abund ~ clDD + I(clDD^2) + I(clDD^3), data=Dickcissel)
```

------------------------------------------------------------------------

**DÉFI 7**

Comparez les différents modèles polynomiaux de l'exemple précédent et
déterminez quel modèle est le plus approprié. Extrayez le R carré
ajusté, les coefficients de régression et les valeurs de p de ce modèle.

++++ Défi 7: Solution\|

```{r, echo = TRUE, eval = FALSE}
anova(lm.linear,lm.quad,lm.cubic) # fait la liste des modèles par ordre croissant de complexité.
# On accepte le modèle se trouvant sur la ligne la plus basse avec une valeur de p significative.
# i.e. le modèle lm.quad

# Examinons le résumé du modèle
summary(lm.quad)
# Les coefficients de régression
summary(lm.quad)$coefficients[,1]
# Estimation des valeurs de p
summary(lm.quad)$coefficients[,4]
# Le R carré ajusté
summary(lm.quad)$adj.r.squared
```

++++

------------------------------------------------------------------------

La comparaison de modèles du défi 7 a montré que la régression
quadratique (i.e. polynomiale de degré 2) était le meilleur modèle. Le
polynôme de degré trois peut être retiré du modèle final :

    Analysis of Variance Table
    Model 1: abund ~ clDD
    Model 2: abund ~ clDD + I(clDD^2)
    Model 3: abund ~ clDD + I(clDD^2) + I(clDD^3)
    Model     Res.Df      RSS             Df  Sum of Sq        F          Pr(>F)
    1         644     365039
    2         643     355871      1       9168.3      16.5457         5.34e-05 ***
    3         642     355743      1       127.7       0.2304      0.6314

La sortie de R pour le modèle final est :

    Call: lm(formula = abund ~ clDD + I(clDD^2), data = Dickcissel)
    Residuals:
        Min           1Q          Median          3Q          Max
       -14.057        -12.253     -8.674      1.495       190.129
    Coefficients:
                  Estimate    Std. Error  t value     Pr(>|t|)
    (Intercept)   -1.968e+01      5.954e+00   -3.306      0.001 **
    clDD          1.297e-02   2.788e-03       4.651       4.00e-06 ***
    I(clDD^2)     -1.246e-06      3.061e-07   -4.070      5.28e-05 ***
    ---
    Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1
    Residual standard error: 23.53 on 643 degrees of freedom
    Multiple R-squared:  0.04018,   Adjusted R-squared:  0.0372
    F-statistic: 13.46 on 2 and 643 DF,  p-value: 1.876e-06

Dans cet exemple, le terme linéaire influence plus la variable réponse
que le terme quadratique, car leurs valeurs de p sont 4.00e-06 et
5.28e-05 respectivement. Ces deux termes expliquent 3.72% de la
variabilité de l'abondance (R carré ajusté), ce qui est très peu.


### 7.4 Régression pas à pas

 Afin d'obtenir un modèle de régression multiple \"optimal\",
on peut commencer avec un modèle qui inclut toutes les variables
explicatives et retirer les variables non significatives, procédant donc
à une **sélection pas à pas**. Les variables non significatives sont
retirées une à la fois et l'ajustement de chaque modèle successif est
évalué à l'aide de l'AIC [(Critère d'information
d'Akaike)](http://fr.wikipedia.org/wiki/Crit%C3%A8re_d%27information_d%27Akaike),
jusqu'à ce que toutes les variables explicatives soient significatives.
Prenez note qu'une valeur plus basse d'AIC indique un meilleur
ajustement (i.e. le meilleur modèle est celui avec la valeur d'AIC la
plus basse). Dans R, la sélection pas à pas est effectuée à l'aide de
la fonction `step()` :

```{r, echo = TRUE, eval = FALSE}
lm.full <- lm(abund ~ . - Present, data=Dickcissel)
lm.step <- step(lm.full)
summary(lm.step)
```

Les résultats indiquent que seulement 6 variables sont significatives
parmi les 13 variables de départ :

     Call:    lm(formula = abund ~ clDD + clFD + clTmi + clTma + clP + grass,  data = Dickcissel)
     Residuals:
      Min         1Q          Median          3Q          Max
      -30.913     -9.640      -3.070      4.217       172.133
    Coefficients:
                  Estimate    Std. Error  t value     Pr(>|t|)
    (Intercept)   -4.457e+02      3.464e+01   -12.868     < 2e-16 ***
    clDD          5.534e-02   8.795e-03       6.292       5.83e-10 ***
    clFD          1.090e+00   1.690e-01       6.452       2.19e-10 ***
    clTmi         -6.717e+00      7.192e-01   -9.339      < 2e-16 ***
    clTma         3.172e+00   1.288e+00       2.463       0.014030 *
    clP           1.562e-01   4.707e-02       3.318       0.000959 ***
    grass         1.066e+01   4.280e+00       2.490       0.013027 *
    ---
    Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1
    Residual standard error: 19.85 on 639 degrees of freedom
    Multiple R-squared:  0.3207,    Adjusted R-squared:  0.3144
    F-statistic: 50.29 on 6 and 639 DF,  p-value: < 2.2e-16

Le modèle explique maintenant 31.44% de la variabilité de l'abondance.
La variable explicative la plus significative est clTmi.\
Cependant, certaines des variables explicatives sont corrélées entre
elles et devraient être retirées du modèle final afin de ne pas inclure
de variables qui n'apportent pas d'information nouvelle. 

## Allons plus loin: Partition de la variation

 Afin d'évaluer la contribution relative de deux ou plusieurs
variables explicatives à la variabilité d'une variable réponse, on peut
utiliser la fonction `varpart()` de la librairie \"vegan\". Cette
fonction permet de subdiviser la variation expliquée de la réponse
variable entre différents groupes de variables explicatives. Par
exemple, dans le jeu de données Dickcissel, on peut évaluer les
contributions relatives des données climatiques et du paysage de la
manière suivante :

```{r, echo = TRUE, eval = FALSE}
part.lm = varpart(Dickcissel$abund, Dickcissel[,c("clDD", "clFD", "clTmi", "clTma", "clP")],
                  Dickcissel[,c("broadleaf", "conif", "grass", "crop", "urban", "wetland")])
part.lm
```

La sortie de R permet de visualiser la partition de la variation :

    Partition of variation in RDA
    Call: varpart(Y = Dickcissel$abund, X = Dickcissel[, c("clDD", "clFD", "clTmi", "clTma", "clP")],
    Dickcissel[, c("broadleaf", "conif", "grass", "crop", "urban", "wetland")])
    Explanatory tables:
    X1:  Dickcissel[, c("clDD", "clFD", "clTmi", "clTma", "clP")]
    X2:  Dickcissel[, c("broadleaf", "conif", "grass", "crop", "urban", "wetland")]
    No. of explanatory tables: 2
    Total variation (SS): 370770
    Variance: 574.84
    No. of observations: 646
    Partition table:
                         Df       R.squared       Adj.R.squared        Testable
    [a+b] = X1           5        0.31414         0.30878              TRUE
    [b+c] = X2           6        0.03654         0.02749              TRUE
    [a+b+c] = X1+X2      11       0.32378         0.31205              TRUE
    Individual fractions
    [a] = X1|X2          5                        0.28456              TRUE
    [b]                  0                        0.02423              FALSE
    [c] = X2|X1          6                        0.00327              TRUE
    [d] = Residuals                               0.68795              FALSE
    ---

Utilisez la fonction `rda` pour tester si les différentes fractions sont
significatives.

Cette sortie R montre que les deux groupes de variables explicatives
expliquent 31.205% (\[a+b+c\] = X1+X2) de la variation de l'abondance
de Dickcissel alors que les variables du climat expliquent à elles
seules 28.46% de la variation (\[a\] = X1\|X2) et les variables du
paysage ne contribuent qu'à expliquer 0.33% de la variation de
l'abondance de Dickcissel (\[c\] = X2\|X1). L'interaction entre les
deux groupes de variables expliquent 2.42% (\[b\]) de la variation.

Pour tester si chaque fraction est significative, il est possible
d'utiliser la RDA partielle et un test par permutation avec les
fonctions `rda()` et `anova()` :

```{r, echo = TRUE, eval = FALSE}
# Variables climatiques
out.1 = rda(Dickcissel$abund, Dickcissel[,c("clDD", "clFD", "clTmi", "clTma", "clP")],
            Dickcissel[,c("broadleaf", "conif", "grass", "crop", "urban", "wetland")])
anova(out.1, step=1000, perm.max=1000)

# Variables du paysage
out.2 = rda(Dickcissel$abund, Dickcissel[,c("broadleaf", "conif", "grass", "crop", "urban", "wetland")],
        Dickcissel[,c("clDD", "clFD", "clTmi", "clTma", "clP")])
anova(out.2, step=1000, perm.max=1000)
```

la sortie R :

    Variables climatiques
    Permutation test for rda under reduced model
    Model: rda(X = Dickcissel$abund, Y = Dickcissel[, c("clDD", "clFD", "clTmi", "clTma", "clP")],
           Z = Dickcissel[, c("broadleaf", "conif", "grass", "crop", "urban", "wetland")])
              Df      Var      F     N.Perm   Pr(>F)
    Model         5   165.12   53.862    999      0.001 ***
    Residual  634     388.72

    Variables du paysage
    Permutation test for rda under reduced model
    Model: rda(X = Dickcissel$abund, Y=Dickcissel[, c("broadleaf", "conif", "grass", "crop", "urban", "wetland")],
            Z = Dickcissel[, c("clDD", "clFD", "clTmi", "clTma", "clP")])
              Df      Var      F     N.Perm   Pr(>F)
    Model         6       5.54     1.5063    999      0.152
    Residual  634     388.72

Dans ce cas, la fraction de la variation expliquée par les variables du
climat est significative (p-value=0.001) alors que la fraction expliquée
par les variables du paysage ne l'est pas (p-value=0.152).

Les résultats du partitionnement de la variation sont généralement
représentés graphiquement par un diagramme de Venn dans lequel chaque
groupe de variables explicatives est représenté par un cercle. La
fraction de la variation expliquée est indiquée à l'intérieur des
cercles.

```{r, echo = TRUE, eval = FALSE}
showvarparts(2)
plot(part.lm,digits=2, bg=rgb(48,225,210,80,maxColorValue=225), col="turquoise4")
```

![](images//varpart.png){width="300"}