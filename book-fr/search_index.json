[["index.html", "Atelier 4: Modèles linéaires Série d’ateliers R du CSBQ Préface 0.1 Code de conduite 0.2 Contributeurs et contributrices 0.3 Contribuez à la série!", " Atelier 4: Modèles linéaires Série d’ateliers R du CSBQ Développé et entretenu par les contributeurs et les contributrices de la Série d’ateliers R du CSBQ1. 2023-01-12 20:46:30 Préface La Série d’ateliers R du CSBQ est une série de 10 ateliers qui guide les participants à travers les étapes nécessaires à l’utilisation de R pour un large éventail d’analyses statistiques pertinentes pour la recherche en biologie et en écologie. Ces ateliers en accès libre ont été créés par des membres du CSBQ, à la fois pour les membres du CSBQ et pour la communauté au sens large. Le contenu de cet atelier a été revu par plusieurs membres du CSBQ. Si vous souhaitez suggérer des modifications, veuillez contacter les coordinateurs de la série actuelle, dont la liste figure sur la page principale de Github 0.1 Code de conduite La Série d’ateliers R du CSBQ et le Symposium R du CSBQ sont des lieux dédiés à fournir un environnement accueillant et favorable à toutes les personnes, indépendamment de leurs origines ou de leur identité. Les participants, les présentateurs et les organisateurs de la série d’ateliers et d’autres activités connexes acceptent le présent code de conduite lorsqu’ils assistent à des activités liées aux ateliers. Nous ne tolérons pas les comportements irrespectueux ou qui excluent, intimident ou gênent les autres. Nous ne tolérons pas la discrimination ou le harcèlement fondés sur des caractéristiques telles que, mais sans s’y limiter, l’identité et l’expression du genre, l’orientation sexuelle, le handicap, l’apparence physique, la taille du corps, la citoyenneté, la nationalité, les origines ethniques ou sociales, la grossesse, le statut familial, les informations génétiques, la religion ou les convictions (ou l’absence de celles-ci), l’appartenance à une minorité nationale, la propriété, l’âge, l’éducation, le statut socio-économique, les choix techniques et le niveau d’expérience. Il s’applique à tous les espaces gérés par l’atelier ou affiliés à celui-ci, y compris, mais sans s’y limiter, les ateliers, les listes de diffusion et les forums en ligne tels que GitHub, Slack et Twitter. 0.1.1 Comportement attendu Tous les participants sont tenus de faire preuve de respect et de courtoisie envers les autres. Toutes les interactions doivent être professionnelles, quelle que soit la plateforme utilisée : en ligne ou en personne. Afin de favoriser un environnement d’apprentissage positif et professionnel, nous encourageons les types de comportements suivants dans tous les événements et plates-formes des ateliers : Utiliser un langage accueillant et inclusif ; Respecter les différents points de vue et expériences ; Accepter avec grâce les critiques constructives ; Se concentrer sur ce qui est le mieux pour la communauté ; Faire preuve de courtoisie et de respect envers les autres membres de la communauté. 0.1.2 Comportements inacceptables Voici quelques exemples de comportements inacceptables de la part des participants à tout événement ou plateforme d’atelier : les commentaires écrits ou verbaux qui ont pour effet d’exclure des personnes sur la base de leur appartenance à un groupe spécifique ; faire craindre à quelqu’un pour sa sécurité, par exemple en le harcelant ou en l’intimidant ; des menaces ou des propos violents dirigés contre une autre personne ; l’affichage d’images sexuelles ou violentes ; l’attention sexuelle non désirée ; les contacts physiques non consensuels ou non désirés ; des insultes ou des rabais ; les blagues sexistes, racistes, homophobes, transphobes, incapables ou d’exclusion ; l’incitation à la violence, au suicide ou à l’automutilation ; la poursuite de l’interaction (y compris la photographie ou l’enregistrement) avec une personne après qu’on - lui a demandé d’arrêter ; la publication d’une communication privée sans consentement. 0.2 Contributeurs et contributrices Cet atelier a été développé à l’origine par Catherine Baltazar, Bérenger Bourgeois, Zofia Taranu, et Shaun Turney. Depuis 2014, plusieurs membres du CSBQ ont contribué à développer et à mettre à jour cet atelier collaborativement sur une base régulière, dans le cadre du Prix d’apprentissage et de développement du Centre de science de la biodiversité du Québec. Ces membres sont: 2022 - 2021 - 2020 2019 - 2018 - 2017 2016 - 2015 - 2014 Victor Cameron Willian Vieira Catherine Baltazar Laurie Maynard Shaun Turney Bérenger Bourgeois Daniel Schoenig Marie-Hélène Brice Zofia Taranu Katherine Hébert Shaun Turney Emmanuelle Chrétien Maxwell Farrell Vincent Fugère 0.3 Contribuez à la série! En construction. La Série d’ateliers R du CSBQ fait partie du Centre de la science de la biodiversité du Québec, et est maintenue par les coordonnateurs et les coordonnatrices de la série, et les membres étudiants diplômés, postdoctoraux et professionnels de la recherche. La liste des contributeurs et des contributrices de cet atelier sont accessiblesici↩︎ "],["objectifs-dapprentissage.html", "Chapitre 1 Objectifs d’apprentissage", " Chapitre 1 Objectifs d’apprentissage Résumé : Dans cet atelier, vous apprendrez la structure d’un modèle linéaire et ses différentes variantes telles que la régression simple, l’analyse de variance (ANOVA), l’analyse de covariance (ANCOVA) et la régression multiple. Cet atelier se concentre sur l’application de modèles linéaires dans R avec lm() et anova(), sur l’identification de modèles dont les conditions d’application ne sont pas rencontrées et sur régler les problèmes. "],["préparez-vous-pour-cet-atelier.html", "Chapitre 2 Préparez-vous pour cet atelier", " Chapitre 2 Préparez-vous pour cet atelier Tout le matériel de l’atelier se trouve sur github.com/QCBSRworkshops/workshop04. Cela inclut un script R qui rassemble tous les morceaux de code présentés dans ce livre. Pour cet atelier, nous travaillerons avec les jeux de données suivants : birdsdiet dickcissel Pour télécharger ces données, faites un clic droit + enregistrer sur la page qui s’ouvre. Vous devriez également vous assurer d’avoir téléchargé, installé et chargé les librairies R suivantes: dplyr (pour travailler avec les données) vegan (pour l’analyse de données populationnelles) e1071 (pour tester les modèles) MASS (pour l’analyse discriminante linéaire) car (pour l’analyse de variance) effects (pour la visualisation de modèles) Pour les installer du CRAN, roulez: # Installez les librairies requises install.packages(&quot;dplyr&quot;) install.packages(&quot;vegan&quot;) install.packages(&quot;e1071&quot;) install.packages(&quot;MASS&quot;) install.packages(&quot;car&quot;) install.packages(&quot;effects&quot;) Pour charger les librairies, roulez: # Load the required packages library(dplyr) library(vegan) library(e1071) library(MASS) library(car) library(effects) "],["le-modèle-linéaire.html", "Chapitre 3 Le modèle linéaire 3.1 Qu’est-ce qu’un modèle linéaire ? 3.2 Formulation d’un modèle linéaire 3.3 Évaluation du modèle linéaire 3.4 Conditions d’application du modèle linéaire 3.5 Notation des modèles linéaires 3.6 Effectuer un modèle linéaire 3.7 Modèles linéaires", " Chapitre 3 Le modèle linéaire Les ateliers précédents ont exploré l’utilisation de R pour manipuler et représenter des données. Cependant, on s’intéresse souvent en science à déterminer les relations entre des variables. Cet atelier bâti sur les connaissances acquises préalablement et s’intéresse à la régression linéaire comme premier pas dans l’univers de l’analyse statistique. Objectifs d’apprentissage Apprendre la structure d’un modèle linéaire et ses différentes variantes. Apprendre comment faire un modèle linéaire dans R avec lm() et anova() Apprendre comment identifier un modèle dont les conditions d’application ne sont pas satisfaites et comment régler le problème. 3.1 Qu’est-ce qu’un modèle linéaire ? Le modèle linéaire décrit la relation entre une variable réponse et une ou plusieurs autres variables prédictrices. Elle est utilisée pour analyser une hypothèse bien formulée, souvent associée à une question de recherche plus générale. La régression détermine si les variables sont corrélées en inférant la direction et la force d’une relation, et notre confiance dans les estimations de l’effet. Un travail scientifique important est nécessaire pour formuler un modèle linéaire. Puisque le modèle analyse une hypothèse, il est recommandé de formuler clairement les attentes concernant la direction et la force d’une relation en tant que prédictions avant d’effectuer un modèle linéaire. 3.1.1 Exemple : Abondance et masse des espèces d’oiseaux Hypothèse Pour différentes espèces d’oiseaux, la masse moyenne d’un individu a un effet sur l’abondance maximale de l’espèce, en raison de contraintes écologiques (sources de nourriture, disponibilité de l’habitat, etc.). Prédiction Les espèces caractérisées par des individus plus grands ont une abondance maximale plus faible. Nous hypothétisons donc que les oiseaux caractérisés par une masse plus importante ont besoin de plus de nourriture et d’espace : la variable réponse est l’abondance maximale, et le prédicteur le poids moyen d’un individu. En fonction de notre prédiction, nous pouvons nous attendre à ce que la direction de la relation entre la variable réponse et le prédicteur soit inverse ou ‘négative’, de façon à ce qu’une masse plus élevée entraîne une abondance plus faible. Cependant, nous ne pouvons pas formuler d’attentes sur la force de la relation ! Les données L’exemple suivant explore le jeu de données “birdsdiet” : # Importez le jeu de données &#39;bidsdiet&#39; et le sauver dans # l&#39;objet &#39;bird&#39; bird &lt;- read.csv(&quot;data/birdsdiet.csv&quot;, stringsAsFactors = TRUE) Le jeu de données bird contient sept variables : # Explorez les variables du jeu de données &#39;bird&#39; str(bird) ## &#39;data.frame&#39;: 54 obs. of 7 variables: ## $ Family : Factor w/ 53 levels &quot;Anhingas&quot;,&quot;Auks&amp; Puffins&quot;,..: 18 25 23 21 2 10 1 44 24 19 ... ## $ MaxAbund : num 2.99 37.8 241.4 4.4 4.53 ... ## $ AvgAbund : num 0.674 4.04 23.105 0.595 2.963 ... ## $ Mass : num 716 5.3 35.8 119.4 315.5 ... ## $ Diet : Factor w/ 5 levels &quot;Insect&quot;,&quot;InsectVert&quot;,..: 5 1 4 5 2 4 5 1 1 5 ... ## $ Passerine: int 0 1 1 0 0 0 0 0 0 0 ... ## $ Aquatic : int 0 0 0 0 1 1 1 0 1 1 ... Notez que Family, Diet, Passerine, et Aquatic sont toutes des variables catégoriques, malgré le fait qu’ils soient encodés de façons différentes (chaîne de caractères, catégorique, binaire). Les variables d’intérêt au test de l’hypothèse sont : “MaxAbund” : La plus grande abondance observée sur un site en Amérique du Nord (continu / numérique) “Masse” : La taille du corps moyenne en grammes (continue / numérique) Concepts de base Il existe deux concepts clés pour comprendre les modèles linéaires: la localisation et la variation. Attention! Ces concepts sont centraux à la compréhension des autres concepts présentés dans l’atelier. La localisation est une mesure de tendance centrale d’une population. Elle peut être mesurée entre autres avec la moyenne arithmétique \\(\\bar{x} = \\frac{1}{n} \\sum_{i=1}^{n} x_{i}\\) : # Moyenne de l&#39;abondance maximale observée mean(bird$MaxAbund) ## [1] 44.90577 ou la médiane : # Médiane de l&#39;abondance maximale observée median(bird$MaxAbund) ## [1] 24.14682 Par contre, la moyenne ne peut pas caractériser une population au complet. Nous pouvons donc aussi décrire une population à l’aide de mesures de variation. La variation est la dispersion (ou l’écart) des observations autour de la moyenne. Elle se mesure avec la variance \\(\\sigma^2 = \\frac{1}{n} \\sum_{i=1}^{n} {(x_{i} - \\bar{x})}^2\\). La variance est la somme de l’écart élevée au carré entre chaque valeur et la moyenne. L’élévation de l’écart au carré permet de transformer les valeurs en valeurs positives sans utiliser de valeurs absolues. # Variance de l&#39;abondance maximale observée var(bird$MaxAbund) ## [1] 5397.675 Par contre, en élevant toutes les valeurs au carré, on change les unités de nos variables. Dans cet exemple, la variance est donnée en abondance^2, une unité qui n’est plus pertinente pour notre question initiale. Pour transformer ces valeurs en unités appropriées, nous pouvons calculer l’écart type \\(\\sigma\\). # Écart type de l&#39;abondance maximale observée sd(bird$MaxAbund) ## [1] 73.46887 Exploration visuelle La figure suivante trace la variable réponse en fonction du prédicteur : # Tracer la réponse en fonction du prédicteur plot(bird$Mass, bird$MaxAbund) Cette figure présente la variation de l’abondance maximale en fonction de la masse de l’oiseau. Nons sommes intéressés à quantifier cette relation. Autrement dit, nous sommes intéressés à quantifier l’effet de la masse des espèces d’oiseaux sur leur abondance maximale. Cependant, comment trouver la “meilleure” estimation de la relation ? La “meilleure” estimation est la ligne qui minimise la somme des carrés. Cela se clarifiera dans les prochaines sections. Notez que la “meilleure” estimation peut également être l’absence de relation, similaire à la ligne bleue dans la figure. 3.2 Formulation d’un modèle linéaire Le modèle linéaire décrit la “meilleure” relation entre une variable réponse (“MaxAbund”) et une ou plusieurs prédicteurs (ici “Mass”). La variable réponse est la variable que nous voulons expliquer, ou la variable dépendante. Il n’y a qu’une variable réponse. Les variables explicatives sont des variables qui peuvent (potentiellement) expliquer la variable réponse. On peut inclure une ou plusieurs variables explicatives. Dans un modèle linéaire, nous définissons une observation de la variable réponse \\(y\\), comme étant \\(y_i\\). Dans notre exemple, cela représente une observation d’abondance maximale pour une espèce \\(i\\). Une observation correspondante du prédicteur \\(x\\) est définie comme \\(x_i\\) et représente, par exemple, le poids moyen d’un individu d’une espèce \\(i\\). Dans les modèles linéaires, on utilise les concepts de moyenne et de variation pour décrire la relation entre deux variables. Nous disons “modèles linéaires”, parce qu’ils décrivent la relation entre variables avec une droite. Cette droite représente la relation supposée: \\[ y_i = \\beta_0 + \\beta_1 \\times x_i + \\epsilon_i\\] \\(y_i\\) est la variable réponse \\(x_i\\) est le prédicteur Le paramètre \\(\\beta_0\\) est l’ordonnée à l’origine Le paramètre \\(\\beta_1\\) quantifie l’effet de \\(x\\) sur \\(y\\) Le résidu \\(\\epsilon_i\\) représent la variation non expliquée La valeur prédite de \\(y_i\\) se définit comme : \\(\\hat{y}_i = \\beta_0 + \\beta_1 \\times x_i\\) 3.3 Évaluation du modèle linéaire Le modèle linéaire évalue s’il y a une corrélation significative entre la variable réponse et la ou les variables explicatives. Ceci est fait en évaluant si la valeur moyenne de la variable réponse diffère significativement entre les différentes valeurs des variables explicatives, comme pour la variation de l’abondance maximale des oiseaux en fonction de leur masse. Pour les variables explicatives catégoriques, le modèle linéaire évalue si la valeur moyenne de la variable réponse diffère significativement entre les différents niveaux (ou groupes) des variables explicatives. Ceci deviendra plus clair en explorant les types de modèles linéaires dans les sections suivantes. Dans presque tous les cas, les variables explicatives n’expliquent pas toute la variation dans la variable réponse. La variation qui reste inexpliquée est les résidus, ou l’erreur. 3.4 Conditions d’application du modèle linéaire Le modèle linéaire est défini selon l’équation que nous avons explorée précédemment : \\[ y_i = \\beta_0 + \\beta_1 \\times x_i + \\epsilon_i\\] Pour être valides, tous les modèles linéaires s’appuient sur 4 conditions de base. Si les 4 conditions ne sont pas respectées, les résultats du modèle ne peuvent pas être interprétés de façon valable. Relation linéaire entre la réponse et le prédicteur Les résidus suivent une distribution normale avec une moyenne de \\(0\\) Les résidus sont distribués de manière identique (homoscédasticité) Les résidus sont indépendants les uns des autres Notez que ces 4 conditions concernent les résidus, et non les variables réponses ou explicatives. Cela ne veut pas dire que l’ensemble des valeurs observées \\(y\\) doivent suivre une distribution normale ! 3.4.1 Normalité des résidus Pour que les résultats d’un modèle linéaire soient valides, les résidus \\(\\epsilon\\) doivent suivre une distribution normale avec une moyenne de \\(0\\) et une variance de \\(\\sigma^2\\), de façon à ce que la majorité des résidus aient une valeur proche de 0 (i.e. l’erreur est très petite) et que leur distribution soit symétrique (i.e. la variable réponse est sous-estimée autant qu’elle est surestimée) : \\[\\epsilon_i \\sim \\mathcal{N}(0,\\,\\sigma^2)\\] Cela veut dire : Chaque obsevation \\(y_i\\) suit une distribution normale, avec moyenne \\(\\hat{y} = \\beta_0 + \\beta_1 \\times x_i\\) et variance \\(\\sigma^2\\): \\[y_i \\sim \\mathcal{N}(\\hat{y},\\,\\sigma^2)\\] 3.4.2 Homoscédasticité De la même façon, les résidus doivent être homoscédastiques. C’est-à-dire que l’erreur ne change pas beaucoup pour les différentes valeurs des variables explicatives. Tous les résidus \\(\\epsilon\\) suivent la même distribution, la variance \\(\\sigma^2\\) reste constante. 3.4.3 Indépendance des résidus Il est également essentiel que les résidus soient indépendants, c’est-à-dire qu’il n’y a pas de structure manquante dans le modèle (comme une autocorrélation spatiale ou temporelle). Autrement dit, chaque résidu \\(\\epsilon_i\\) est indépendant de tout autre résidu. 3.5 Notation des modèles linéaires Cette section vise à fournir une compréhension de base des différents types de description de modèles linéaires qu’il est possible de rencontrer. La première est la notation mathématique et la seconde la notation en R. 3.5.1 Notation mathématique La notation mathématique est la seule forme de notation appropriée pour la rédaction de manuscrits. Nous notons les observations individuelles à l’aide de l’équation de la droite telle que vue dans les sections précédentes et de l’équation pour la distribution des résidus: \\[y_i = \\beta_0 + \\beta_1 \\times x_i + \\epsilon_i \\quad \\textrm{with} \\quad \\epsilon_i \\sim \\mathcal{N}(0,\\,\\sigma^2)\\] Pour noter l’ensemble des observations, nous suivons la notation matricielle et incluons l’intercepte dans\\(\\mathbf{X}\\) et \\(\\boldsymbol{\\beta}\\)) : \\[\\mathbf{y}= \\mathbf{X}\\boldsymbol{\\beta} + \\mathbf{\\epsilon} \\quad \\textrm{with} \\quad \\epsilon_i \\sim \\mathcal{N}(0,\\,I_n\\sigma^2)\\] 3.5.2 Notation en R Il est à noter que la notation R n’est pas adéquate pour préparer une publication. En R, nous écrivons la formule du modèle comme : y ~ 1 + x Ou encore plus simplement comme : y ~ x qui inclut aussi la constante. La variable prédite est toujours placée à gauche du tilde ~alors que les variables prédictricteurs sont placées à droite. Il ne faut jamais mélanger les différents types de notation ! 3.6 Effectuer un modèle linéaire Nous avons vu qu’il est possible de définir un modèle linéaire avec cette équation : \\[ y_i = \\beta_0 + \\beta_1 \\times x_i + \\epsilon_i\\] 3.6.1 Estimation du modèle Effectuer un modèle linéaire revient à trouver les “meilleures” estimations des paramètres \\(\\beta_0,\\, \\beta_1\\). C’est ce que nous appelons faire l’estimation du modèle. Les “meilleurs” paramètres sont ceux qui minimisent la variation dans la variable réponse. La méthode la plus répandue pour minimiser la variation d’un modèle est de faire la somme des résidus au carré \\(\\sum{\\epsilon_i^2}\\). Cette méthode est appelée la méthode de moindres carrés ordinaire (MCO). 3.7 Modèles linéaires La régression linéaire se découle en multiples variantes telles que le Test de T et l’analyse de variance. Ces méthodes rendent possible la quantification de relations entre variables. "],["régression-linéaire-avec-r.html", "Chapitre 4 Régression linéaire avec R 4.1 Formulation du modèle 4.2 Régression linéaire avec R 4.3 Interprétation du modèle 4.4 Défi 2 4.5 Régression linéaire avec R 4.6 Noms de variables", " Chapitre 4 Régression linéaire avec R Dans l’exemple suivant, nous reprendrons les données d’abondance et de masse des oiseaux pour effectuer une régression linéaire en R. Basé sur l’hypothèse, nous formulons une formule qui nous permet d’exécuter le modèle et puis nous vérifions les conditions d’application de celui-ci. Nous verrons également comment interpréter la sortie du modèle et comment le représenter graphiquement. 4.1 Formulation du modèle Les données sont composées de la masse moyenne des individus d’une espèce et l’abondance de ces espèces. Nous sommes intéressés à quantifier la relation entre la masse d’un individu et l’abondance de l’espèce (ou l’effet de la masse sur l’abondance). Nous avons formulé l’hypothèse que pour différentes espèces d’oiseaux, la masse moyenne d’un individu a un effet sur l’abondance maximale de l’espèce, en raison de contraintes écologiques (sources de nourriture, disponibilité de l’habitat, etc.). 4.1.1 Équation du modèle En notation mathématique, un modèle linéaire prend la forme de l’équation d’une droite pour laquelle la variable prédite est l’abondance maximale “MaxAbund” et la variable prédicteur est la masse des individus “Mass”. \\[\\textrm{MaxAbund}_i = \\beta_0 + \\beta_1 \\times \\textrm{Mass}_i + \\epsilon_i \\;, \\quad \\epsilon_i \\sim \\mathcal{N}(0, \\sigma^2)\\] Notez que le modèle linéaire a trois variables: \\(\\beta_0\\) , \\(\\beta_1\\) et \\(\\sigma^1\\). \\(\\sigma^1\\) défini la variance des données autour du modèle et est une variable de la distribution normale qui décrit la distribution des données autour du modèle (de part et d’autre de notre droite). Formule en R Dans le langage de programmation R, l’équation est traduite par : MaxAbund ~ Mass où la variable prédite est placée à gauche du tilde et la variable prédicteur est à droite. 4.2 Régression linéaire avec R Effectuer une régression linéaire avec R se découpe en trois étapes: Formuler et exécuter un modèle linéaire basé sur un hypothèse Vérifier les conditions d’application du modèle linéaire Examiner la sortie du modèle et si les conditions sont respectées Analyser les paramètres de régression Tracer le modèle Effectuer des tests de signification sur les estimations des paramètres (si nécessaire) Nous allons explorer chaque étape dans les sections suivantes. Aussi, dans le cas ou les conditions ne sont pas respectées, nous verrons qu’il est possible d’envisager l’utilisation d’un Modèle linéaire généralisé (GLM) ou la transformation des données. 4.2.1 Étape 1. Formuler et exécuter un modèle linéaire La fonction lm() est utilisée pour ajuster un modèle linéaire, en fournissant la formule du modèle comme premier argument : # Régression linéaire de l&#39;abondance maximale en fonction # de la masse lm1 &lt;- lm(MaxAbund ~ Mass, data = bird) Avec cette ligne de code, nous définissons un nouvel objet lm1 qui contient le modèle linéaire. Nous spécifions également deux arguments dans la fonction. Le premier MaxAbund ~ Mass est la formule du modèle et le second bird définis l’objet qui contient les variables. Avant d’utiliser une nouvelle fonction dans R, vous devriez vous référer à sa page d’aide (?nomdelafonction) afin de comprendre comment utiliser la fonction ainsi que les paramètres par défaut. Regardons les estimations des paramètres : # Examen de la sortie de la régression lm1 ## ## Call: ## lm(formula = MaxAbund ~ Mass, data = bird) ## ## Coefficients: ## (Intercept) Mass ## 38.16646 0.01439 Comment les paramètres se comparent-ils à nos prédictions ? Vous remarquerez que le paramètre pour la masse est positif alors que nous avons prédit une relation négative (Les espèces caractérisées par des individus plus grands ont une abondance maximale plus faible). Cependant, pouvons-nous nous fier aux estimations? Pour en être certain, il faut vérifier les conditions d’application ! 4.2.2 Étape 2. Vérifier les conditions d’application avec les graphiques diagnostics Une méthode efficace pour vérifier le respect des conditions d’application du modèle est de procéder à un examen visuel. Quatre graphiques diagnostiques peuvent être produits d’un objet lm. Pour ce faire, nous utilisons ces commandes : # Tracer les quatres graphiques diagnostiques par(mfrow = c(2, 2)) plot(lm1) par() est une fonction qui permet de définir les paramètres du graphique. Ici, nous spécifions mfrow=c(2,2) qui permet d’afficher une grille de 2 x 2 graphiques à la fois. Finalement, plot()produit les graphiques. Pour afficher une seule figure (parcelle) à la fois, nous pouvons spécifier par(mfrow=1). 4.2.2.1 Graphique #1 - Résidus vs valeurs prédites Le premier graphique nous informe de la distribution des résidus en fonction des valeurs prédites par le modèle de régression linéaire. Chaque point représente la distance entre la variable réponse et la réponse prédite par le modèle. Il nous informe sur l’indépendance des résidus et sur leur distribution. Il faut se rappeler qu’avec la régression linéaire, nous avons besoin d’une distribution uniforme des résidus (condition d’homoscédasticité). Sur l’axe des y nous retrouvons les résidus \\(\\epsilon_i\\) et sur l’axe des x les valeurs prédites \\(\\hat{y_i} = \\beta_0 + \\beta_1 \\times x_i\\). Dans une situation idéale, la dispersion des points ne présente pas de patron. Si les résidus sont dispersés de façon aléatoire autour de la ligne de 0, la relation est linéaire et la moyenne des résidus est 0. Si les résidus forment une bande horizontale approximative autour de la ligne de 0, la variance des résidus est homogène (donc, ils sont homoscédastiques). Si les résidus sont organisés en forme d’entonnoir, les résidus ne sont pas homoscédastiques. Alerte ! Il faut être alerté si la distribution des points est non-linéaire comme dans ces deux exemples : Ces exemples présentent une relation non linéaire et un exemple d’hétéroscédasticité qui est l’opposé de l’homoscédasticité, ce qui signifie que la condition de normalité est n’est pas respectée. Dans cette situation, il faut plutôt utiliser un modèle linéaire généralisé (MLG) qui permet d’autres distributions (Poisson, binomial, binomial négatif, etc.) ou essayer de transformer la variable réponse et/ou les prédicteurs. 4.2.2.2 Graphique #2 - Échelle localisée Le deuxième graphique diagnostique permet de vérifier si la dispersion des résidus augmente pour une valeur prédite donnée (i.e. si la dispersion des résidus est causée par la variable explicative). Si la dispersion augmente, la condition de base d’homoscédasticité n’est pas respectée. Sur l’axe des y nous retrouvons la racine carrée des résidus standardisés \\(\\sqrt{\\frac{\\epsilon_i}{\\sigma}}\\) et sur l’axe des x les valeurs prédites \\(\\hat{y_i} = \\beta_0 + \\beta_1 \\times x_i\\). Nous recherchons ici aussi une dispersion des points sans patron, donc un prédicteur distribué de manière égale. Alerte ! Il faut être méfiant si la distribution des points présente une tendance marquée : Dans une situation comme celle-ci, nous ne pouvons nous fier aux résultats de modèle et devons plutôt essayer d’utiliser un modèle linéaire généralisé (MLG) qui permet d’autres distributions (Poisson, binomial, binomial négatif, etc.) ou de transformer la variable réponse et/ou les prédicteurs. 4.2.2.3 Graphique #3 - Normal QQ Le troisième graphique présente la distribution des résidus. Avec ce graphique quantile-quantile, nous pouvons évaluer la normalité des résidus. Ce graphique compare la distribution de probabilité des résidus du modèle à une distribution de probabilité de données normales. Sur l’axe des y nous retrouvons les résidus standardisés \\(\\frac{\\epsilon_i}{\\sigma}\\) et sur l’axe des x les quantiles d’une distribution normale standard \\(\\mathcal{N}(0, \\sigma^2)\\). Nous voulons voir les résidus standardisés sont près de la ligne 1:1. Ainsi, les résidus peuvent être considérés comme normalement distribués. Alerte ! Il faut être méfiant si la distribution des points ne suit pas la ligne 1:1 : Dans ce cas-ci, les points ne sont pas bien alignés sur la droite, ce qui suggère que les résidus ne sont pas distribués normalement. Il faut plutôt essayer d’utiliser un modèle linéaire généralisé (MLG) qui permet d’autres distributions (Poisson, binomial, binomial négatif, etc.) ou de transformer la variable réponse et/ou les prédicteurs. 4.2.2.4 Graphique #4 - Résidus vs effet de levier Ce dernier graphique diagnostique présente les résidus et leur influence. Il permet de déterminer si certaines observations ont une forte influence. Bien que nous ne testons pas un test de condition de base, la présence de points avec une forte influence peut influencer notre interprétation des données. Si une ou certaines observations sont aberrantes (donc, si elles ont des valeurs très différentes des autres), le modèle peut être mal ajusté en raison de leur influence exagérée sur l’estimation du modèle. Le graphique des résidus vs effet de levier présente les points de levier qui sont des observations extrêmes du prédicteur et leur influence sur la régression. L’influence est quantifiée par la distance Cook. Une distance supérieure à 0,5 est problématique. Exemple d’effet de levier et d’influence Il ne s’agit pas ici de graphiques diagnostiques, mais de figures qui illustrent les concepts d’effet de levier et d’influence. Sur l’axe des y nous retrouvons la réponse et le prédicteur sur l’axe des x. Le modèle ne devrait pas pas dépendre fortement d’observations isolées. Une influence élevée de points de levier cause le modèle à passer près des points de levier, car ils manquent d’observations voisines. Graphique #4 Le graphique diagnostique présente Sur l’axe des y les résidus standardisés \\(\\frac{\\epsilon_i}{\\sigma}\\) et l’effet de levier sur l’axe des x. La ligne pointillée rouge marque la distance de Cook de 0,5. Nous voulons observer des résidus se situant à l’intérieur des lignes pointillées marquant la distance de Cook de 0,5. Alerte ! Il faut être méfiant si un ou des points se trouvent à l’extérieur de la ligne pointillée : Le 29 a un effet de levier et une distance de Cook de plus de 0,5. Il correspond à une donnée aberrante. Il ne faut cependant jamais supprimer les valeurs aberrantes sans avoir de bonnes raisons de le faire ! Si (et seulement si!) ces observations correspondent à des erreurs de mesure ou à des exceptions, elles peuvent être retirées du jeu de données. 4.2.3 Étape 2. Vérifier les conditions d’application pour lm1 Le modèle lm1 respecte-t-il les conditions du modèle linéaire ? En se basant sur les connaissances acquises dans les sections précédentes, ces graphiques diagnostiques présentent de sérieux problèmes. * Les graphiques 1 et 2 présentent de fortes tendances, * Le graphique 3 montre que les résidus ne suivent pas une distribution normale, * Le graphique 4 met en évidence l’effet levier du point 32 et de son influence très élevée. 4.2.4 Conditions non respectées - Quelle est la cause ? Pour comprendre la source des problèmes du modèle linéaire, traçons le modèle avec les observations : # Graphique du modèle et des observations par(mfrow = c(1, 2)) coef(lm1) # constante et pente ## (Intercept) Mass ## 38.16645523 0.01438562 plot(MaxAbund ~ Mass, data = bird) # graphique à gauche abline(lm1) # ligne définie par les paramètres du modèle hist(residuals(lm1)) # graphique à droite : distribution des résidus À gauche nous avons les données ainsi que la droite représentant l’estimation du modèle (MaxAbund ~ Mass). À gauche, la distribution des résidus. Nous pouvons vérifier si les résidus suivent une distribution normale à l’aide d’un test de Shapiro-Wilk et d’un test d’asymétrie (skewness) : # Test de la normalité des résidus shapiro.test(residuals(lm1)) ## ## Shapiro-Wilk normality test ## ## data: residuals(lm1) ## W = 0.64158, p-value = 3.172e-10 # Test d&#39;asymétrie library(e1071) skewness(residuals(lm1)) ## [1] 3.154719 Le test de Shapiro-Wilk compare la distribution des données observées à une distribution normale. Les données observées peuvent être considérées comme normalement distribuées lorsque la valeur de p calculée par le test de Shapiro-Wilk est supérieure au seuil de significativité α (généralement 0.05). Ici, la valeur de p (p-value) retournée indique une distribution significativement différente d’une normale. Le test d’asymétrie mesure le décalage des résidus. Une valeur positive représente un décalage vers la gauche et une valeur négative un décalage vers la droite. Ici, la valeur positive d’asymétrie indique que la distribution est décalée vers la gauche. 4.2.5 Conditions non respectées - Comment procéder ? Clairement, les conditions d’application du modèle linéaire lm1 ne sont pas respectées. Nous ne pouvons donc pas nous fier aux résultats du modèle. Il faut se tourner vers une autre alternative et il y a deux options lorsque les conditions d’application du modèle linéaire ne sont pas respectées. Utiliser un autre type de modèle Les ateliers R 6 à 8 du CSBQ explorent d’autres modèles qui pourraient être mieux adaptés à l’hypothèse et aux données. Transformer les données Il est également possible de modifier ses données, que ce soit la variable réponse ou les prédicteurs. Plusieurs types de transformations sont possibles et leur utilité dépend de la distribution de la variable et du type de modèle. Cependant, la modification des variables est souvent délicate en pratique. La transformation peut régler certains problèmes, mais peut en créer d’autres. Il est à noter que les résultats des tests de signification sur les données transformées ne sont pas automatiquement valables pour les données non transformées. 4.2.5.1 Défi 1: Un modèle sur variables transformées Notre modèle présente de sérieux problèmes. Essayons une transformation logarithmique pour voir si ça peut corriger la situation. Premièrement, transformez données et exécutez une nouvelle régression linéaire sur ces données. Par la suite, vérifiez le respect des conditions d’application du nouveau modèle en utilisant les graphiques diagnostiques. Étape 1 Débutons par la transformation des données de notre jeu de données : # Transformation logarithmique des données bird$logMaxAbund &lt;- log10(bird$MaxAbund) bird$logMass &lt;- log10(bird$Mass) Avec ces données logMaxAbund et logMass transformées, nous exécutons une nouvelle régression linéaire et sauvegardons l’objet du modèle sous lm2. # Modèle linéaire sur les données transformées lm2 &lt;- lm(logMaxAbund ~ logMass, data = bird) Nous pouvons observer que les paramètres s’alignent avec notre prédiction. C’est-à-dire, que le coefficient logMass est négatif et donc que l’abondance décroit avec la masse de l’espèce. Cependant, il faut encore vérifier conditions d’application du modèle pour s’assurer de la validité des résultats. Étape 2 Vérifions les conditions pour lm2 en utilisant les graphiques diagnostiques. # Graphiques diagnostiques par(mfrow = c(2, 2), mar = c(3, 4, 1.15, 1.2)) plot(lm2) Les graphiques diagnostiques semblent beaucoup mieux, mais il reste des problèmes. Certains graphiques présentent encore des tendances marquées. Traçons le modèle avec les observations : # Graphique du modèle et des observations par(mfrow = c(1, 2)) coef(lm2) # constantes et pente ## (Intercept) logMass ## 1.6723673 -0.2361498 plot(logMaxAbund ~ logMass, data = bird) # graphique à gauche abline(lm2) # ligne définie par les paramètres du modèle hist(residuals(lm2)) # graphique à droite : distribution des résidus Le modèle semble mieux expliquer les données et la distribution des résidus s’est beaucoup rapprochée de la distribution normale. 4.2.6 Étape 3. Analyser les paramètres La dernière étape d’une régression linéaire avec R est de vérifier les paramètres du modèle. Nous utilisons alors la commande summary() pour obtenir plus d’informations sure le modèle ajusté. # Paramètres du modèle ajusté summary(lm2) Call: lm(formula = logMaxAbund ~ logMass, data = bird) Residuals: Min 1Q Median 3Q Max -1.93562 -0.39982 0.05487 0.40625 1.61469 Coefficients: Estimate Std. Error t value Pr(&gt;|t|) (Intercept) 1.6724 0.2472 6.767 1.17e-08 *** logMass -0.2361 0.1170 -2.019 0.0487 * --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Residual standard error: 0.6959 on 52 degrees of freedom Multiple R-squared: 0.07267, Adjusted R-squared: 0.05484 F-statistic: 4.075 on 1 and 52 DF, p-value: 0.04869 La sortie de summary() présente plusieurs valeurs : 1. Coefficients : Estimations des paramètres et leur écart type 2. Pr(&gt;|t|) : Résultats d’un test de t visant à déterminer si les paramètres sont différents de 0 3. Adjusted R squared (R au carré ajusté) : Dans quelle mesure le modèle explique-t-il les données ? 4. F-statistic (statistique F) (ANOVA) : Le modèle est-il significativement différent d’un modèle sans prédicteur (modèle nul) ? Nous aborderons dans la prochaine section les Tests de T et l’ANOVA. Nous pouvons cependant déjà en dégager que notre modèle n’est que marginalement meilleur que le modèle nul. Avec l’objet lm2, nous pouvons aussi extraire les paramètres du modèle et les autres résultats : # Vecteurs de résidus et valeurs prédites e &lt;- residuals(lm2) y &lt;- fitted(lm2) coefficients(lm2) # coefficients ## (Intercept) logMass ## 1.6723673 -0.2361498 summary(lm2)$coefficients # coefficients avec test de t ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 1.6723673 0.2471519 6.766557 1.166186e-08 ## logMass -0.2361498 0.1169836 -2.018658 4.869342e-02 summary(lm2)$adj.r.squared # R au carré ajusté ## [1] 0.05483696 4.3 Interprétation du modèle L’interprétation du modèle est l’étape finale lorsque nous obtenons un modèle qui respecte les conditions d’application. L’interprétation est l’évaluation de l’appui du modèle pour l’hypothèse. Bref, nous répondons à la question: Dans quelle mesure le modèle soutient notre hypothèse ? Hypothèse Pour différentes espèces d’oiseaux, la masse moyenne d’un individu a un effet sur l’abondance maximale de l’espèce, en raison de contraintes écologiques (sources de nourriture, disponibilité de l’habitat, etc.). # Sommaire du modèle linéaire avec les données # log-transformées summary(lm2) Call: lm(formula = logMaxAbund ~ logMass, data = bird) Residuals: Min 1Q Median 3Q Max -1.93562 -0.39982 0.05487 0.40625 1.61469 Coefficients: Estimate Std. Error t value Pr(&gt;|t|) (Intercept) 1.6724 0.2472 6.767 1.17e-08 *** logMass -0.2361 0.1170 -2.019 0.0487 * --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Residual standard error: 0.6959 on 52 degrees of freedom Multiple R-squared: 0.07267, Adjusted R-squared: 0.05484 F-statistic: 4.075 on 1 and 52 DF, p-value: 0.04869 Le modèle lm2 ne présente que très peu preuves à l’appui de l’hypothèse. En regardant les paramètres du modèle comme nous l’avons vu précédemment, nous observons que le modèle explique peu de la réponse. Le faible R au carré ajusté indique qu’une faible partie de la variance de la variable réponse est expliquée par le modèle. La masse n’explique qu’une petite fraction de l’abondance des espèces. Le F-test est à peine significatif ce qui indique que le modèle n’est que légèrement meilleur qu’un modèle sans variables prédictives. Finalement, la taille d’effet estimé (le coefficient) du paramètre logMass est très près de zéro et n’est que marginalement significative, c’est-à-dire qu’une augmentation ou une diminution de la masse des espèces n’entraine quasiment pas de changement dans leur abondance. Les résultats ne sont pas à la hauteur de ce que nous aimerions, peut-être devrions-nous formuler une hypothèse plus précise ? 4.3.1 Trouver un meilleur modèle: oiseaux terrestres Formulons une nouvelle hypothèse plus précise. Cette fois, concentrons-nous seulement sur les oiseaux terrestres. L’abondance des oiseaux aquatiques ne répond peut-être pas de la même façon à la masse que les oiseaux terrestres. Nouvelle hypothèse Pour différentes espèces d’oiseaux terrestres, la masse moyenne d’un individu a un effet sur l’abondance maximale de l’espèce, en raison de contraintes écologiques (sources de nourriture, disponibilité de l’habitat, etc.). Nous pouvons maintenant ajuster le modèle linéaire pour exclure les oiseaux aquatiques. Il suffit : # Modèle linéaire avec oiseaux terrestres lm3 &lt;- lm(logMaxAbund ~ logMass, data = bird, subset = !bird$Aquatic) # exclut les oiseaux aquatiques (!birdsAquatic == TRUE) ou # de façon équivalente : lm3 &lt;- lm(logMaxAbund~logMass, # data=bird, subset=bird$Aquatic == 0) # Sortie du modèle lm3 ## ## Call: ## lm(formula = logMaxAbund ~ logMass, data = bird, subset = !bird$Aquatic) ## ## Coefficients: ## (Intercept) logMass ## 2.2701 -0.6429 Et vérifions les conditions d’application du modèle : par(mfrow = c(2, 2)) plot(lm3) Au vu des graphiques diagnostiques, nous pouvons conclure qu les conditions d’application sont respectées ! Finalement, le modèle fournit des preuves à l’appui de notre hypothèse : summary(lm3) Call: lm(formula = logMaxAbund ~ logMass, data = bird, subset = !bird$Aquatic) Residuals: Min 1Q Median 3Q Max -1.78289 -0.23135 0.04031 0.22932 1.68109 Coefficients: Estimate Std. Error t value Pr(&gt;|t|) (Intercept) 2.2701 0.2931 7.744 2.96e-09 *** logMass -0.6429 0.1746 -3.683 0.000733 *** --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Residual standard error: 0.6094 on 37 degrees of freedom Multiple R-squared: 0.2682, Adjusted R-squared: 0.2485 F-statistic: 13.56 on 1 and 37 DF, p-value: 0.000733 Le R au carré ajusté est de 0,25, ce qui indique que le modèle est raisonnablement bien ajusté aux données. Le modèle est bien meilleur qu’un modèle sans variables prédictives. Le F-test est significatif (&lt; 0.05). Le T-test montre que l’estimation du paramètre “logMass” est clairement différente de 0 (t-test) et que la masse a un effet sur l’abondance des espèces. 4.4 Défi 2 Pour le deuxième défi, rassemblons toutes les étapes et essayons avec de nouvelles données : Formuler une autre hypothèse similaire sur l’abondance maximale et la masse moyenne d’un individu, cette fois pour les passereaux (“passerine birds”). Ajuster un modèle pour évaluer cette hypothèse, en utilisant les variables transformées (c’est-à-dire logMaxAbund et logMass). Sauvegarder le modèle sous le nom de lm4. Vérifier les conditions d’application du modèle linéaire à l’aide des graphiques diagnostiques. Interpréter les résultats : Le modèle fournit-il des preuves à l’appui de l’hypothèse ? Indice : Comme les espèces aquatiques, les passereaux (variable Passerine) sont codées 0/1 (vérifier avec str(bird)) 4.4.1 Solutions Hypothèse Pour différentes espèces de passereaux, la masse moyenne d’un individu a un effet sur l’abondance maximale de l’espèce, en raison de contraintes écologiques (sources de nourriture, disponibilité de l’habitat, etc.). Ajuster le modèle # Modèle linéaire pour les passeraux lm4 &lt;- lm(logMaxAbund ~ logMass, data = bird, subset = bird$Passerine == 1) lm4 ## ## Call: ## lm(formula = logMaxAbund ~ logMass, data = bird, subset = bird$Passerine == ## 1) ## ## Coefficients: ## (Intercept) logMass ## 1.2429 0.2107 Vérifier les conditions d’application par(mfrow = c(2, 2)) plot(lm4) Vaut-il la peine d’interpréter les résultats ? summary(lm4) Call: lm(formula = logMaxAbund ~ logMass, data = bird, subset = bird$Passerine == 1) Residuals: Min 1Q Median 3Q Max -1.24644 -0.20937 0.02494 0.25192 0.93624 Coefficients: Estimate Std. Error t value Pr(&gt;|t|) (Intercept) 1.2429 0.4163 2.985 0.00661 ** logMass 0.2107 0.3076 0.685 0.50010 --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Residual standard error: 0.5151 on 23 degrees of freedom Multiple R-squared: 0.02, Adjusted R-squared: -0.02261 F-statistic: 0.4694 on 1 and 23 DF, p-value: 0.5001 Les résultats du modèle ne doivent pas être interprétés, car les conditions d’application du modèle linéaire ne sont pas respectées! 4.5 Régression linéaire avec R Effectuer une régression linéaire avec R se découpe en trois étapes: Formuler et exécuter un modèle linéaire basé sur une hypothèse Vérifier les conditions d’application du modèle linéaire Examiner la sortie du modèle et si les conditions sont respectées Analyser les paramètres de régression Tracer le modèle Effectuer des tests de signification sur les estimations des paramètres (si nécessaire) Nous allons explorer chaque étape dans les sections suivantes. Aussi, dans le cas où les conditions ne sont pas respectées, nous verrons qu’il est possible d’envisager l’utilisation d’un Modèle linéaire généralisé (GLM) ou la transformation des données. 4.6 Noms de variables Des termes différents sont utilisés pour la réponse et le prédicteur, en fonction du contexte et du domaine scientifique. Les termes ne sont pas toujours synonymes. Voici deux tableaux pour vous éclairer sur le jargon que vous rencontrerez. résponse prédicteur var. expliqué var. explicatif covariable var. endogène var. exogène var. dépendante var. indépendante response predictor explanatory var. covariate outcome output var. input var. dependent var. independent var. "],["test-de-t-et-anova.html", "Chapitre 5 Test de t et ANOVA 5.1 ANOVA 5.2 ANOVA à deux critères de classification 5.3 ANOVA non-équilibrée (section avancée/facultative) 5.4 6. ANCOVA", " Chapitre 5 Test de t et ANOVA 5.1 ANOVA L’analyse de la variance (ANOVA) est un type de modèle linéaire pour une variable réponse continue, et une ou plusieurs variables explicatives catégoriques. Les variables explicatives catégoriques peuvent comprendre plusieurs niveaux (ou groupes). Par exemple, une variable \"couleur\" peut avoir 3 niveaux: vert, bleu, et jaune. L’ANOVA teste si la moyenne de la variable réponse diffère entre ces niveaux ou groupes en comparant la variation intra-groupe et inter-groupe. Par exemple, si la masse des bleuets diffère selon leur couleur. Le calcul de l’ANOVA se base sur la partition de la somme des carrés, et compare la variance entre les groupes à celle à l’intérieur des groupes (i.e. la variance intra-groupe). Si la variance entre les groupes est supérieure à la variance intra-groupe, la variable explicative a un effet plus important que l’erreur aléatoire (due à la variance intra-groupe). La variable explicative est donc susceptible d’influencer significativement la variable réponse. Dans un ANOVA, la comparaison de la variance entre les groupes à celle intra-groupe se fait en calculant la statistique F. Cette statistique correspond au ratio entre la moyenne des carrés des groups (MSTrt) et la moyenne des carrés des erreurs (MS\\(\\epsilon\\)). Ces deux termes sont obtenus en divisant leurs sommes des carrés respectives par leurs degrés de liberté, comme on le voit présenté typiquement dans un tableau d’ANOVA. Une valeur de p peut ensuite être calculée à partir de la statistique de F, qui suit une distribution de khi carré (χ2) Source de variation Degrés de liberté (df) Somme des carrés des écarts à la moyenne Moyenne des carrés Statistique de F Total \\(ra-1\\) \\(SS_{t}=\\sum(y_{i}-\\overline{y})^{2}\\) Facteur A \\(a-1\\) \\(SS_{f}=\\sum(\\hat{y_{i}}-\\overline{y})^{2}\\) \\(MS_{f}=\\frac{SS_{f}}{(a-1)}\\) \\(F=\\frac{MS_{f}} {MS_{E}}\\) Résidus \\(a(r-1)\\) \\(SS_{\\epsilon}=\\sum(y_{i}-\\hat{y_{i}})^{2}\\) \\(MS_{\\epsilon}=\\frac{SS_{\\epsilon}}{a(r-1)}\\) \\(a\\): nombre de niveaux de la variable explicative A \\(r\\): nombre de répétitions par groupe \\(\\overline{y}\\): moyenne globale de la variable réponse \\(\\hat{y_{i}}\\) : moyenne de la variable réponse du groupe i. 5.1.1 Types d’ANOVA ANOVA à un critère de classification Une variable explicative catégorique avec au moins 2 niveaux. S’il n’y a que 2 niveaux, un test de t peut être utilisé. ANOVA à deux critères de classification section 4.1.3 Deux variables explicatives catégoriques ou plus, Chaque facteur peut avoir plusieurs niveaux, Les interactions entre chaque variable explicative catégorique doivent être testées. Mesures répétées L’ANOVA peut être utilisée pour des mesures répétées, mais ce sujet n’est pas abordé dans cet atelier. Un modèle linéaire mixte peut également être utilisé pour ce type de données (voir l’atelier 6). 5.1.2 Test de t Si on a une variable explicative est qualitative et n’a que 2 niveaux, on peut utiliser un test de t de Student pour déterminer s’il y a une différence entre la moyenne des 2 niveaux. Selon les données, on peut choisir de tester une hypothèse unilatérale: c’est-à-dire qu’on peut déterminer si la moyenne d’un groupe est plus grande que celle de l’autre groupe, plutôt que de seulement détecter une différence entre les moyennes du groupe.Noter que le test est plus robuste lorsque la taille de l’échantillon est plus élevée et lorsque les groupes ont des tailles égales. Pour le test de t, la statistique t qui est utilisée pour déterminer la valeur de p est calculée de la manière suivante : \\(t = (\\overline{y_{1}}-\\overline{y_{1}})/\\sqrt{\\frac{s_{1}^2} n_{1} + \\frac{s_{2}^2} n_{2}}\\) où \\(\\overline{y_{1}}\\) and \\(\\overline{y_{2}}\\) sont les moyennes de la variable réponse y pour les groupes 1 et 2 respectivement, \\(s_{1}^2\\) et \\(s_{2}^2\\) sont les variances de la variable réponse y pour les groupes 1 et 2 respectivement, \\(n_{1}\\) et \\(n_{2}\\) sont les tailles d’échantillons des groupes 1 et 2 respectivement. Notez que le test de t est mathématiquement équivalent à une ANOVA à un critère de classification ayant deux niveaux. 5.1.2.1 Conditions de base Si les conditions de base du test de t ne sont pas respectées, les résultats du test peuvent être erronés. Voici quelques notes à propos de la validation de ces conditions de base: Normalité des données Comme pour la régression linéaire simple, la variable réponse doit être distribuée normalement. Si cette condition n’est pas respectée, mais que la distribution est relativement symétrique, que la moyenne est près du centre de la distribution, et que la distribution est unimodale, le test de t donnera un résultat valable en autant que la taille de l’échantillon soit suffisante (règle empirique : ~30 observations). Si les données sont fortement asymétriques, il est nécessaire d’avoir un très large échantillon pour que le test fonctionne. Dans ce cas-là, il est préférable d’utiliser un test non-paramétrique. Homoscédasticité Une autre supposition importante du test de t est que les variances des deux groupes sont égales. Ceci permet de calculer une variance combinée qui est utilisée pour calculer l’erreur type de la différence des moyennes. Si les variances des deux groupes sont inégales, la probabilité de commettre une erreur de type I (i.e. rejeter l’hypothèse nulle alors qu’elle est vraie) est supérieure au seuil α. La robustesse du test de t augmente avec la taille de l’échantillon et est supérieure lorsque les groupes sont de même taille. Il est possible d’évaluer la différence de variance entre deux échantillons en se demandant quelle est la probabilité de tirer deux échantillons d’une population avec des variances identiques alors que les échantillons ont des variances de \\(s_{1}^2\\) et \\(s_{2}^2\\). Pour ce faire, il faut effectuer un test de ratio des variances (i.e. un test de F). 5.1.2.2 Non-respect des conditions d’application Si les variances entre les groupes ne sont pas égales, il est possible de corriger la situation avec la correction de Welch. Si les conditions de base ne sont toujours pas respectées, il est possible de transformer les données (avec un log ou une racine carré par exemple) ou utiliser l’équivalent non-paramétrique du test de t : le test de Mann-Whitney. Finalement, si les deux groupes ne sont pas indépendants (e.g. mesures prises sur un même individu à deux périodes différentes), il faut utiliser un test de t apparié. 5.1.2.3 Effectuer un test de t Dans R, le test de t est exécutés avec la fonction t.test. t.test(Y ~ X2, data = data, alternative = &quot;two.sided&quot;) où: -Y est la variable réponse -X2 est la variable quantitative à deux niveaux -data est le nom du jeux de données -alternative réfère à l’hypothèse alternative. 'two.sided' est le paramètre par défault. Vous pouvez aussi choisir 'less' ou 'greater'. Pour plus de détails, voir la section suivante. -var.eqal, if true, this increases the robustness of the test. But we need to test for it prior to testing. Regardons un exemple avec des données de régime alimentaire sur des oiseaux Par exemple, nous pouvons tester la différence de masse entre les oiseaux aquatiques et les oiseaux terrestres avec la variable Aquatic. Commençons par visualizer les données: Il semble avoir une différence simplement en regardant le graphique. Il faut maintenant tester les conditions d’application pour s’assurer que le test sera valide. Note: Nous n’avons pas besoin de tester la normalité puisque nous avons transfomé en log plus tôt. # Homogénéité de la variance var.test(logMass ~ Aquatic, data = bird) ## ## F test to compare two variances ## ## data: logMass by Aquatic ## F = 1.0725, num df = 38, denom df = 14, p-value = 0.9305 ## alternative hypothesis: true ratio of variances is not equal to 1 ## 95 percent confidence interval: ## 0.3996428 2.3941032 ## sample estimates: ## ratio of variances ## 1.072452 Ici, on voit que le test de ratio des variances n’est pas statistiquement différent de 1, ce qui signifie que les variances entre les groupes sont égales. ttest1 &lt;- t.test(x = bird$logMass[bird$Aquatic == 0], y = bird$logMass[bird$Aquatic == 1], var.equal = TRUE) # ou l&#39;équivalent ttest1 &lt;- t.test(logMass ~ Aquatic, var.equal = TRUE, data = bird) ttest1 ## ## Two Sample t-test ## ## data: logMass by Aquatic ## t = -7.7707, df = 52, p-value = 2.936e-10 ## alternative hypothesis: true difference in means between group 0 and group 1 is not equal to 0 ## 95 percent confidence interval: ## -3.838340 -2.262829 ## sample estimates: ## mean in group 0 mean in group 1 ## 3.645998 6.696582 Étant donné que notre valeur de p est inférieure à 0.05, l’hypothèse nulle (i.e. l’absence de différence de masse entre les deux groupes) est rejetée. 5.1.2.4 Effectuer un test de t avec lm() Le test de t est un modèle linéaire et un cas spécifique de l’ANOVA avec un facteur à 2 niveaux. Vous pouvez donc arriver aux mêmes résultats avec: lm.t &lt;- lm(logMass ~ Aquatic, data = bird) anova(lm.t) ## Analysis of Variance Table ## ## Response: logMass ## Df Sum Sq Mean Sq F value Pr(&gt;F) ## Aquatic 1 100.816 100.82 60.385 2.936e-10 *** ## Residuals 52 86.817 1.67 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Quand les variances sont équivalents, on peut montrer que t2 = F: ttest1$statistic^2 ## t ## 60.3845 anova(lm.t)$F ## [1] 60.3845 NA 5.1.2.5 Test de t unilatéral L’argument \"alternative\" de la fonction t.test() permet d’effectuer un test de t unilatéral, c’est-à-dire dans une seule direction. Par défault, la fonction t.test() utilise 'two-sided', qui permet seulement de tester si les moyennes diffère l’une de l’autre. Si l’on cherche à déterminer si une moyenne est plus élevée que l’autre, nous pouvons utiliser 'less' (\\(\\overline{y_{1}}\\) &lt; \\(\\overline{y_{2}}\\)) ou 'greater' (\\(\\overline{y_{1}}\\) &gt; \\(\\overline{y_{2}}\\)). Par exemple, si on veut tester l’hypothèse que les oiseaux terrestres sont plus légers que les oiseaux aquatiques, on peut écrire la commande de la façon suivante : # Test de t en spécifiant l&#39;argument &#39;alternative&#39; uni.ttest1 &lt;- t.test(logMass ~ Aquatic, var.equal = TRUE, data = bird, alternative = &quot;less&quot;) uni.ttest1 Dans la sortie R obtenue par uni.ttest1, les résultats du test sont indiqués à la troisième ligne : ## ## Two Sample t-test ## ## data: logMass by Aquatic ## t = -7.7707, df = 52, p-value = 1.468e-10 ## alternative hypothesis: true difference in means between group 0 and group 1 is less than 0 ## 95 percent confidence interval: ## -Inf -2.393147 ## sample estimates: ## mean in group 0 mean in group 1 ## 3.645998 6.696582 Dans ce cas-ci, la statistique du test de t est t = -7.7707 avec df = 52 degrés de liberté, ce qui donne une valeur de p = 1.468e-10. On rejette donc l’hypothèse nulle. On peut conclure que les oiseaux aquatiques sont significativement plus lourds que les oiseaux terrestres. Nous aurions pu tester l’invers: si les oiseaux terrestres sont plus lourds que les oiseaux aquatique. Dece test, nous obtenons une même valeur de t (mais négative) et une valeur de p qui reflète ces résultats. Nous pouvons en conclure que les oiseaux terrestres ne sont pas significativement plus lourds que les oiseaux aquatiques. # Test de t en spécifiant l&#39;argument &#39;alternative&#39; uni.ttest1 &lt;- t.test(logMass ~ Aquatic, var.equal = TRUE, data = bird, alternative = &quot;greater&quot;) uni.ttest1 ## ## Two Sample t-test ## ## data: logMass by Aquatic ## t = -7.7707, df = 52, p-value = 1 ## alternative hypothesis: true difference in means between group 0 and group 1 is greater than 0 ## 95 percent confidence interval: ## -3.708022 Inf ## sample estimates: ## mean in group 0 mean in group 1 ## 3.645998 6.696582 5.1.3 Effectuer une ANOVA Le test de t s’applique seulement quand on a une seule variable explicative catégorique, qui comprend 2 niveaux. Pour tous les autres modèles linéaires avec des variables explicatives catégoriques avec &gt; 2 niveaux, on utilise une ANOVA. Lorsque l’ANOVA détecte une différence significative entre les groupes, l’analyse n’indique pas quel(s) groupe(s) diffère(nt) de(s) l’autre(s). Un test couramment utilisé a posteriori pour répondre à cette question est le test de Tukey. Vous voudrez peut-être comparer vos groupes avec des comparaison planifiées ou contrastes. Ceci est souvent plus robust et élégant puisque les différences attendues sont établies a priori. 5.1.4 Vérification des conditions d’application Comme la régression linéaire simple et le test de t, l’ANOVA doit respecter 4 conditions statistiques pour que les résultats soient valides. Voici quelques conseils pour tester ces conditions pour une ANOVA: Distribution normale Les résidus d’un modèle d’ANOVA peuvent être visualisés à l’aide d’un diagramme quantile-quantile (Q-Q). Les résidus sont considérés comme normalement distribués s’ils se répartissent le long de la droite 1:1. Si ce n’est pas le cas, les résultats de l’ANOVA ne peuvent pas être interprétés. Homoscédasticité L’ANOVA est valide seulement lorsque la variance des résidus est homogène entre les groupes. Cette homoscédasticité peut être vérifiée par un graphique des résidus en fonction des valeurs prédites ou par un diagramme diagnostic \"scale-location\". Si ces graphiques montrent une dispersion équivalente des résidus pour chaque valeur prédite, la variance des résidus peut être considérée homogène. Il est également possible d’effectuer un test de Bartlett à l’aide de la fonction bartlett.test(). Si la valeur de p de ce test est supérieure à 0.05, l’hypothèse nulle H0: s12 = s22 =... = sj2 =... = sn2 est acceptée (i.e. l’homoscédasticité est respectée). Une transformation de la variable réponse peut être utilisée si cette supposition n’est pas respectée. Additivité Les effets de deux facteurs sont additifs si l’effet d’un facteur demeure constant pour tous les niveaux d’un autre facteur. Chaque facteur doit influencer la variable réponse de manière indépendante des autres facteurs. Si les conditions ne sont pas respectées, vous pouvez essayer de transformer la variable réponse. Ceci peut aider à normaliser les résidus, à égaliser les variances, et à transformer un effet multiplicatif en effet additif. Si vous ne voulez pas (ou ne pouvez pas) transformer vos données, vous pouvez utiliser l’équivalent non-paramétrique de l’ANOVA : le test de Kruskal-Wallis. 5.1.5 Exemple avec le jeu de données bird Commençons tout d’abord par visualiser les données avec la fonction boxplot(). Rappelez-vous que, dans R, les groupes sont ordonnés par ordre alphabétique par défaut. Il est possible de réorganiser les groupes autrement. Par exemple, on peut les ordonner par ordre croissant de la médiane de chaque diète. # Ordre alphabétique par défaut boxplot(logMaxAbund ~ Diet, data = bird) # Réorganiser l&#39;ordre des facteurs med &lt;- sort(tapply(bird$logMaxAbund, bird$Diet, median)) boxplot(logMaxAbund ~ factor(Diet, levels = names(med)), data = bird, col = c(&quot;white&quot;, &quot;lightblue1&quot;, &quot;skyblue1&quot;, &quot;skyblue3&quot;, &quot;skyblue4&quot;)) Une autre façon de visualiser les effets des facteurs est d’utiliser la fonction plot.design(). Cette fonction permet de représenter les valeurs moyennes des niveaux d’un facteur (par une ligne verticale) et la moyenne globale de la variable réponse (par une ligne horizontale). plot.design(logMaxAbund ~ Diet, data = bird, ylab = expression(&quot;log&quot;[10] * &quot;(Maximum Abundance)&quot;)) Par la suite, nous devons vérifier les conditions d’applications. Note: nous devons performer l’ANOVA poour pouvoir utiliser les résidus, cependant, tant que nous ne vérifions pas les conditions d’application, les résultats ne peuvent être interprétés. # Graphiques pour conditions d&#39;application aov1 &lt;- aov(logMaxAbund ~ Diet, data = bird) opar &lt;- par(mfrow = c(2, 2)) plot(aov1) par(opar) Idéalement, le premier graphique devrait montrer une dispersion similaire pour chaque niveau de diète. Nous pouvons utiliser tous ces graphiques pour évaluer les conditions d’application, mais nous pouvons aussi utiliser les test de Shapiro, de Bartlett ou de Levene en supplément. Note:Le test de Levene performe mieux, mais a une erreur de Type II un peu plus élevée. # Test de la supposition de la normalité des résidus shapiro.test(resid(aov1)) ## ## Shapiro-Wilk normality test ## ## data: resid(aov1) ## W = 0.97995, p-value = 0.4982 # Test de la supposition de l&#39;homogénéité de la variance # Bartlett bartlett.test(logMaxAbund ~ Diet, data = bird) ## ## Bartlett test of homogeneity of variances ## ## data: logMaxAbund by Diet ## Bartlett&#39;s K-squared = 7.4728, df = 4, p-value = 0.1129 # Levene library(car) leveneTest(logMaxAbund ~ Diet, data = bird) ## Levene&#39;s Test for Homogeneity of Variance (center = median) ## Df F value Pr(&gt;F) ## group 4 2.3493 0.06717 . ## 49 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Toutefois, les tests ne sont pas significatifs. On peut supposer que les résidus sont distribués normalement et que les variances sont égales. Nous sommes maintenant prêts à effectuer une ANOVA. Dans R, la fonction aov() permet d’effectuer une ANOVA directement. Il est également possible d’effectuer une ANOVA avec la fonction anova() qui exécute l’ANOVA comme un modèle linéaire : # En utilisant aov() aov1 &lt;- aov(logMaxAbund ~ Diet, data = bird) summary(aov1) # En utilisant lm() anov1 &lt;- lm(logMaxAbund ~ Diet, data = bird) anova(anov1) 5.1.6 Sortie du modèle Lorsque le modèle d’ANOVA a été validé et les conditions d’applications rencontrées, on peut interpréter les résultats correctement. La sortie du modèle fournie par R dépend de la fonction qui a été utilisée pour effectuer l’ANOVA. Si la fonction aov() a été utilisée : aov1 &lt;- aov(logMaxAbund ~ Diet, data = bird) Les résultats de l’ANOVA peuvent être visualisés avec la fonction summary() : summary(aov1) Si la fonction lm() a été utilisée : anov1 &lt;- lm(logMaxAbund ~ Diet, data = bird) les résultats de l’ANOVA peuvent être visualisés avec la fonction anova() : anova(anov1) Dans les deux cas, la sortie dans R sera la même : ## Df Sum Sq Mean Sq F value Pr(&gt;F) ## Diet 4 27.07 6.768 2.836 0.0341 * ## Residuals 49 116.92 2.386 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Cette sortie de R représente le tableau de l’ANOVA. On y retrouve les degrés de liberté, la somme des carrés, la moyenne de la somme des carrés, la statistique de F ainsi qu’une valeur de p. Dans l’exemple de la diète des oiseaux, la diète influence significativement l’abondance des oiseaux car la valeur de p est inférieure à 0.05. L’hypothèse nulle est rejetée, ce qui signifie qu’au moins une des diètes influence l’abondance différemment des autres diètes. 5.1.7 Tests complémentaires Il est impossible d’identifier quel groupe diffère des autres avec une ANOVA. Elle ne permet que de déterminer s’il existe une différence entre niveaux. Pour identifier les niveaux qui diffèrent des autres, les tests post-hoc comparent les combinaisons de variables explicatives (i.e. les groupes) deux par deux. Il existe plusieurs tests post hoc (e.g. Fischer’s least significant difference, Duncan’s new multiple range test, Newman-Keuls method, Dunnett’s test, etc.), mais le test de Tukey est le plus couramment utilisé. Dans R, on utilise la fonction TukeyHSD() pour effectuer ce test : # À quel niveau se situe la différence de diète ? TukeyHSD(aov(anov1), ordered = T) # Cette commande est équivalente à la précédente : TukeyHSD(aov1, ordered = T) La sortie de R inclut un tableau qui liste toutes les combinaisons des niveaux de la variable explicative et qui identifie quel(s) groupe(s) diffère(ent) des autres : ## Tukey multiple comparisons of means ## 95% family-wise confidence level ## factor levels have been ordered ## ## Fit: aov(formula = logMaxAbund ~ Diet, data = bird) ## ## $Diet ## diff lwr upr p adj ## Vertebrate-InsectVert 0.7746576 -2.56640638 4.115722 0.9645742 ## Insect-InsectVert 1.4815601 -1.76264078 4.725761 0.6965047 ## Plant-InsectVert 2.0364840 -2.33799553 6.410964 0.6812494 ## PlantInsect-InsectVert 2.4539424 -0.80660217 5.714487 0.2235587 ## Insect-Vertebrate 0.7069025 -0.89043156 2.304237 0.7204249 ## Plant-Vertebrate 1.2618265 -2.07923748 4.602890 0.8211024 ## PlantInsect-Vertebrate 1.6792848 0.04901254 3.309557 0.0405485 ## Plant-Insect 0.5549239 -2.68927692 3.799125 0.9884504 ## PlantInsect-Insect 0.9723823 -0.44885612 2.393621 0.3117612 ## PlantInsect-Plant 0.4174584 -2.84308619 3.678003 0.9961844 Dans ce cas-ci, la seule différence significative d’abondance se retrouve entre les diètes \"PlantInsect\" et \"Vertebrate\". 5.1.8 Visualisation des résultats Après avoir vérifié les conditions de base, interprété les résultats, et identifié les niveaux significatifs à l’aide de tests post-hoc ou de contrastes, les résultats d’une ANOVA peuvent être représentés graphiquement à l’aide de la fonction barplot(). R produit donc un graphique de la variable réponse en fonction des niveaux de groupe, ou les erreurs types et le nom des niveaux du groupe (représentant le résultat d’un test post hoc) peuvent y être apposées. # Visualisation d&#39;un modèle d&#39;ANOVA à l&#39;aide de la fonction # barplot() sd &lt;- tapply(bird$logMaxAbund, list(bird$Diet), sd) means &lt;- tapply(bird$logMaxAbund, list(bird$Diet), mean) n &lt;- length(bird$logMaxAbund) se &lt;- 1.96 * sd/sqrt(n) bp &lt;- barplot(means, col = c(&quot;white&quot;, &quot;lightblue1&quot;, &quot;skyblue1&quot;, &quot;skyblue3&quot;, &quot;skyblue4&quot;), ylab = expression(&quot;log&quot;[10] * &quot;(Maximum Abundance)&quot;), xlab = &quot;Diet&quot;, ylim = c(0, 5)) # Ajout des lignes verticales représentant les erreurs # types segments(bp, means - se, bp, means + se, lwd = 2) # et des lignes horizontales segments(bp - 0.1, means - se, bp + 0.1, means - se, lwd = 2) segments(bp - 0.1, means + se, bp + 0.1, means + se, lwd = 2) # ajout d&#39;une ligne à 0 abline(h = 0) 5.1.9 Allons plus loin: Contrastes Les constrastes servent à comparer chaque niveau du facteur à un niveau de référence, et de détecter des différences significatives entre chaque niveau. Les contrastes sont dbasées sur des hypothèses a priori, ce qui les rend beaucoup plus robustes que les test a posteriori comme le test de Tukey. Avec les contrastes, les groupes peuvent être composés d’un ou plusieurs niveaux d’un facteur et on peut tester une hypothèse simple (e.g. μ1 = μ2) ou des hypothèses plus complexes (e.g. (μ1 + μ2)/3 == μ3). Important Le nombre de comparaisons doit être plus petit ou égal au nombre de degrés de liberté de l’ANOVA. Ces comparaisons doivent être indépendantes l’une de l’autre. Pour une ANOVA où la variable prédictrice est catégorique, l’estimation de l’ordonnée à l’origine est le niveau de référence et correspond à la moyenne du premier niveau (en ordre alphabétique) du facteur.En calculant l’ordonnée à l’origine de référence et l’ordonnée à l’origine de chaque niveau de Diet, que remarquez-vous? tapply(bird$logMaxAbund, bird$Diet, mean) ## Insect InsectVert Plant PlantInsect Vertebrate ## 2.656938 1.175378 3.211862 3.629321 1.950036 coef(anov1) ## (Intercept) DietInsectVert DietPlant DietPlantInsect DietVertebrate ## 2.6569384 -1.4815601 0.5549239 0.9723823 -0.7069025 coef(anov1)[1] + coef(anov1)[2] # InsectVert ## (Intercept) ## 1.175378 coef(anov1)[1] + coef(anov1)[3] # Plant ## (Intercept) ## 3.211862 La moyenne de la variable Insect correspond à l’ordonnée à l’origine de notre de notre ANOVA anov1. Il est aussi possible d’afficher ces résultats supplémentaires de l’ANOVA dans R avec la fonction summmary.lm(). Cette sortie montre les résultats de la régression linéaire pour chaque niveau de la variable catégorique. Note: On peut afficher ces résultats avec la fonction summmary.lm() lorsque l’ANOVA a été effectuée avec la fonction aov() et avec la fonction summary() lorsque l’ANOVA a été effectuée avec la fonction lm(). ## ## Call: ## lm(formula = logMaxAbund ~ Diet, data = bird) ## ## Residuals: ## Min 1Q Median 3Q Max ## -4.2664 -0.7592 -0.2028 1.0908 3.5938 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 2.6569 0.3454 7.692 5.66e-10 *** ## DietInsectVert -1.4816 1.1456 -1.293 0.2020 ## DietPlant 0.5549 1.1456 0.484 0.6303 ## DietPlantInsect 0.9724 0.5019 1.938 0.0585 . ## DietVertebrate -0.7069 0.5640 -1.253 0.2161 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 1.545 on 49 degrees of freedom ## Multiple R-squared: 0.188, Adjusted R-squared: 0.1217 ## F-statistic: 2.836 on 4 and 49 DF, p-value: 0.0341 La dernière ligne de cette sortie est identique à la sortie précédente de l’ANOVA. La statistique de F de l’ANOVA et sa valeur de p associée (2.836 et 0.0341 respectivement) sont les mêmes que celles présentées dans la table d’ANOVA, ce qui indique que la variabilité de l’abondance est mieux expliquée par la diète que par un modèle nul; la diète a donc un effet significatif sur l’abondance. L’ajustement du modèle (i.e. le R2 ajusté) apparaît sur l’avant-dernière ligne de la sortie. Dans ce cas-ci, la diète explique 12.17% de la variabilité de l’abondance. Les contrastes sont utilisés pour ajuster une variable réponse en fonction des différents niveaux d’une variable catégorique. Dans le cas de l’abondance en fonction de la diète, cinq régressions linéaires (correspondant aux cinq coefficients dans la sortie de R) sont calculées par la fonction lm(), car la variable Diet contient cinq niveaux. Par défaut, le niveau de référence correspond au premier niveau (en ordre alphabétique) de la variable catégorique. Ce niveau est indiqué par la ligne intercept dans la sortie de R, soit Insect dans ce cas-ci. Ici, le coefficient estimé du niveau de référence est comparé à 0 par un test de t, alors que les autres coefficients sont comparés à celui du niveau de référence. Dans ce cas-ci, seule la diète PlantInsect est différente de la diète Insect (valeur de p = 0.0585). En d’autres mots, cette sortie de R permet de calculer la moyenne de la variable réponse pour chaque niveau de diète. Par exemple : LogMaxAbund = 1.1539 pour la diète Insect, LogMaxAbund = 1.1539 – 0.6434 pour la diète InsectVert, LogMaxAbund = 1.1539 + 0.2410 pour la diète Plant, etc. Ce type de contrastes compare chaque niveau de la variable explicative à un niveau de référence. Dans R, ceci correspond à la fonction contr.treatment() et représentent la méthode par défaut de la fonction lm(). Le niveau de référence peut être changé en utilisant la fonction relevel(). Par exemple,les lignes suivantes comparent chaque diète à la diète Plant maintenant définie comme le niveau de référence. bird$Diet2 &lt;- relevel(bird$Diet, ref = &quot;Plant&quot;) anov2 &lt;- lm(logMaxAbund ~ Diet2, data = bird) summary(anov2) ## ## Call: ## lm(formula = logMaxAbund ~ Diet2, data = bird) ## ## Residuals: ## Min 1Q Median 3Q Max ## -4.2664 -0.7592 -0.2028 1.0908 3.5938 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 3.2119 1.0923 2.941 0.00499 ** ## Diet2Insect -0.5549 1.1456 -0.484 0.63026 ## Diet2InsectVert -2.0365 1.5447 -1.318 0.19351 ## Diet2PlantInsect 0.4175 1.1513 0.363 0.71848 ## Diet2Vertebrate -1.2618 1.1798 -1.070 0.29006 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 1.545 on 49 degrees of freedom ## Multiple R-squared: 0.188, Adjusted R-squared: 0.1217 ## F-statistic: 2.836 on 4 and 49 DF, p-value: 0.0341 anova(anov2) ## Analysis of Variance Table ## ## Response: logMaxAbund ## Df Sum Sq Mean Sq F value Pr(&gt;F) ## Diet2 4 27.071 6.7677 2.8363 0.0341 * ## Residuals 49 116.918 2.3861 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Il est aussi possible de réordonné les niveaux selon leur médiane, plutôt que par ordre alphabétique: med &lt;- sort(tapply(bird$logMaxAbund, bird$Diet, median)) bird$Diet2 &lt;- factor(bird$Diet, levels = names(med)) anov2 &lt;- lm(logMaxAbund ~ Diet2, data = bird) summary(anov2) ## ## Call: ## lm(formula = logMaxAbund ~ Diet2, data = bird) ## ## Residuals: ## Min 1Q Median 3Q Max ## -4.2664 -0.7592 -0.2028 1.0908 3.5938 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 1.1754 1.0923 1.076 0.2872 ## Diet2Vertebrate 0.7747 1.1798 0.657 0.5145 ## Diet2Insect 1.4816 1.1456 1.293 0.2020 ## Diet2Plant 2.0365 1.5447 1.318 0.1935 ## Diet2PlantInsect 2.4539 1.1513 2.131 0.0381 * ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 1.545 on 49 degrees of freedom ## Multiple R-squared: 0.188, Adjusted R-squared: 0.1217 ## F-statistic: 2.836 on 4 and 49 DF, p-value: 0.0341 anova(anov2) ## Analysis of Variance Table ## ## Response: logMaxAbund ## Df Sum Sq Mean Sq F value Pr(&gt;F) ## Diet2 4 27.071 6.7677 2.8363 0.0341 * ## Residuals 49 116.918 2.3861 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 La matrice de coefficients de contrastes peut être affichée par la commande suivante : bird$Diet2 &lt;- relevel(bird$Diet, ref = &quot;Plant&quot;) contrasts(bird$Diet2) ## Insect InsectVert PlantInsect Vertebrate ## Plant 0 0 0 0 ## Insect 1 0 0 0 ## InsectVert 0 1 0 0 ## PlantInsect 0 0 1 0 ## Vertebrate 0 0 0 1 où chaque colonne représente une comparaison avec le niveau de référence Plant et chaque ligne représente un type de diète. Par exemple, la première comparaison est effectuée entre les diètes Plant et Insect. La seconde comparaison est effectuée entre Plant et InsectVert etc. Un point important à remarquer à propos du contraste par défaut dans R contr.treatment est qu’il n’est PAS orthogonal, c’est-à-dire que la somme des produits de leurs coefficients n’est PAS nulle. Nou pouvons vérifier que les contrastes sont orthogonaux en s’assurant que: - La somme des coefficients doit être égale à 0 - La somme du produit de deux colonnes égale 0 sum(contrasts(bird$Diet2)[, 1]) # condition 1 pour colonne 1 ## [1] 1 sum(contrasts(bird$Diet2)[, 1] * contrasts(bird$Diet2)[, 2]) # condition 2 pour colonne 1 et 2 ## [1] 0 La première colonne éagle à 1, signifiant que les contrastes ne sont pas orthogonaux. L’orthogonalité est importante pour s’assurer que nos contrastes sont indépendants. Nous pouvons utiliser des contrastes de Helmert ou des contrastes polynomiaux pour remédier à ce problème. Les contrastes Helmert vont contraster le deuxième niveau avec le premier, le troisième avec la moyenne des deux premiers niveaux, etc. options(contrasts = c(&quot;contr.helmert&quot;, &quot;contr.poly&quot;)) sum(contrasts(bird$Diet2)[, 1]) ## [1] 0 sum(contrasts(bird$Diet2)[, 1] * contrasts(bird$Diet2)[, 2]) ## [1] 0 Nos conditions sont mainteant nulles et nos contrastes orthogonaux. anov3 &lt;- lm(logMaxAbund ~ Diet, data = bird) summary(anov3) ## ## Call: ## lm(formula = logMaxAbund ~ Diet, data = bird) ## ## Residuals: ## Min 1Q Median 3Q Max ## -4.2664 -0.7592 -0.2028 1.0908 3.5938 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 2.5247 0.3369 7.495 1.14e-09 *** ## Diet1 -0.7408 0.5728 -1.293 0.2020 ## Diet2 0.4319 0.4111 1.051 0.2986 ## Diet3 0.3203 0.1603 1.999 0.0512 . ## Diet4 -0.1437 0.1206 -1.191 0.2393 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 1.545 on 49 degrees of freedom ## Multiple R-squared: 0.188, Adjusted R-squared: 0.1217 ## F-statistic: 2.836 on 4 and 49 DF, p-value: 0.0341 Il est aussi possible de créer sa propre matrice de coefficients de contrastes afin d’effectuer certaines comparaisons bien précises à l’aide de la fonction contrasts(). Par exemple, les lignes suivantes créent la matrice de coefficients de contrastes suivante : contrasts(bird$Diet2) &lt;- cbind(c(4, -1, -1, -1, -1), c(0, 1, 1, -1, -1), c(0, 0, 0, 1, -1), c(0, 1, -1, 0, 0)) contrasts(bird$Diet2) ## [,1] [,2] [,3] [,4] ## Plant 4 0 0 0 ## Insect -1 1 0 1 ## InsectVert -1 1 0 -1 ## PlantInsect -1 -1 1 0 ## Vertebrate -1 -1 -1 0 qui compare : la diète Plant à toutes les autres diètes dans la première comparaison (colonne), les diètes InsectVert et Insect aux diètes PlantInsect et Vertebrate dans la deuxième comparaison, la diète PlantInsect à la diète Vertebrate dans la troisième comparaison, et la diète Insect à la diète InsectVert dans la quatrième comparaison. Pour chaque colonne, les diètes avec le même coefficient appartiennent au même groupe (e.g. pour la colonne 1, les quatre diètes avec un coefficient de -1 appartiennent au même groupe et sont comparés à la diète avec un coefficient différent; ici la diète Plant avec un coefficient de 4). Il est donc possible d’effectuer n’importe quelle comparaison possible à l’aide d’une matrice de coefficients de contrastes. Vérifions l’orhtogonalité : sum(contrasts(bird$Diet2)[, 1]) # première condition pour la colonne 1 ## [1] 0 sum(contrasts(bird$Diet2)[, 1] * contrasts(bird$Diet2)[, 2]) # deuxième condition pour les colonnes 1 et 2 ## [1] 0 Ces contrastes suivent l’orthogonalité et pourrait donc être utilisés. D’autres types de contrastes utilisés fréquemment sont déjà programmés dans R help(contrasts). 5.2 ANOVA à deux critères de classification Jusqu’ici, les modèles ANOVA que nous avons explorés n’ont eu qu’une seule variable catégorique, mais on peut aussi créer des modèles ANOVA avec plusieurs variables explicatives catégoriques. Quand il y a 2 variables explicatives catégoriques, le modèle est un ANOVA à deux critères de classification. Un ANOVA à deux critères de classification teste plusieurs hypothèses: que la moyenne diffère entre les niveaux de la variable A, que la moyenne ne diffère pas entre les niveaux de la variable B; et qu’il n’y a pas d’interaction entre les variables A et B. Une interaction significative implique que la valeur moyenne de la variable réponse pour chaque niveau de la variable A change selon le niveau de la variable B. Par exemple, la relation entre la couleur d’un fruit et sa masse dépend de l’espèce de la plante: si oui, on peut dire qu’il y a une interaction entre la couleur et l’espèce. Le tableau de calcul de l’ANOVA vu à la section précédente doit être modifié afin d’inclure le deuxième facteur et l’interaction entre ces deux facteurs : Source de variation Degrés de liberté (df) Sommes des carrés des écarts à la moyenne Moyenne des carrés Statistique de F Total \\(abr-1\\) \\(SS_{t}=\\sum_{i,j,k}{}(y_{ijk}-\\overline{y})^2\\) Cases \\(ab-1\\) \\(SS_{Cases}=\\sum_{i,j}(\\overline{y}_{ij}-\\overline{y})^2\\) Intra- case \\(ab(r-1)\\) \\(SS_{\\epsilon}=\\sum_{i,j,k}(y_{ijk}-\\overline{y}_{ij})^2\\) \\(MS_{\\epsilon}=\\frac{SS_{\\epsilon}}{ab(r-1)}\\) Facteur A \\(a-1\\) \\(SS_{A}= rb\\sum_{i}(\\overline{y}_{i.}-\\overline{y})^2\\) \\(MS_{A}=\\frac{SS_{A}}{a-1}\\) \\(F_{A}=\\frac{MS_{A}}{MS_{\\epsilon}}\\) Facteur B \\(b-1\\) \\(SS_{B}= ra\\sum_{j}(\\overline{y}_{.j}-\\overline{y})^2\\) \\(MS_{B}=\\frac{SS_{B}}{b-1}\\) \\({F_B}=\\frac{MS_{B}}{MS_\\epsilon}\\) Intéraction AB   \\((a-1)(b-1)\\) \\(SS_{AB}= r\\sum_{i,j,k}(\\overline{y}_{..k}-\\overline{y}_{.jk}-\\overline{y}_{i.k})^2\\) \\(MS_{AB}=\\frac{SS_{AB}}{(a-1)(b-1)}\\) \\(F_{AB}=\\frac{MS_{AB}}{MS_\\epsilon}\\) a: nombre de niveaux de la variable explicative A b: nombre de niveaux de la variable explicative B r: nombre de répétitions par groupe \\(\\epsilon\\) : erreur 5.2.1 Effectuer une ANOVA à deux critères de classification Dans R, une ANOVA à deux critères de classification est effectuée de la même manière qu’une ANOVA à un critère de classification avec la fonction lm(). ANOVA à un facteur aov &lt;- lm(Y ~ X, data) ANOVA à deux facteurs ou plus aov &lt;- lm(Y ~ X1 * X2 * ..., data) Lorsque vous utilisez le symbole * avec lm(), le modèle inclut les effets de chaque facteur séparément, ainsi que leur interaction. Selon le principe de parcimonie, vous voulez que votre modèle explique le plus possible de la variance observée dans les données, avec le moins de termes possible Enlever le terme d’interaction s’il n’est pas significatif, et ré-exécuter le modèle. Lorsque vous utilisez le symbole + avec lm(), le modèle inclut les effets de chaque facteur séparément (pas d’interaction) aov &lt;- lm(Y ~ X1 + X2 + ..., data) DÉFI 2 Examinez les effets des facteurs \"Diet\", \"Aquatic\" et de leur interaction sur l’abondance maximale d’oiseaux. Rappelez-vous que vous devez vérifier les suppositions statistiques de base avant d’interpréter les résultats d’une ANOVA, soit : - Distribution normale des rsidus du modèle Homoscédasticité des résidus de la variance Cette vérification peut être faite en utilisant les quatre graphiques de diagnostic expliqués dans la section précédente. Cliquez pour voir la solution au Défi 2! Conditions d’applications anov4 &lt;- lm(logMaxAbund ~ Diet * Aquatic, data = bird) opar &lt;- par(mfrow = c(2, 2)) plot(anov4) ## Warning: not plotting observations with leverage one: ## 5, 6, 26 par(opar) La fonction anova() permet de visualiser le tableau d’ANOVA du modèle : anova(anov4) ## Analysis of Variance Table ## ## Response: logMaxAbund ## Df Sum Sq Mean Sq F value Pr(&gt;F) ## Diet 4 27.071 6.7677 3.0378 0.02669 * ## Aquatic 1 1.688 1.6878 0.7576 0.38870 ## Diet:Aquatic 3 14.978 4.9926 2.2410 0.09644 . ## Residuals 45 100.252 2.2278 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Dans ce cas-ci, le seul facteur significatif est la diète. La valeur de p de l’interaction n’est pas significative, ce qui signifie que l’effet de la diète est le même peu importe si l’oiseau est aquatique ou non. Le seuil de signification peut aussi être testé en comparant deux modèles nichés, i.e. en incluant un premier modèle avec une interaction et un deuxième modèle avec sans l’interaction. La fonction anova() est utilisée : anov5 &lt;- lm(logMaxAbund ~ Diet + Aquatic, data = bird) anova(anov5, anov4) ## Analysis of Variance Table ## ## Model 1: logMaxAbund ~ Diet + Aquatic ## Model 2: logMaxAbund ~ Diet * Aquatic ## Res.Df RSS Df Sum of Sq F Pr(&gt;F) ## 1 48 115.23 ## 2 45 100.25 3 14.978 2.241 0.09644 . ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Étant donné que la seule différence entre ces deux modèles est la présence de l’interaction, cette sortie de R présente le seuil de signification de cette interaction. Dans ce cas-ci, l’interaction n’est pas significative et peut donc être retirée du modèle. Lorsque l’interaction est significative, rappelez-vous que chaque facteur ne peut pas être interprété séparément. Seule l’interaction peut l’être. Note : Le tableau d’ANOVA indique que le nombre de degrés de liberté pour l’interaction entre la diète et le type d’oiseau (aquatique ou non) est de 3. Selon la notation mathématique du tableau de l’ANOVA à deux critères de classification (pour les plans équilibrés), a = 5 et b = 2 et le nombre de degrés de liberté est de (a-1)(b-1) = 4*1 = 4. La sortie de R indique cependant que le nombre de degrés de liberté est de 3. Cette interaction est extrêmement non équilibrée () : les oiseaux aquatiques ne se nourrissent pas de plante, donc ce niveau n’est pas considéré (prenez note du NA dans la sortie de summary(anov4)). Consultez la section sur les ANOVA non équilibrées plus bas pour plus de détails. 5.2.2 Diagramme d’interaction Les interactions peuvent être visualisées à l’aide de la fonction interaction.plot() : interaction.plot(bird$Diet, bird$Aquatic, bird$logMaxAbund, col = &quot;black&quot;, ylab = expression(&quot;log&quot;[10] * &quot;(Maximum Abundance)&quot;), xlab = &quot;Diet&quot;) Que signifie le trou sur la ligne des oiseaux aquatiques? table(bird$Diet, bird$Aquatic) ## ## 0 1 ## Insect 14 6 ## InsectVert 1 1 ## Plant 2 0 ## PlantInsect 17 1 ## Vertebrate 5 7 Le plan est non-équilibré: il y a un nombre inégal d’observations entre les diètes pour les oiseaux aquatiques (représentés par le 1) et les oiseaux terrestres (représentés par le 0). Consultez la section avancée ci-dessous pour plus de détails sur les ANOVA à plan non-équilibré. DÉFI 3 Tester le seuil de signification du facteur \"Aquatic\" en comparant deux modèles nichés (i.e. avec et sans ce facteur). Cliquez pour voir la solution au Défi 3! anova(anov1, anov5) # Rappel que anov3 est le modèle avec le facteur &#39;Diet&#39; seulement. ## Analysis of Variance Table ## ## Model 1: logMaxAbund ~ Diet ## Model 2: logMaxAbund ~ Diet + Aquatic ## Res.Df RSS Df Sum of Sq F Pr(&gt;F) ## 1 49 116.92 ## 2 48 115.23 1 1.6878 0.7031 0.4059 5.3 ANOVA non-équilibrée (section avancée/facultative) Les ANOVA à un et à deux critères de classification nous permettent de déterminer les effets de variables catégoriques sur une variable réponse continue lorsque nous avons un plan expérimental équilibré (i.e. lorsque le nombre de répétitions est égal pour chaque niveau de facteur). Cependant, le plan peut devenir non-équilibré en raison d’une perte d’unités expérimentales au cours d’une expérience ou de restrictions techniques dues au plan expérimental. Dans de telles situations, les résultats d’ANOVA peuvent être mal interprétés en raison de calculs erronés de la somme des carrés. Pour des plans expérimentaux non-équilibrés, l’ANOVA doit être modifiée pour prendre en compte les données manquantes de la variable réponse. Un jeu de données est considéré non équilibré lorsque le nombre d’échantillons entre deux niveaux n’est pas égal. Le jeu de données bird est en réalité non équilibré (le nombre d’espèces aquatiques n’égale pas le nombre d’espèces non-aquatiques). table(bird$Aquatic) ## ## 0 1 ## 39 15 Le modèle mathématique, les hypothèses statistiques, et les conditions de base d’une ANOVA à plan non-équilibré demeurent les mêmes que deux de l’ANOVA à plan équilibré. Le calcul de la somme des carrés, par contre, est différent. Pour un plan expérimental non-équilibré, les hypothèses statistiques sont les suivantes : H0: µ1 = µ2 =... = µi =... = µn H1: il y a au moins une moyenne µi qui diffère des autres. On utilise ce modèle mathématique : \\(y_{ijk} = µ + A_{i} + B_{j} + A_{i}B_{j} + ε_{ijk}\\) Rappelez-vous du calcul de la somme des carrés dans le cas d’une ANOVA à plan équilibré : \\[ SS_{A} = rb\\sum_{i}(\\overline{y}_{i.}-\\overline{y})^2 = SS(A)\\] \\[ SS_{B} = ra \\sum_{j}(\\overline{y}_{.j}-\\overline{y})^2 = SS(B\\|A) = SS(A,B)-SS(B)\\] \\[ SS_{AB} = r \\sum{i,j,k}(\\overline{y}_{..k}-\\overline{y}_{.jk}-\\overline{y}_{i.k})^2= SS(A,B,AB)-SS(A,B)\\] Ceci correspond à une somme des carrés séquentielle (aussi appelée de Type I), car l’effet d’un facteur B est calculé après avoir retiré l’effet d’un facteur A. L’interaction est calculée après avoir retiré les effets principaux de ces deux facteurs. Le Type I est le paramètre par défaut dans R. Ces calculs dépendent de la taille de l’échantillon, car l’effet de chaque facteur est calculé après avoir retiré l’effet du facteur précédent. Dans le cas d’un plan expérimental non-équilibré, les résultats d’ANOVA dépendent de l’ordre dans lequel chaque variable apparaît dans le modèle. Voyez comment les résultats diffèrent en comparant les deux modèles suivants : unb_anov1 &lt;- lm(logMaxAbund ~ Aquatic + Diet, data = bird) unb_anov2 &lt;- lm(logMaxAbund ~ Diet + Aquatic, data = bird) anova(unb_anov1) ## Analysis of Variance Table ## ## Response: logMaxAbund ## Df Sum Sq Mean Sq F value Pr(&gt;F) ## Aquatic 1 1.228 1.2278 0.5114 0.47798 ## Diet 4 27.531 6.8827 2.8671 0.03291 * ## Residuals 48 115.230 2.4006 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 anova(unb_anov2) ## Analysis of Variance Table ## ## Response: logMaxAbund ## Df Sum Sq Mean Sq F value Pr(&gt;F) ## Diet 4 27.071 6.7677 2.8191 0.03517 * ## Aquatic 1 1.688 1.6878 0.7031 0.40591 ## Residuals 48 115.230 2.4006 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Bien que les variables explicatives soient les mêmes pour chaque modèle, les tableaux d’ANOVA montrent des résultats différents à cause d’un plan non-équilibré (i.e. un nombre différent d’observations pour les oiseaux aquatiques et terrestres). La somme des carrés de Type II teste les effets de chaque facteur, mais après avoir tester l’autre facteur. Pour les plans non-équilibrés, une somme des carrés marginale (aussi appelée de Type III) est souvent utilisé. Cela permet de calculer un effet principal après avoir retiré les effets des autres facteurs. Ceci rend le calcul indépendant de la taille des échantillons. Si vous considérez utiliser le Type II ou III avec vos propres données, vous devriez en lire plus sur le sujet avant de choisir. Vous pouvez commencer avec ce lien L’équation mathématique pour une somme des carrés de Type III correspond à: \\[SS_{A}=SS(A\\|B,AB)=SS(A,B,AB)-SS(B,AB)\\] \\[SS_{B}=SS(B\\|A,AB)=SS(A,B,AB)-SS(A,AB)\\] \\[SS_{AB}=SS(AB\\|B,A)=SS(A,B,AB)-SS(B,AB)\\] Dans R, une ANOVA avec somme des carrés de type III peut être effectuée avec la fonction Anova() du paquet car et en spécifiant l’argument type=\"III\" : library(car) Anova(unb_anov1, type = &quot;III&quot;) ## Anova Table (Type III tests) ## ## Response: logMaxAbund ## Sum Sq Df F value Pr(&gt;F) ## (Intercept) 100.391 1 41.8186 4.837e-08 *** ## Aquatic 1.688 1 0.7031 0.40591 ## Diet 27.531 4 2.8671 0.03291 * ## Residuals 115.230 48 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Anova(unb_anov2, type = &quot;III&quot;) ## Anova Table (Type III tests) ## ## Response: logMaxAbund ## Sum Sq Df F value Pr(&gt;F) ## (Intercept) 100.391 1 41.8186 4.837e-08 *** ## Diet 27.531 4 2.8671 0.03291 * ## Aquatic 1.688 1 0.7031 0.40591 ## Residuals 115.230 48 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 En comparant les tableaux d’ANOVA de modèles avec un ordre différent dans les variables explicatives, on peut voir que les résultats sont les mêmes. L’utilisation de la somme des carrés de type III produit une ANOVA qui est indépendante de la tailles des échantillons. Après avoir vérifié les suppositions du modèle, les résultats peuvent finalement être interprétés correctement. 5.4 6. ANCOVA L’analyse de covariance (ANCOVA) est un modèle linéaire qui teste l’influence d’une (ou plusieurs) variable explicative catégorique sur une variable réponse continue. Chaque niveau de la variable catégorique est décrit par une pente (ou coefficient de variation) et une ordonnée à l’origine. En plus de tester si la variable réponse diffère pour au moins un niveau de la variable catégorique, l’ANCOVA teste aussi si la variable réponse est influencée par sa relation avec la variable continue (nommée la covariable dans une ANCOVA), et par une différence dans l’influence de la variable continue sur la réponse (i.e. l’interaction) entre les niveaux de groupe. Les hypothèses d’un ANCOVA sont alors: qu’il n’y a pas de différence de moyenne entre les niveaux de la variable catégorique; qu’il n’y a pas de correlation entre la variable réponse et la variable explicative catégorique; et qu’il n’y a pas d’interaction entre les variables catégoriques et continues. \\(Y = X * Z\\) où: \\(Y\\): Variable réponse est continue \\(X\\): Varaible prédictrice est catégorique (facteur) \\(Z\\): Varaible prédictrice est continue \\[Y = \\mu + Effets Principaux Facteurs + Intéraction entre Facteurs + Effets Principaux Covariables + Intéractions entre Covariables Facteurs + \\epsilon\\] 5.4.1 6.1 Conditions de base En plus des conditions d’application des modèles linéaires, les modèles ANCOVA doivent respecter : Les covariables ont toutes la même étendue de valeurs Les variables sont fixes Les variables catégoriques et continues sont indépendantes Note : Un variable fixe est une variable d’intérêt pour une étude (e.g. la masse des oiseaux). En comparaison, une variable aléatoire représente surtout une source de bruit qu’on veut contrôler (i.e. le site où les oiseaux ont été échantillonnés). Si votre modèle comporte des effets aléatoires, consultez l’atelier 7 sur les modèles linéaires et généralisés linéaires mixtes! 5.4.2 6.2 Types d’ANCOVA Il est possible d’avoir plusieurs facteurs (i.e. variables explicatives catégoriques) et covariables (i.e. variables explicatives continues) au sein d’une même ANCOVA. Par contre, l’interprétation des résultats devient de plus en plus complexe à mesure que le nombre de covariables et de facteurs augmente. Les ANCOVA les plus courantes comportent : une covariable et un facteur une covariable et deux facteurs deux covariables et un facteur Les buts possibles de l’ANCOVA sont de déterminer les effets : des facteurs et des covariables sur la variable réponse des facteurs sur la variable réponse après avoir retiré l’effet des covariables des facteurs sur la relation existant entre les covariables et la variable réponse Ces buts ne sont atteints que s’il n’y a pas d’interaction significative entre le(s) facteur(s) et la(les) covariable(s)! Des exemples d’interaction significative entre un facteur et une covariable (pour une ANCOVA avec un facteur et une covariable) sont illustrés ci-dessous dans les deux derniers graphiques: Si l’interaction est significative, vous aurez un scénario qui ressemble aux graphiques de gauche et central. Si votre covariable et votre facteur sont significatifs, vous avez un cas comme le graphique de droite. La même logique s’applique aux ANCOVAs à plusieurs facteurs et/ou covariables. 5.4.3 6.3 Effectuer une ANCOVA Effectuer une ANCOVA dans R ressemble à une ANOVA à deux critères de classification : on utilise la fonction lm(). Toutefois, au lieu d’avoir deux variables catégoriques (par exemple, \"Diet\" et \"Aquatic\"), on utilise maintenant une variable catégorique et une variable continue. Par exemple, en utilisant le jeu de données CO2 (déjà inclus dans R) où la variable réponse est uptake, on peut effectuer une ANCOVA avec la variable continue conc et le facteur Treatment : ancova.example &lt;- lm(uptake ~ conc * Treatment, data = CO2) anova(ancova.example) ## Analysis of Variance Table ## ## Response: uptake ## Df Sum Sq Mean Sq F value Pr(&gt;F) ## conc 1 2285.0 2284.99 28.5535 8.377e-07 *** ## Treatment 1 988.1 988.11 12.3476 0.0007297 *** ## conc:Treatment 1 31.9 31.87 0.3983 0.5297890 ## Residuals 80 6402.0 80.02 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 -Si l’analyse indique que seule la covariable est significative, on retire le facteur du modèle; on revient à une ANOVA à un critère de classification. -Si l’analyse indique que seul le facteur est significatif, on retire la covariable du modèle; on revient à une régression linéaire simple. -Si l’analyse indique que l’interaction est significative, il faut trouver quels niveaux ont une pente différente. Dans l’exemple du jeu de données CO2, la covariable et le facteur sont significatifs, mais l’interaction n’est pas significative. Si on remplace le facteur Treatment par le facteur Type, l’interaction devient significative. Si vous voulez comparer les moyennes de la variable réponse entre les facteurs, vous pouvez utiliser les moyennes ajustées qui sont calculées comme dans l’équation de l’ANCOVA et en tenant compte de l’effet de la covariable : install.packages(&quot;effects&quot;) library(effects) Si vous voulez comparer les moyennes des différents facteurs, vous pouvez utiliser les moyennes ajustées. La fonction effect() utilise les équations données par l’ANCOVA pour estimer les moyennes de chaque niveau, corrigées pour l’effet de la covariable. adj.means.ex &lt;- effect(&quot;Treatment&quot;, ancova.example) ## NOTE: Treatment is not a high-order term in the model plot(adj.means.ex) DÉFI 4 Effectuez une ANCOVA qui teste l’effet du facteur Diet, de la covariable Mass, et de leur interaction sur la variable réponse MaxAbund. Variable réponse: MaxAbund Variables prédictrices: -Diet (facteur avec 5 groupes) -Mass (numérique, continuous) str(bird) ## &#39;data.frame&#39;: 54 obs. of 9 variables: ## $ Family : chr &quot;Hawks&amp;Eagles&amp;Kites&quot; &quot;Long-tailed tits&quot; &quot;Larks&quot; &quot;Kingfishers&quot; ... ## $ MaxAbund : num 2.99 37.8 241.4 4.4 4.53 ... ## $ AvgAbund : num 0.674 4.04 23.105 0.595 2.963 ... ## $ Mass : num 716 5.3 35.8 119.4 315.5 ... ## $ Diet : Factor w/ 5 levels &quot;Insect&quot;,&quot;InsectVert&quot;,..: 5 1 4 5 2 4 5 1 1 5 ... ## $ Passerine : int 0 1 1 0 0 0 0 0 0 0 ... ## $ Aquatic : int 0 0 0 0 1 1 1 0 1 1 ... ## $ logMass : num 6.57 1.67 3.58 4.78 5.75 ... ## $ logMaxAbund: num 1.09 3.63 5.49 1.48 1.51 ... Cliquez pour voir la solution au Défi 3! # Si vous avez complété la section avancée sur les # contrastes, vous devrez réinitialiser les contrastes à # l&#39;aide de la fonction &#39;&#39;options()&#39;&#39; Si vous n&#39;avez pas # complété la section avancée sur les contrastes, ignorez # la première ligne du script. options(contrasts = c(&quot;contr.treatment&quot;, &quot;contr.poly&quot;)) # solution ancov1 &lt;- lm(logMaxAbund ~ logMass * Diet, data = bird) anova(ancov1) ## Analysis of Variance Table ## ## Response: logMaxAbund ## Df Sum Sq Mean Sq F value Pr(&gt;F) ## logMass 1 10.464 10.4637 4.6054 0.03743 * ## Diet 4 17.749 4.4372 1.9530 0.11850 ## logMass:Diet 4 15.805 3.9513 1.7391 0.15849 ## Residuals 44 99.971 2.2721 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 summary(ancov1) ## ## Call: ## lm(formula = logMaxAbund ~ logMass * Diet, data = bird) ## ## Residuals: ## Min 1Q Median 3Q Max ## -4.1308 -0.7081 -0.0855 0.9854 2.5694 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 3.7384 0.8042 4.648 3.05e-05 *** ## logMass -0.2865 0.1934 -1.481 0.1457 ## DietInsectVert -4.4599 6.1652 -0.723 0.4733 ## DietPlant 1.6796 4.7819 0.351 0.7271 ## DietPlantInsect 0.5537 1.3860 0.400 0.6914 ## DietVertebrate -7.7409 2.9359 -2.637 0.0115 * ## logMass:DietInsectVert 0.6745 1.2463 0.541 0.5911 ## logMass:DietPlant -0.2631 1.1602 -0.227 0.8216 ## logMass:DietPlantInsect 0.1115 0.3427 0.325 0.7465 ## logMass:DietVertebrate 1.1665 0.4556 2.561 0.0140 * ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 1.507 on 44 degrees of freedom ## Multiple R-squared: 0.3057, Adjusted R-squared: 0.1637 ## F-statistic: 2.153 on 9 and 44 DF, p-value: 0.04469 Dans ce cas-ci, l’interaction n’est pas significative, ce qui signifie que l’effet de la masse sur l’abondance maximale est le même peu importe la diète. L’interaction est retirée du modèle et l’ANCOVA devient : ancov2 &lt;- lm(logMaxAbund ~ logMass + Diet, data = bird) anova(ancov2) ## Analysis of Variance Table ## ## Response: logMaxAbund ## Df Sum Sq Mean Sq F value Pr(&gt;F) ## logMass 1 10.464 10.4637 4.3382 0.04262 * ## Diet 4 17.749 4.4372 1.8396 0.13664 ## Residuals 48 115.776 2.4120 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 R nous indique que la diète n’est pas significative non plus, donc ce terme est retiré du modèle. Notre modèle final devient donc une régression linéaire simple : lm2 &lt;- lm(logMaxAbund ~ logMass, data = bird) summary(lm2) ## ## Call: ## lm(formula = logMaxAbund ~ logMass, data = bird) ## ## Residuals: ## Min 1Q Median 3Q Max ## -4.4569 -0.9206 0.1263 0.9354 3.7180 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 3.8508 0.5691 6.767 1.17e-08 *** ## logMass -0.2361 0.1170 -2.019 0.0487 * ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 1.602 on 52 degrees of freedom ## Multiple R-squared: 0.07267, Adjusted R-squared: 0.05484 ## F-statistic: 4.075 on 1 and 52 DF, p-value: 0.04869 Les résultats de l’analyse peuvent être représentés graphiquement. On trace la variable réponse en fonction de la variable explicative continue avec des points et des lignes de différentes couleurs pour les différents niveaux de la variable catégorique. Nous pouvons aussi tracez un diagramme représentant les pentes et ordonnées à l’origine d’une ANCOVA (le modèle ancov1 plus haut) à l’aide des fonctions abline() et coef(). coef(ancov1) ## (Intercept) logMass DietInsectVert ## 3.7384247 -0.2864726 -4.4598537 ## DietPlant DietPlantInsect DietVertebrate ## 1.6795975 0.5537085 -7.7409274 ## logMass:DietInsectVert logMass:DietPlant logMass:DietPlantInsect ## 0.6744893 -0.2631444 0.1114568 ## logMass:DietVertebrate ## 1.1665348 plot(logMaxAbund ~ logMass, data = bird, col = Diet, pch = 19, ylab = expression(&quot;log&quot;[10] * &quot;(Maximum Abundance)&quot;), xlab = expression(&quot;log&quot;[10] * &quot;(Mass)&quot;)) abline(a = coef(ancov1)[1], b = coef(ancov1)[2], col = &quot;deepskyblue1&quot;) abline(a = sum(coef(ancov1)[1] + coef(ancov1)[3]), b = sum(coef(ancov1)[2] + coef(ancov1)[7]), col = &quot;green2&quot;, lwd = 2) abline(a = sum(coef(ancov1)[1] + coef(ancov1)[4]), b = sum(coef(ancov1)[2] + coef(ancov1)[8]), col = &quot;orange1&quot;, lwd = 2) abline(a = sum(coef(ancov1)[1] + coef(ancov1)[5]), b = sum(coef(ancov1)[2] + coef(ancov1)[9]), col = &quot;lightsteelblue1&quot;, lwd = 2) abline(a = sum(coef(ancov1)[1] + coef(ancov1)[6]), b = sum(coef(ancov1)[2] + coef(ancov1)[10]), col = &quot;darkcyan&quot;, lwd = 2) "],["régression-multiple.html", "Chapitre 6 Régression multiple 6.1 Conditions d’application 6.2 Régression linéaire multiple dans R 6.3 Régression polynomiale (matériel facultatif) 6.4 Partitionnement de la variation (matériel facultatif)", " Chapitre 6 Régression multiple Une régression multiple teste les effets de plusieurs variables explicatives continues sur une variable réponse continue. Elle se distingue de la régression linéaire simple en ayant plusieurs variables explicatives. 6.0.1 Formulation du modèle Les variables La régression linéaire multiple sont définies par les variables \\(y\\) représentant la variable réponse (continue) et \\(x\\) pour les variables explicatives (continues ou catégoriques). La relation supposée La relation entre la variable réponse et les prédicteurs se définit comme pour la régression simple. La différence est dans l’ajout de paramètres \\(\\beta\\) pour les variables supplémentaires : \\[y_i = \\beta_0 + \\beta_1x_{1,i}+\\beta_2x_{2,i}+\\beta_3x_{3,i}+...+\\beta_kx_{k,i} + \\epsilon_i\\] Le paramètre \\(\\beta_0\\) est l’ordonnée à l’origine (ou constante) Les paramètres \\(\\beta_1\\) quantifie l’effet de \\(x\\) sur \\(y\\) Le résidu \\(\\epsilon_i\\) représente la variation non expliquée La valeur prédite de \\(y_i\\) se définit comme : \\(\\hat{y}_i = \\beta_0 + \\beta_1x_{1,i}+\\beta_2x_{2,i}+\\beta_3x_{3,i}+...+\\beta_kx_{k,i}\\). La variation non expliquée ou l’erreur demeure distribuée normalement, centrée sur zéro avec une variance de \\(\\sigma^2\\) : \\[\\epsilon_i \\sim \\mathcal{N}(0,\\,\\sigma^2)\\] 6.1 Conditions d’application Dans le cas des régressions linéaires multiples, deux conditions d’application s’ajoutent conditions habituelles des modèles linéaires. Premièrement, il doit y avoir une relation linéaire entre chaque variable explicative et la variable réponse. Deuxièmement, les variables explicatives sont indépendantes les unes des autres (il n’y a pas de colinéarité). 6.1.1 En cas de colinéarité En cas de colinéarité, il existe quelques solutions : Garder seulement une des variables colinéaires Essayer une analyse multidimensionnelle (voir l’atelier 9) Essayer une analyse pseudo-orthogonale 6.2 Régression linéaire multiple dans R 6.2.1 Les données En utilisant le jeu de données Dickcissel nous comparerons l’importance relative du climat (clTma), de la productivité (NDVI) et de la couverture du sol (grass) comme prédicteurs de l’abondance de dickcissels (abund). Dickcissel = read.csv(&quot;data/dickcissel.csv&quot;) str(Dickcissel) ## &#39;data.frame&#39;: 646 obs. of 15 variables: ## $ abund : num 5 0.2 0.4 0 0 0 0 0 0 0 ... ## $ Present : chr &quot;Absent&quot; &quot;Absent&quot; &quot;Absent&quot; &quot;Present&quot; ... ## $ clDD : num 5543 5750 5395 5920 6152 ... ## $ clFD : num 83.5 67.5 79.5 66.7 57.6 59.2 59.5 51.5 47.4 46.3 ... ## $ clTmi : num 9 9.6 8.6 11.9 11.6 10.8 10.8 11.6 13.6 13.5 ... ## $ clTma : num 32.1 31.4 30.9 31.9 32.4 32.1 32.3 33 33.5 33.4 ... ## $ clTmn : num 15.2 15.7 14.8 16.2 16.8 ... ## $ clP : num 140 147 148 143 141 ... ## $ NDVI : int -56 -44 -36 -49 -42 -49 -48 -50 -64 -58 ... ## $ broadleaf: num 0.3866 0.9516 0.9905 0.0506 0.2296 ... ## $ conif : num 0.0128 0.0484 0 0.9146 0.7013 ... ## $ grass : num 0 0 0 0 0 0 0 0 0 0 ... ## $ crop : num 0.2716 0 0 0.0285 0.044 ... ## $ urban : num 0.2396 0 0 0 0.0157 ... ## $ wetland : num 0 0 0 0 0 0 0 0 0 0 ... 6.2.2 Vérification des conditions d’application Il faut d’abord vérifier la présence de colinéarité entre toutes les variables explicatives et d’intérêt : # Sélectionner lesvariables var &lt;- c(&quot;clTma&quot;, &quot;NDVI&quot;, &quot;grass&quot;, &quot;abund&quot;) # Graphiques des relations entre variables plot(Dickcissel[, var]) Un patron observable entre deux variables explicatives peut indiquer qu’elles sont colinéaires ! Vous devez éviter ceci, sinon leurs effets sur la variable réponse seront confondus. 6.2.3 Régression linéaire Maintenant, exécutons la régression multiple de l’abondance (abund) en fonction des variables clTma + NDVI + grass : # Régression multiple lm.mult &lt;- lm(abund ~ clTma + NDVI + grass, data = Dickcissel) summary(lm.mult) ## ## Call: ## lm(formula = abund ~ clTma + NDVI + grass, data = Dickcissel) ## ## Residuals: ## Min 1Q Median 3Q Max ## -35.327 -11.029 -4.337 2.150 180.725 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) -83.60813 11.57745 -7.222 1.46e-12 *** ## clTma 3.27299 0.40677 8.046 4.14e-15 *** ## NDVI 0.13716 0.05486 2.500 0.0127 * ## grass 10.41435 4.68962 2.221 0.0267 * ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 22.58 on 642 degrees of freedom ## Multiple R-squared: 0.117, Adjusted R-squared: 0.1128 ## F-statistic: 28.35 on 3 and 642 DF, p-value: &lt; 2.2e-16 Puis, vérifions les autres conditions d’application, comme pour la régression linéaire simple : # Conditions d&#39;application par(mfrow = c(2, 2), mar = c(3.9, 4, 1.2, 1.1), oma = c(0, 0, 0, 0)) plot(lm.mult) 6.2.4 Définir le meilleur modèle Il existe un principe de première importance dans la sélection de modèles. Il s’agit du principe de parcimonie. C’est-à-dire, expliquer le plus de variation avec le plus petit nombre de termes. Nous pourrions donc enlever la variable la moins significative. summary(lm.mult)$coefficients ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) -83.6081274 11.5774529 -7.221634 1.458749e-12 ## clTma 3.2729872 0.4067706 8.046272 4.135118e-15 ## NDVI 0.1371634 0.0548603 2.500231 1.265953e-02 ## grass 10.4143451 4.6896157 2.220725 2.671787e-02 Les 3 variables sont importantes. On garde tout ! Le modèle explique 11.28% de la variabilité de l’abondance de dickcissels \\(R²_{adj} = 0.11\\). Toutefois, ces informations ne sont pas valables, car les conditions d’application du modèle linéaire ne sont pas respectées. Il est important de noter que la variable réponse ne varie pas de façon linéaire avec les variables explicatives : par(mfrow = c(1, 3), mar = c(4, 4, 0.5, 0.5), cex = 1) plot(abund ~ clTma, data = Dickcissel) plot(abund ~ NDVI, data = Dickcissel) plot(abund ~ grass, data = Dickcissel) 6.3 Régression polynomiale (matériel facultatif) Comme nous l’avons remarqué dans la section sur la régression linéaire multiple, certaines variables semblent avoir des relations non-linéaires avec la variable abund. Pour tester des relations non-linéaires, des régressions polynomiales de différents degrés sont comparées Un modèle polynômial ressemble à ceci : \\[\\underbrace{2x^4}+\\underbrace{3x}-\\underbrace{2}\\] Ce polynôme a trois termes. Pour un polynôme avec une variable (comme \\(x\\) ), le degré est l’exposant le plus élevé de cette variable. Nous avons ici un polynôme de degré 4: \\[2x^\\overbrace{4} + 3x - 2\\] Lorsque vous connaissez le degré, vous pouvez lui donner un nom : Degré Nom Example 0 Constante \\(3\\) 1 Linéaire \\(x+9\\) 2 Quadratique \\(x^2-x+4\\) 3 Cubique \\(x^3-x^2+5\\) 4 Quartique \\(6x^4-x^3+x-2\\) 5 Quintique \\(x^5-3x^3+x^2+8\\) Nous pouvson maintenant règler notre problème avec le jeu de données Dickcisselen testant la relation non-linéaire entre l’abondance et la température en comparant trois modèles polynômiaux groupés (de degrés 0, 1, and 3) : lm.linear &lt;- lm(abund ~ clDD, data = Dickcissel) lm.quad &lt;- lm(abund ~ clDD + I(clDD^2), data = Dickcissel) lm.cubic &lt;- lm(abund ~ clDD + I(clDD^2) + I(clDD^3), data = Dickcissel) En comparant les modèles polynomiaux, nous pouvons déterminer quel modèle niché nous devrions sélectionner: summary(lm.linear) ## ## Call: ## lm(formula = abund ~ clDD, data = Dickcissel) ## ## Residuals: ## Min 1Q Median 3Q Max ## -17.062 -10.608 -7.758 -2.487 193.128 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 1.864566 2.757554 0.676 0.49918 ## clDD 0.001870 0.000588 3.180 0.00154 ** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 23.81 on 644 degrees of freedom ## Multiple R-squared: 0.01546, Adjusted R-squared: 0.01393 ## F-statistic: 10.11 on 1 and 644 DF, p-value: 0.001545 summary(lm.quad) ## ## Call: ## lm(formula = abund ~ clDD + I(clDD^2), data = Dickcissel) ## ## Residuals: ## Min 1Q Median 3Q Max ## -14.057 -12.253 -8.674 1.495 190.129 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) -1.968e+01 5.954e+00 -3.306 0.001 ** ## clDD 1.297e-02 2.788e-03 4.651 4.00e-06 *** ## I(clDD^2) -1.246e-06 3.061e-07 -4.070 5.28e-05 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 23.53 on 643 degrees of freedom ## Multiple R-squared: 0.04018, Adjusted R-squared: 0.0372 ## F-statistic: 13.46 on 2 and 643 DF, p-value: 1.876e-06 summary(lm.cubic) ## ## Call: ## lm(formula = abund ~ clDD + I(clDD^2) + I(clDD^3), data = Dickcissel) ## ## Residuals: ## Min 1Q Median 3Q Max ## -14.417 -12.247 -8.394 1.473 189.955 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) -1.465e+01 1.206e+01 -1.215 0.225 ## clDD 8.612e-03 9.493e-03 0.907 0.365 ## I(clDD^2) -1.628e-07 2.277e-06 -0.071 0.943 ## I(clDD^3) -8.063e-11 1.680e-10 -0.480 0.631 ## ## Residual standard error: 23.54 on 642 degrees of freedom ## Multiple R-squared: 0.04053, Adjusted R-squared: 0.03605 ## F-statistic: 9.04 on 3 and 642 DF, p-value: 7.202e-06 Quel modèle devriez-vous choisir 6.4 Partitionnement de la variation (matériel facultatif) Certaines variables explicatives de la régression linéaire multiple étaient fortement corrélées (c.-à-d.multicolinéarité) La colinéarité entre variables explicatives peut être détectée à l’aide de critères d’inflation de la variance (fonction vif() du package car). Les valeurs supérieures à 5 sont considérées colinéaires: mod &lt;- lm(clDD ~ clFD + clTmi + clTma + clP + grass, data = Dickcissel) car::vif(mod) ## clFD clTmi clTma clP grass ## 13.605855 9.566169 4.811837 3.196599 1.165775 Dans cet exemple, clFD,clTmi etclTma sont colinéaires avec clDD. Plutôt que d’enlever des variables à notre modèle, il est possible réduire l’effet de colinéarité en regroupant certaines variables entre elles. Vous pouvez utiliser varpart() afin de partitionner la variation de la variable abund avec toutes les variables de la couverture du paysage groupées ensemble (\"broadleaf\",\"conif\",\"grass\",\"crop\", \"urban\",\"wetland\") et toutes les variables du climat groupées ensemble (\"clDD\",\"clFD\",\"clTmi\",\"clTma\",\"clP\"). Laissez NDVI à part library(vegan) part.lm = varpart(Dickcissel$abund, Dickcissel[, c(&quot;clDD&quot;, &quot;clFD&quot;, &quot;clTmi&quot;, &quot;clTma&quot;, &quot;clP&quot;)], Dickcissel[, c(&quot;broadleaf&quot;, &quot;conif&quot;, &quot;grass&quot;, &quot;crop&quot;, &quot;urban&quot;, &quot;wetland&quot;)]) part.lm ## ## Partition of variance in RDA ## ## Call: varpart(Y = Dickcissel$abund, X = Dickcissel[, c(&quot;clDD&quot;, &quot;clFD&quot;, ## &quot;clTmi&quot;, &quot;clTma&quot;, &quot;clP&quot;)], Dickcissel[, c(&quot;broadleaf&quot;, &quot;conif&quot;, ## &quot;grass&quot;, &quot;crop&quot;, &quot;urban&quot;, &quot;wetland&quot;)]) ## ## Explanatory tables: ## X1: Dickcissel[, c(&quot;clDD&quot;, &quot;clFD&quot;, &quot;clTmi&quot;, &quot;clTma&quot;, &quot;clP&quot;)] ## X2: Dickcissel[, c(&quot;broadleaf&quot;, &quot;conif&quot;, &quot;grass&quot;, &quot;crop&quot;, &quot;urban&quot;, &quot;wetland&quot;)] ## ## No. of explanatory tables: 2 ## Total variation (SS): 370770 ## Variance: 574.84 ## No. of observations: 646 ## ## Partition table: ## Df R.squared Adj.R.squared Testable ## [a+c] = X1 5 0.31414 0.30878 TRUE ## [b+c] = X2 6 0.03654 0.02749 TRUE ## [a+b+c] = X1+X2 11 0.32378 0.31205 TRUE ## Individual fractions ## [a] = X1|X2 5 0.28456 TRUE ## [b] = X2|X1 6 0.00327 TRUE ## [c] 0 0.02423 FALSE ## [d] = Residuals 0.68795 FALSE ## --- ## Use function &#39;rda&#39; to test significance of fractions of interest Note : les variables colinéaires n’ont pas besoin d’être enlevées avant l’analyse. Avec showvarpart(), il est possible de visualiser comment ces deux groupes (climat et paysage) expliquent la variation de la variable abund. Par exemple: showvarparts(2) `?`(showvarparts) # With two explanatory tables, the fractions explained # uniquely by each of the two tables are ‘[a]’ and ‘[c]’, # and their joint effect is ‘[b]’ following Borcard et al. # (1992). Essayons avec nos données Dickcissel et notre modèle. par(mar = rep(0.5, 4)) plot(part.lm, digits = 2, bg = rgb(48, 225, 210, 80, maxColorValue = 225), col = &quot;turquoise4&quot;) La proportion de la variation de la variable abund expliquée par: - Le climat est de 28.5% (obtenu par X1|X2) - La couverture du paysage est ~0% (X2|X1) - Les deux combinés est 2.4%. La variation non-expliquée par ces groupes (les résidus) est de 68.8%. Nous pouvons tester si chaque fraction est significative: Climat seul out.1 = rda(Dickcissel$abund, Dickcissel[, c(&quot;clDD&quot;, &quot;clFD&quot;, &quot;clTmi&quot;, &quot;clTma&quot;, &quot;clP&quot;)], Dickcissel[, c(&quot;broadleaf&quot;, &quot;conif&quot;, &quot;grass&quot;, &quot;crop&quot;, &quot;urban&quot;, &quot;wetland&quot;)]) Couverture du paysage seul out.2 = rda(Dickcissel$abund, Dickcissel[, c(&quot;broadleaf&quot;, &quot;conif&quot;, &quot;grass&quot;, &quot;crop&quot;, &quot;urban&quot;, &quot;wetland&quot;)], Dickcissel[, c(&quot;clDD&quot;, &quot;clFD&quot;, &quot;clTmi&quot;, &quot;clTma&quot;, &quot;clP&quot;)]) # Climat seul anova(out.1, step = 1000, perm.max = 1000) ## Permutation test for rda under reduced model ## Permutation: free ## Number of permutations: 999 ## ## Model: rda(X = Dickcissel$abund, Y = Dickcissel[, c(&quot;clDD&quot;, &quot;clFD&quot;, &quot;clTmi&quot;, &quot;clTma&quot;, &quot;clP&quot;)], Z = Dickcissel[, c(&quot;broadleaf&quot;, &quot;conif&quot;, &quot;grass&quot;, &quot;crop&quot;, &quot;urban&quot;, &quot;wetland&quot;)]) ## Df Variance F Pr(&gt;F) ## Model 5 165.12 53.862 0.001 *** ## Residual 634 388.72 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 # Couverture du paysage seul anova(out.2, step = 1000, perm.max = 1000) ## Permutation test for rda under reduced model ## Permutation: free ## Number of permutations: 999 ## ## Model: rda(X = Dickcissel$abund, Y = Dickcissel[, c(&quot;broadleaf&quot;, &quot;conif&quot;, &quot;grass&quot;, &quot;crop&quot;, &quot;urban&quot;, &quot;wetland&quot;)], Z = Dickcissel[, c(&quot;clDD&quot;, &quot;clFD&quot;, &quot;clTmi&quot;, &quot;clTma&quot;, &quot;clP&quot;)]) ## Df Variance F Pr(&gt;F) ## Model 6 5.54 1.5063 0.167 ## Residual 634 388.72 La fraction expliquée par la couverture du paysage n’est pas significative une fois que nous avons pris en compte l’effet du climat. Ceci était attendu puisque la variation expliqué pour ce groupe était seulement 0.3%. En conclusion, en partitionnant la variation, nous avons pu tenir compte de notre colinéarité entre nos variables et tout de même tester l’effet du climat et du paysage d’une façon simple et facile d’interprétation! ANOVA et des ANCOVA sur vos propres données. Cependant, rappelez-vous de toujours spécifier vos modèles correctement et de vérifier leurs conditions de base avant d’interpréter les résultats en fonction des caractéristiques écologiques de vos données. "],["résumé.html", "Chapitre 7 Résumé", " Chapitre 7 Résumé Le modèle linéaire décrit la relation entre une variable réponse et une ou plusieurs autres variables prédictrices. Elle est utilisée pour analyser une hypothèse bien formulée, souvent associée à une question de recherche plus générale. La régression détermine si les variables sont corrélées en inférant la direction et la force d’une relation, et notre confiance dans les estimations de l’effet. Lors du prochain atelier, vous verrez comment programmer en R. Vous apprendrez à utiliser des structures de contrôle (boucles for, if, while) afin d’éviter la répétition de code, de faciliter l’organisation et d’effectuer des simulations. Vous apprendrez également à écrire vos propres fonctions et quelques astuces pour programmer plus efficacement. "],["ressources-additionnelles.html", "Chapitre 8 Ressources additionnelles", " Chapitre 8 Ressources additionnelles 8.0.0.1 Aide-mémoire (cheat sheets) 8.0.0.2 Quelques livres Myers RH - Classical and Modern Regression with Application Gotelli NJ - A Primer of Ecological Statistics 8.0.0.3 Quelques sites internet "],["réferences.html", "Chapitre 9 Réferences", " Chapitre 9 Réferences "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
