---
title: "Atelier 4: ModÃ¨les linÃ©aires"
subtitle: "SÃ©rie d'ateliers R du CSBQ"
author: "Centre de la Science de la BiodiversitÃ© du QuÃ©bec"
output:
  xaringan::moon_reader:
    includes:
      in_header: qcbsR-header.html
    lib_dir: assets
    seal: true
    css: ["default", "qcbsR.css", "qcbsR-fonts.css"]
    nature:
      beforeInit: "qcbsR-macros.js"
      highlightLines: true
---
class: inverse, center, middle

```{r setup, echo = FALSE}
knitr::opts_chunk$set(
  comment = "#",
  collapse = TRUE,
  #cache = TRUE,
  warning = FALSE,
  message = FALSE,
  fig.width=6, fig.height=6,
  fig.retina = 3,
  fig.align = 'center'
)
options(repos=structure(c(CRAN="http://cran.r-project.org")))
```

```{r install_pkgs, message=FALSE, warning=FALSE, include=FALSE, results=0}
# Standard procedure to check and install packages and their dependencies, if needed.

list.of.packages <- c('dplyr', 'vegan', 'e1071', 'MASS', 'car', 'effect')

new.packages <- list.of.packages[!(list.of.packages %in% installed.packages()[,"Package"])]

if(length(new.packages) > 0) {
  install.packages(new.packages, dependencies = TRUE) 
  print(paste0("The following package was installed:", new.packages)) 
} else if(length(new.packages) == 0) {
    print("All packages were already installed previously")
  }
```

# À propos de cet atelier
[![badge](https://img.shields.io/static/v1?style=for-the-badge&label=repo&message=dev&color=6f42c1&logo=github)](https://github.com/QCBSRworkshops/workshop04)
[![badge](https://img.shields.io/static/v1?style=for-the-badge&label=wiki&message=04&logo=wikipedia)](https://wiki.qcbs.ca/r_atelier4)
[![badge](https://img.shields.io/static/v1?style=for-the-badge&label=Diapos&message=04&color=red&logo=html5)](https://qcbsrworkshops.github.io/workshop04/workshop04-fr/workshop04-fr.html)
[![badge](https://img.shields.io/static/v1?style=for-the-badge&label=Diapos&message=04&color=red&logo=adobe-acrobat-reader)](https://qcbsrworkshops.github.io/workshop04/workshop04-fr/workshop04-fr.pdf)
[![badge](https://img.shields.io/static/v1?style=for-the-badge&label=script&message=04&color=2a50b8&logo=r)](https://qcbsrworkshops.github.io/workshop04/workshop04-fr/workshop04-fr.R)

---

# Packages requis

* [dplyr](https://cran.r-project.org/package=dplyr)
* [vegan](https://cran.r-project.org/package=vegan)
* [e1071](https://cran.r-project.org/package=e1071)
* [MASS](https://cran.r-project.org/package=MASS)
* [car](https://cran.r-project.org/package=car)
* [effect](https://cran.r-project.org/package=effect)

<br>

```{r echo = TRUE, eval = FASE}
install.packages(c('dplyr', 'vegan', 'e1071', 'MASS', 'car', 'effect'))
```

---

# Objectifs d'apprentissage

.large[-Apprendre la structure d'un modÃ¨le linÃ©aire et ses *diffÃ©rentes variantes*.]
<br>
<br>
<br>
--

.center[
![:scale 80%](images/schema.png)
]

???

Note au prÃ©sentateur: Ce shÃ©ma reprÃ©sente les diffÃ©rentes variantes d'un modÃ¨le linÃ©aire qui sera prÃ©sentÃ©es durant l'atelier. 


---
# Objectifs d'apprentissage

.large[-Apprendre la structure d'un modÃ¨le linÃ©aire et ses diffÃ©rentes variantes.]
<br>
<br>
.large[-Apprendre comment faire un modÃ¨le linÃ©aire dans R avec `lm()` et `anova()`]
<br>
<br>
.large[-Apprendre comment identifier un modÃ¨le dont les conditions d'application ne sont pas rencontrÃ©es et comment rÃ¨gler le problÃ¨me.] 

---

# Qu'est-ce qu'un modÃ¨le linÃ©aire ?

#### Un **modÃ¨le linÃ©aire** ...

... dÃ©crit la relation entre une variable (la **rÃ©ponse**) et une ou plusieurs autres variables (les **prÃ©dicteurs**).

... est utilisÃ© pour analyser une **hypothÃ¨se bien formulÃ©e**, souvent associÃ©e Ã  une question de recherche plus gÃ©nÃ©rale.

... est utilisÃ© pour faire des infÃ©rences sur la **direction** et la **force** d'une relation, et notre **confiance** dans les estimations de l'effet.


???

- Point important : Il y a beaucoup de travail scientifique Ã  faire avant de formuler un modÃ¨le linÃ©aire.
- Il est recommandÃ© de formuler clairement les attentes concernant la direction et la force d'une relation en tant que prÃ©dictions avant d'effectuer un modÃ¨le linÃ©aire.


---

# Exemple : Abondance et masse des espÃ¨ces d'oiseaux

#### HypothÃ¨se

> Pour diffÃ©rentes espÃ¨ces d'oiseaux, la masse moyenne d'un individu a un effet sur l'abondance maximale de l'espÃ¨ce, en raison de contraintes Ã©cologiques (sources de nourriture, disponibilitÃ© de l'habitat, etc.).

#### PrÃ©diction
> Les espÃ¨ces caractÃ©risÃ©es par des individus plus grands ont une abondance maximale plus faible.

--

.center[

**Discussion en groupe**

*Quelle variable est la rÃ©ponse ? Quelle est le prÃ©dicteur ?*
  
*Quelles sont nos attentes concernant la direction et la force de la relation ?*
]

???

- Court : Oiseaux plus grands -> moins de nourriture et d'espace
- RÃ©ponse : Abondance maximale
- PrÃ©dicteur : Poids moyen (d'un individu)
- Direction : Inverse ou "nÃ©gative" (une masse plus Ã©levÃ© entraÃ®ne une abondance plus faible)
- La force : Aucune attente !

---

# Exemple : Abondance et masse des espÃ¨ces d'oiseaux

#### Regardons les donnÃ©es ...

Importer le jeu de donnÃ©es "birdsdiet" :

```{r, eval=TRUE, echo=FALSE}
bird <- read.csv("data/birdsdiet.csv", stringsAsFactors = TRUE)
```

```{r, eval = FALSE}
bird <- read.csv("birdsdiet.csv", stringsAsFactors = TRUE)
```

Visualiser le tableau de la structure des donnÃ©es en utilisant la fonction `str()` :

```{r}
str(bird)
```

???

- Il suffit pour l'instant d'expliquer les variables d'intÃ©rÃªt (vous trouverez plus d'informations sur l'ensemble des donnÃ©es dans le wiki : <https://wiki.qcbs.ca/r_atelier4#effectuer_un_modele_lineaire>)
- "MaxAbund" : La plus grande abondance observÃ©e sur un site en AmÃ©rique du Nord (continu / numÃ©rique)
- "Masse" : La taille du corps moyenne en grammes (continue / numÃ©rique)

---

# Exemple : Abondance et masse des espÃ¨ces d'oiseaux

#### Regardons les donnÃ©es ...



.pull-left[
Mesures communes de **localisation** (tendance centrale) :

<br>

- Moyenne **arithmÃ©tique** $\bar{x} = \frac{1}{n} \sum_{i=1}^{n} x_{i}$
```{r}
mean(bird$MaxAbund)
```
<br>
- **MÃ©diane** (valeur sÃ©parant la moitiÃ© supÃ©rieure de la moitiÃ© infÃ©rieure d'un Ã©chantillon)
```{r}
median(bird$MaxAbund)
```
]

.pull-right[

Mesure communes de **variation** (dispersion) :

<br>

- **Variance** $\sigma^2 = \frac{1}{n} \sum_{i=1}^{n} {(x_{i} - \bar{x})}^2$
```{r}
var(bird$MaxAbund)
```
<br>
- **Ã‰cart type** $\sigma$ 
```{r}
sd(bird$MaxAbund)
```
]

???

- Cette diapositive n'a pour but que de rappeler des concepts de base. 
- Les participant.e.s qui ont des difficultÃ©s avec ces mesures peuvent avoir des difficultÃ©s de comprendre les autres concepts prÃ©sentÃ©s dans l'atelier.
- Oui, il existe d'autres types de moyens dont nous n'avons gÃ©nÃ©ralement pas besoin pour les modÃ¨les linÃ©aires : moyenne gÃ©omÃ©trique, harmonique, ...
- La dÃ©finition de la mÃ©diane est omise car elle peut Ãªtre source de confusion pour certains participant.e.s : $\mathrm {median} (x)={\frac {1}{2}}(x_{\lfloor (n+1)/2\rfloor }+x_{\lceil (n+1)/2\rceil })$

---

# Exemple : Abondance et masse des espÃ¨ces d'oiseaux

Tracer la rÃ©ponse en fonction du prÃ©dicteur:

```{r}
plot(bird$Mass, bird$MaxAbund)
```

???
- Assurer que les participants comprennent comment le graphique est liÃ© Ã  l'hypothÃ¨se !

---

# Exemple : Abondance et masse des espÃ¨ces d'oiseaux

Comment trouver la "meilleure" estimation de la relation ?

```{r, eval=FALSE}
plot(bird$Mass, bird$MaxAbund)
```

```{r, echo=FALSE}
plot(bird$Mass, bird$MaxAbund)
abline(coef = c(70, -.03),  lwd = 1.5, lty = 2, col = palette()[2])
abline(coef = c(20, -.005), lwd = 1.5, lty = 2, col = palette()[4])
abline(coef = c(200, -.1),  lwd = 1.5, lty = 2, col = palette()[6])
```


???
- La question est destinÃ©e Ã  rester sans rÃ©ponse pour l'instant.
- La "meilleure" estimation est la ligne qui minimise la somme des carrÃ©s, ce qui devrait devenir clair Ã  travers les prochaines diapositives
- La "meilleure" estimation peut Ã©galement dire : Il n'y a pas de relation (similaire Ã  la ligne bleue dans le graphique).

---

# Formulation d'un modÃ¨le linÃ©aire

#### Variables

- $y_i$ est une observation de la **rÃ©ponse** $y$  
  (par exemple, l'abondance maximale des espÃ¨ces $i$)

- $x_i$ est une observation correspondante du **prÃ©dicteur** $x$  
  (par exemple, le poids moyen d'un individu d'une espÃ¨ce $i$)

#### Relation supposÃ©e

$$ y_i = \beta_0 + \beta_1 \times x_i + \epsilon_i$$


- Le paramÃ¨tre $\beta_0$ est **l'ordonnÃ©e Ã  l'origine** (ou constante)
- Le paramÃ¨tre $\beta_1$ quantifie **l'effet** de $x$ sur $y$.
- Le rÃ©sidu $\epsilon_i$ reprÃ©sent la variation **non expliquÃ©e**
- La **valeur prÃ©dite** de $y_i$ se dÃ©finit comme : $\hat{y}_i = \beta_0 + \beta_1 \times x_i$


???

- Prener du temps avec cette diapositive, toutes les dÃ©finitions sont importantes.
- Comprendre les paramÃ¨tres : important pour savoir ce qui sera estimÃ© et interprÃ©tÃ© ultÃ©rieurement
- Comprendre les rÃ©sidus et les valeurs ajustÃ©es : Important pour la vÃ©rification des modÃ¨les par la suite
- En thÃ©orie, les participants devraient savoir tout cela grÃ¢ce Ã  leurs cours de statistiques ; en pratique, la connaissance des dÃ©finitions est parfois faible


---

# Conditions d'application du modÃ¨le linÃ©aire


$$y_i = \beta_0 + \beta_1 \times x_i + \epsilon_i$$

#### Distribution normale

Les **rÃ©sidus** $\epsilon$ suivent une **distribution normale** avec une moyenne de $0$ et une variance de $\sigma^2$
$$\epsilon_i \sim \mathcal{N}(0,\,\sigma^2)$$

```{r, echo=FALSE, fig.height=4, fig.width=6}
x <- seq(-5, 5, length=100)
p <- dnorm(x, 0, 1)
plot(x, p, type = "l", lty = 2, lwd = 1.5,  xlab = "Residuals", ylab = "Probability", xaxt = "n")
```

---

# Conditions d'application du modÃ¨le linÃ©aire


$$y_i = \beta_0 + \beta_1 \times x_i + \epsilon_i$$

#### Distribution normale

Les **rÃ©sidus** $\epsilon$ suivent une **distribution normale** avec une moyenne de $0$ et une variance de $\sigma^2$
$$\epsilon_i \sim \mathcal{N}(0,\,\sigma^2)$$

**Cela veut dire :** Chaque obsevation $y_i$ suit une distribution normale,  
avec moyenne $\hat{y} = \beta_0 + \beta_1 \times x_i$ et variance $\sigma^2$: 

$$y_i \sim \mathcal{N}(\hat{y},\,\sigma^2)$$

.alert[**Cela ne veut pas dire**] que l'ensemble des valeurs observÃ©es $y$ ~~doit suivre une distribution normale~~.

???

- L'idÃ©e fausse selon laquelle $y$ plutÃ´t que $\epsilon$ doit suivre une distribution normale est trÃ¨s courante.


---

# Conditions d'application du modÃ¨le linÃ©aire

$$y_i = \beta_0 + \beta_1 \times x_i + \epsilon_i$$
$$\epsilon_i \sim \mathcal{N}(0,\,\sigma^2)$$


#### HomoscÃ©dasticitÃ©
- Tous les rÃ©sidus $\epsilon$ suivent la mÃªme distribution, la **variance** $\sigma^2$ **reste constante**.

<br>
<br>

#### IndÃ©pendance des rÃ©sidus
- Chaque rÃ©sidu $\epsilon_i$ est **indÃ©pendant** de tout autre rÃ©sidu. 


---

# Conditions d'application du modÃ¨le linÃ©aire

$$y_i = \beta_0 + \beta_1 \times x_i + \epsilon_i$$
$$\epsilon_i \sim \mathcal{N}(0,\,\sigma^2)$$

#### RÃ©sumÃ© des conditions d'application
- Relation linÃ©aire entre la rÃ©ponse et le prÃ©dicteur
- Les rÃ©sidus suivent une distribution normale avec une moyenne de $0$
- Les rÃ©sidus sont distribuÃ©s de maniÃ¨re identique (*homoscÃ©dasticitÃ©*)
- Les rÃ©sidus sont indÃ©pendants les uns des autres


???

- La dÃ©finition complÃ¨te d'un modÃ¨le linÃ©aire se compose toujours des deux Ã©quations prÃ©sentÃ©es


---

# Notation des modÃ¨les linÃ©aires

#### Notation mathÃ©matique (pour des manuscrits)

- Observations individuelles :  
  $y_i = \beta_0 + \beta_1 \times x_i + \epsilon_i \quad \textrm{with} \quad \epsilon_i \sim \mathcal{N}(0,\,\sigma^2)$

<br>

- Toutes les observations (notation matricielle, interception incluse dans $\mathbf{X}$ et $\boldsymbol{\beta}$) :   
  $\mathbf{y}= \mathbf{X}\boldsymbol{\beta} + \mathbf{\epsilon} \quad \textrm{with} \quad \epsilon_i \sim \mathcal{N}(0,\,I_n\sigma^2)$  

<br>

#### Notation en R

.pull-left[
- Formule du modÃ¨le :  
  ```{r, eval=FALSE}
  y ~ 1 + x
  ```  
]

.pull-right[
- Ou encore plus simple : 
  ```{r, eval=FALSE}
  y ~ x
  ```  
  (inclut aussi la constante)
]
  
.alert[Il ne faut jamais mÃ©langer les diffÃ©rentes types de notation !]


???

- Cette diapositive est destinÃ©e Ã aider les participant.e.s Ã  comprendre les diffÃ©rents types de description qu'on peut rencontrer
- Il n'est pas du tout nÃ©cessaire d'entrer dans le dÃ©tail de la notation matricielle.
- La notation R n'est pas adÃ©quate pour prÃ©parer une publication.

---

# Effectuer une modÃ¨le linÃ©aire

$$y_i = \beta_0 + \beta_1 \times x_i + \epsilon_i$$
$$\epsilon_i \sim \mathcal{N}(0,\,\sigma^2)$$

#### Estimation du modÃ¨le

- Trouver les "meilleures" estimations des paramÃ¨tres $\beta_0,\, \beta_1$.
- Les "meilleurs" paramÃ¨tres sont ceux qui minimisent la somme des rÃ©sidus au carrÃ© $\sum{\epsilon_i^2}$
- Cette mÃ©thode est appelÃ©e la mÃ©thode de **moindres carrÃ©s ordinaire** (MCO)


---

# ModÃ¨les linÃ©aires

.center[
![:scale 100%](images/schema.png)
]


---

class: inverse, center, middle

# RÃ©gression linÃ©aire avec R

---

# RÃ©gression linÃ©aire avec R

Revenons sur les oiseaux ...

```{r}
plot(bird$Mass, bird$MaxAbund)
```

---

# RÃ©gression linÃ©aire avec R

#### Formulation du modÃ¨le

> *HypothÃ¨se*: Pour diffÃ©rentes espÃ¨ces d'oiseaux, la **masse moyenne d'un individu a un effet sur l'abondance maximale** de l'espÃ¨ce, en raison de contraintes Ã©cologiques (sources de nourriture, disponibilitÃ© de l'habitat, etc.).


--

**Ã‰quation du modÃ¨le**

$\textrm{MaxAbund}_i = \beta_0 + \beta_1 \times \textrm{Mass}_i + \epsilon_i \;, \quad \epsilon_i \sim \mathcal{N}(0, \sigma^2)$

<br>

--

**Formule du modÃ¨le en R**

```{r, eval=FALSE}
MaxAbund ~ Mass
```

???
- La formulation du modÃ¨le peut Ãªtre posÃ©e comme question aux participant.e.s


---

# RÃ©gression linÃ©aire avec R

.center[.small[
**Ã‰tape 1**   
Formuler et exÃ©cuter un modÃ¨le linÃ©aire basÃ© sur un hypothÃ¨se

**Ã‰tape 2**  
VÃ©rifier les conditions d'application du modÃ¨le linÃ©aire
]]

<br>

.pull-left[.center[![:faic](arrow-down)]] .pull-right[.center[![:faic](arrow-down)]]

.pull-left[.center[*Conditions sont satisfaits ?*]

.small[.center[**Ã‰tape 3**  ]
- Analyser les paramÃ¨tres de rÃ©gression
- Tracer le modÃ¨le
- Effectuer des tests de signification sur les estimations des paramÃ¨tres (si nÃ©cessaire)
]]

.pull-right[.center[*Conditions non satisfaites ?*]

.center[Envisager l'utilisation d'un *ModÃ¨le linÃ©aire gÃ©nÃ©ralisÃ©* (GLM) ou la transformation des donnÃ©es]

.pull-left[.center[![:faic](arrow-down)]] .pull-right[.center[![:faic](arrow-down)]]

.small[
.pull-left[
Utiliser un GLM mieux adaptÃ© aux donnÃ©es
]

.pull-right[
Retourner Ã  l'Ã‰tape 1 avec des variables transformÃ©es
]]]

---

# RÃ©gression linÃ©aire avec R

#### **Ã‰tape 1.** Formuler et exÃ©cuter un modÃ¨le linÃ©aire

La fonction `lm()` est utilisÃ©e pour ajuster un modÃ¨le linÃ©aire, en fournissant la formule du modÃ¨le comme premier argument ::


```{r eval=TRUE}
lm1 <- lm(MaxAbund ~ Mass, data = bird)
```

- `lm1` : Nouvel objet contenant le modÃ¨le linÃ©aire
- `MaxAbund ~ Mass` : Formule du modÃ¨le 
- `bird` : objet contenant les variables


---

# RÃ©gression linÃ©aire avec R

#### **Ã‰tape 1.** Formuler et exÃ©cuter un modÃ¨le linÃ©aire

Examinons les estimations des paramÃ¨tres :

```{r, eval=TRUE}
lm1
```

.center[
*Comment les paramÃ¨tres se comparent-ils Ã  nos prÃ©dictions ?*
]

--

.center[
**Peut-on se fier aux estimations du modÃ¨le ?**
]


???
- Les questions peuvent Ãªtre utilisÃ©es pour une discussion en groupe
- La prÃ©diction Ã©tait : *Les espÃ¨ces caractÃ©risÃ©es par des individus plus grands ont une abondance maximale plus faible.*
- Le paramÃ¨tre pour la "masse" *ne correspond pas Ã  notre prÃ©diction* car il est positif !
- Nous ne savons pas si nous pouvons nous fier aux estimations - pour cela, nous avons besoin de l'Ã©tape 2

---

# RÃ©gression linÃ©aire avec R

#### **Ã‰tape 2.** VÃ©rifier les conditions d'application avec les graphiques diagnostics

Nous pouvons produire **quatre graphiques diagnostics** d'un objet `lm` :

```{r, eval=FALSE, fig.height=6, fig.width=8}
par(mfrow=c(2,2))
plot(lm1)
```

- `par()` : Fonction pour dÃ©finir les paramÃ¨tres du graphique
- `mfrow=c(2,2)`:  ParamÃ¨tre graphique permettant d'afficher une grille de 2 x 2 graphiques Ã  la fois
- `plot()`: Fonction pour produire les graphiques

???

- Comment faire pour ne montrer qu'une seule parcelle Ã  la fois : `par(mfrow=1)`.

---

# RÃ©gression linÃ©aire avec R

#### **Ã‰tape 2.** VÃ©rifier les conditions d'application avec les graphiques diagnostics

```{r, eval=FALSE}
par(mfrow=c(2,2)
plot(lm1)
```

```{r, echo=FALSE, fig.height=4.75, fig.width=5.5}
par(mfrow=c(2,2), mar = c(4,4,2,1.1), oma =c(0,0,0,0))
plot(lm1)
```

.center[**Comment interprÃ©ter ces graphiques ?**]

---

# Graph. #1 - RÃ©sidus vs valeurs prÃ©dites

**Ce qu'on voit :**  
* Axe des **Y** : Residus $\epsilon_i$
* Axe des **X** : Valeurs prÃ©dites $\hat{y_i} = \beta_0 + \beta_1 \times x_i$

<span style="color:green">**Ce qu'on espÃ¨re voir :**</span> Dispersion de points sans patron


**Motivation :** Indication si les rÃ©sidus sont *indÃ©pendants* et *uniformÃ©ment distribuÃ©s*.

```{r, echo = FALSE, fig.height=5, fig.width=6.5}
  set.seed(1234564)
  x <- rnorm(100,10,10)
  y <- 2*x+0 + rnorm(100)
  lm <- lm(y~x)
  plot(lm, which = 1)
```

???

- La dispersion sans patron est parfois dÃ©crite comme "des Ã©toiles dans le firmament".

---
# Graphique # 1 - RÃ©sidus vs valeurs prÃ©dites

.alert[Ce qui devrait nous rendre mÃ©fiants :]

```{r, echo=FALSE, fig.height=4.5, fig.width=8.5, warning=FALSE}
par(mfrow=c(1,2))
set.seed(1234564)
x = rnorm(100,10,10)
y = (x)^2 + rnorm(length(x),0,30)
lm=lm(y~scale(x))
plot(lm,which = 1, main = "Non-linÃ©aire", col.main="red")

x = abs(rnorm(100,10,10))
y = (x) + rnorm(length(x), 0, x)
lm=lm(y~scale(x))
plot(lm,which = 1, main = "HÃ©tÃ©roscÃ©dastique", col.main="red")
```

**Quoi faire ?**

- Utiliser plutÃ´t un **modÃ¨le linÃ©aire gÃ©nÃ©ralisÃ©** (MLG) qui permet d'autres distributions : Poisson, binomial, binomial nÃ©gatif, etc.)
- Essayer de **transformer** la rÃ©ponse et/ou prÃ©dicteurs

???

- Expliquez que "hÃ©tÃ©roscÃ©dastique" est l'opposÃ© de "homoscÃ©dastique", ce qui signifie que la condition de normalitÃ© est non-respectÃ©e.

---

# Graphique # 2 - Ã‰chelle localisÃ©
**Ce qu'on voit :**  
* Axe des **Y** : Racine carrÃ©e des rÃ©sidus standardisÃ©s $\sqrt{\frac{\epsilon_i}{\sigma}}$
* Axe des **X** : Valeurs prÃ©dites $\hat{y_i} = \beta_0 + \beta_1 \times x_i$

<span style="color:green">**Ce qu'on espÃ¨re voir :**</span> Dispersion de points sans patron

**Motivation :** Parfois plus facile de dÃ©tecter si les conditions d'application ne sont pas respectÃ©es, surtout quand le prÃ©dicteur est distribuÃ© de maniÃ¨re inÃ©gale.

```{r, echo=FALSE, fig.height=4.5, fig.width=6, warning=FALSE}
set.seed(1234564)
x <- 1:100
y <- x + rnorm(100,sd=5)
lm=lm(y~x)
plot(lm,which = 3)
```

---

# Graphique # 2 - Ã‰chelle localisÃ©

.alert[Ce qui devrait nous rendre mÃ©fiants :]

```{r, echo=FALSE, fig.height=4.5, fig.width=6, warning=FALSE}
set.seed(2)
x = abs(rnorm(100,10,10))
y = (x) + rnorm(length(x), 0, x)
lm=lm(y~scale(x))
plot(lm,which = 3)
```

.center[*Forte tendance dans les rÃ©sidus*]

???

- Quoi fair ? Voire graphique #1

---

# Graphique # 3 - Normal QQ

**Ce qu'on voit :**  
* **Y**-axis: Residus standardisÃ©s $\frac{\epsilon_i}{\sigma}$
* **X**-axis: Distribution normale standard $\mathcal{N}(0, \sigma^2)$

<span style="color:green">**Ce qu'on espÃ¨re voir :**</span> Points sur la ligne 1:1

**Motivation :** Comparer la distribution (quantiles) des rÃ©sidus Ã  une distribution normale standard

```{r, echo=FALSE, fig.height=4.5, fig.width=6, warning=FALSE}
set.seed(1234564)
x <- 1:100
y <- x + rnorm(100,sd=5)
lm=lm(y~x)
plot(lm, which = 2)

```

---

# Graphique # 3 - Normal QQ

.alert[Ce qui devrait nous rendre mÃ©fiants :]

```{r, echo=FALSE, fig.height=4.5, fig.width=6, warning=FALSE}
set.seed(2)
x = abs(rnorm(100,10,10))
y = (x) + rnorm(length(x), 0, x)
lm=lm(y~scale(x))
plot(lm, which = 2)
```

.center[*Les rÃ©sidus ne suivent pas une distribution normale*]


---

# Graphique # 4 - RÃ©sidus vs effet de levier

**Motivation :**

- Le modÃ¨le ne devrait **pas dÃ©pendre fortement d'observations isolÃ©es**.
- Les **points de levier** sont des observations extrÃªmes du prÃ©dicteur. 
- Le **modÃ¨le passe prÃ¨s des points de levier**, car ils manquent d'observations voisines.
- Les points de levier **<span style="color:red">peuvent</span> (ou <span style="color:green">pas</span>) avoir une grande influence sur la rÃ©gression**
- L'influence peut Ãªtre quantifiÃ©e par **la distance Cook : plus de 0,5 est problÃ©matique**.

---

# Examples: Effet levier et influence

```{r, echo=FALSE, fig.height=8, fig.width=7.7, warning=FALSE}
par(mfrow=c(3, 1), mar = c(4, 15, 1, 3), cex = 1.2)
set.seed(1234564)
x <- 1:20
y <- rnorm(x, x, 2)
lm0 <- lm(y ~ x)
# plot 1
plot(x, y, ylim = c(-4, 22), xlab = '', ylab = ''); abline(lm0, col = 2); points(11, -3, pch = 15)
# add 20, 10 point to the new lm
xx <- c(x, 11); yy <- c(y, -3)
abline(lm(yy ~ xx), col = 2, lty = 3)
text(-20, 10, srt=0, adj = 0, labels = "* Pas d'effet de levier \n* Faible influence
", xpd = TRUE, cex = 1.5)
# plot 2
plot(x, y, ylim = c(-4, 32), xlim = c(0, 31), xlab = '', ylab = ''); abline(lm0, col = 2); points(30, 30, pch = 15)
# add 20, 10 point to the new lm
xx <- c(x, 30); yy <- c(y, 30)
abline(lm(yy ~ xx), col = 2, lty = 3)
text(-33, 15, srt=0, adj = 0, labels = "* Effet de levier \n* Pas d'influence", xpd = TRUE, cex = 1.5)

# plot 3
plot(x, y, ylim = c(-4, 32), xlim = c(0, 31), xlab = '', ylab = ''); abline(lm0, col = 2); points(30, 15, pch = 15)
# add 20, 10 point to the new lm
xx <- c(x, 30); yy <- c(y, 15)
abline(lm(yy ~ xx), col = 2, lty = 3)
text(-33, 15, srt=0, adj = 0, labels = '* Effet de levier \n* Influence Ã©levÃ©e', xpd = TRUE, cex = 1.5)
```


???

- Tous les graphiques ont la rÃ©ponse sur l'axe des y et le prÃ©dicteur sur l'axe des x
- Pour Ã©viter la confusion : Il ne s'agit pas de graphiques diagnostics sue cette diapositive !

---

# Graphique # 4 - RÃ©sidus vs effet de levier

**Ce qu'on voit :**  
* Axe des **Y** : Residus standardisÃ©s $\frac{\epsilon_i}{\sigma}$
* Axe des **X** : Effet de levier
* Ligne rouge en tirets : distance Cook de 0.5

<span style="color:green">**Ce qu'on espÃ¨re voir :**</span> Pas de points de levier avec influence elevÃ©e

```{r, echo=FALSE, fig.height=4.5, fig.width=9, warning=FALSE}
par(mfrow=c(1,2))
set.seed(1234564)
x <- 1:100
y <- x + rnorm(100,sd=5)
lm=lm(y~x)
plot(lm, which = 5, main = "Aucune observation influente", col.main=palette()[3])

set.seed(1234564)
x = abs(rnorm(100,10,10))
y = (x) + rnorm(length(x), 0, x)
lm=lm(y~scale(x))
plot(lm, which = 5, main = "Effet de levier et faible influence",  col.main=palette()[3])
```

---

# Graphique # 4 - RÃ©sidus vs effet de levier

.alert[Ce qui devrait nous rendre mÃ©fiants :]

<br />

```{r, echo=FALSE, fig.height=5, fig.width=8, warning=FALSE}
set.seed(1234564)
x = abs(rnorm(100,10,10))
y = (x) + rnorm(length(x), 0, x)
y[29] <- 100
lm=lm(y~scale(x))
plot(lm, which = 5, main = "Effet de levier et influence Ã©levÃ©e")
```

<br>

.alert[Il ne faut jamais supprimer les valeurs aberrantes sans avoir des bonnes raisons de le faire]

???

- Point 29 a un effet de levier Ã©levÃ© et une distance Cook > 0,5
- Raison potentielle pour supprimer les valeurs aberrantes : Erreur de mesure Ã©vidente

---

# **Ã‰tape 2**. VÃ©rifier les conditions d'application pour `lm1`

```{r, eval=FALSE, fig.height=5.5, fig.width=7.5}
par(mfrow=c(2,2))
plot(lm1)
```

```{r, echo=FALSE, fig.height=5.5, fig.width=7.5}
par(mfrow=c(2,2), mar = c(4,4,2,1.1), oma =c(0,0,0,0))
plot(lm1)
```

**Discussion :** Le modÃ¨le `lm1` respecte-t-il les conditions du modÃ¨le linÃ©aire ?

???

- Graphiques 1 et 2 : prÃ©sence de fortes tendances
- Graphique 3 : les rÃ©sidus ne suivent pas une distribution normale
- Graphique 4 : point 32 a un effet de levier important et une influence (trÃ¨s Ã©levÃ©)


---

# Conditions non-respectÃ©es - Quelle est la cause ?

TraÃ§ons le modÃ¨le avec les observations ...

```{r, fig.height=4, fig.width=11}
par(mfrow = c(1,2))
coef(lm1) # constante et pente
plot(MaxAbund ~ Mass, data=bird) # graphique Ã  gauche
abline(lm1) # ligne dÃ©finie par les paramÃ¨tres du modÃ¨le
hist(residuals(lm1)) # graphique Ã  droite : distribution des rÃ©sidus
```

---

# Conditions non-respectÃ©es - Quelle est la cause ?

On peut verifier si les rÃ©sidus suivent une distribution normale Ã  l'aide d'un test de *Shapiro-Wilk* et d'un test d'asymÃ©trie (*skewness*) :

```{r}
shapiro.test(residuals(lm1))

library(e1071)
skewness(residuals(lm1))
```
.comment[La distribution est significativement diffÃ©rente d'une distribution normale, dÃ©calÃ©e vers la gauche (valeur positive d'asymÃ©trie)]


---

# Conditions non-respectÃ©es - Comment proÃ©eder ?


*Il y a deux options quand les conditions d'application du modÃ¨le linÃ©aire ne sont pas respectÃ©es :*

<br>

1. Utiliser un **autre type de modÃ¨le** mieux adaptÃ© Ã  l'hypothÃ¨se et aux donnÃ©es (ateliers 6 - 8 du CSBQ R).
<br>
<br>
2. Essayer de **transformer** la rÃ©ponse et / ou le prÃ©dicteurs
  - Il existe **plusieurs types de transformations** et leur utilitÃ© dÃ©pend de la distribution de la variable et du type de modÃ¨le.
  - La transformation peut **rÃ©gler certains** problÃ¨mes mais peut en **crÃ©er d'autres**.
  - Les **rÃ©sultats des tests de signification** sur les donnÃ©es transformÃ©es ne sont **pas automatiquement valables** pour les donnÃ©es non transformÃ©es.

???

- La transformation des variables peut Ãªtre utile, mais elle est souvent dÃ©licate en pratique

---

# DÃ©fi 1: Un modÃ¨le sur variables transformÃ©es ![:cube]

*Essayons de rÃ©soudre nos problÃ¨mes avec une transformation logarithmique.*

Ajoutons des variables transformÃ©es Ã  notre jeu de donnÃ©es :

```{r}
bird$logMaxAbund <- log10(bird$MaxAbund)
bird$logMass <- log10(bird$Mass)
```

--

#### DÃ©fi

**Ã‰tape 1.** ExÃ©cuter une rÃ©gression linÃ©aire sur les variables transformÃ©es `logMaxAbund` et `logMass`.
Sauvegarder l'objet du modÃ¨le sous `lm2`

**Ã‰tape 2**: VÃ©rifier les conditions pour `lm2` en utilisant les graphique diagnostics.

```{r}
lm2 <- lm(logMaxAbund ~ logMass, data = bird)
```

???

- Se rÃ©partir en petits groupes. Puis disctuter des rÃ©sultats avec l'ensemble des participant.e.s

---

# DÃ©fi 1: Un modÃ¨le sur variables transformÃ©es ![:cube]

**Ã‰tape 1.** ExÃ©cuter une rÃ©gression linÃ©aire sur les variables transformÃ©es 

```{r}
lm2 <- lm(logMaxAbund ~ logMass, data = bird)

lm2
```

.center[
*Comment les paramÃ¨tres se comparent-ils Ã  nos prÃ©dictions ?*
]

.center[
**Peut-on se fier aux estimations du modÃ¨le ?**
]

???

- Cette fois, les paramÃ¨tres s'alignent avec nos prÃ©dictions.
- MAIS : Bien sÃ»r, nous devons encore vÃ©rifier les hypothÃ¨ses 

---

# DÃ©fi 1: Un modÃ¨le sur variables transformÃ©es ![:cube]

**Ã‰tape 2**: VÃ©rifier les conditions pour `lm2` 

```{r, fig.height=5.5, fig.width=7.5}
par(mfrow=c(2,2), mar=c(3,4,1.15,1.2))
plot(lm2)
```

--

.comment[.center[Beaucoup mieux, mais il reste des problÃ¨mes]]

???

- Il y a encore des tendances visibles dans les graphiques

---

# **Ã‰tape 2.** VÃ©rifier les conditions d'application pour `lm2`

```{r, fig.height=4, fig.width=11,}
par(mfrow = c(1,2))
coef(lm2) # constante et pente
plot(logMaxAbund ~ logMass, data=bird) # graphique Ã  gauche
abline(lm2) # ligne dÃ©finie par les paramÃ¨tres du modÃ¨le
hist(residuals(lm2)) # graphique Ã  droite : distribution des rÃ©sidus
```

---

# **Ã‰tape 3.** Analyser les paramÃ¨tres

La fonction `summary()` est utiliÃ©e pour obtenir plus d'informations sure le modÃ¨le ajustÃ©. 

.small[
```{r, comment=""}
summary(lm2)
```
]

???

- Prendre le temps d'expliquer la sortie de `summary()` :
  1. Estimations des paramÃ¨tres et leur Ã©carts type
  2. RÃ©sultats d'un test de t visant Ã  dÃ©terminer si les paramÃ¨tres sont diffÃ©rents de 0
  3. Adjusted R squared (R au carrÃ© ajustÃ©) : Dans quelle mesure le modÃ¨le explique-t-il les donnÃ©es ?
  4. F-statistic (statistique F) (ANOVA) : Le modÃ¨le est-il significativement diffÃ©rent d'un modÃ¨le sans prÃ©dicteur (modÃ¨le nul) ?
- Mentionner que les tests t et l'ANOVA seront abordÃ©s plus tard
- Dans ce cas : notre modÃ¨le est Ã  peine meilleur que le modÃ¨le nul


---

# **Ã‰tape 3.** Analyser les paramÃ¨tres

Nous pouvons aussi extraire les paramÃ¨tres du modÃ¨le et des autres rÃ©sultats :

```{r}
# Vecteurs de rÃ©sidus et valeures prÃ©dites
e <- residuals(lm2)
y <- fitted(lm2)

coefficients(lm2) # coefficients
summary(lm2)$coefficients # coefficients avec test de t

summary(lm2)$adj.r.squared # R au carrÃ© ajustÃ©
```

---

# InterprÃ©tation du modÃ¨le

.center[*Dans quelle mesure le modÃ¨le soutient-il notre hypothÃ¨se ?*]

#### HypothÃ¨se

> Pour diffÃ©rentes espÃ¨ces d'oiseaux, la **masse moyenne d'un individu a un effet sur l'abondance maximale** de l'espÃ¨ce, en raison de contraintes Ã©cologiques (sources de nourriture, disponibilitÃ© de l'habitat, etc.).


---

# InterprÃ©tation du modÃ¨le

.center[*Dans quelle mesure le modÃ¨le soutient-il notre hypothÃ¨se ?*]

```{r, comment=""}
summary(lm2)
```

---

# InterprÃ©tation du modÃ¨le

.center[*Dans quelle mesure le modÃ¨le soutient-il notre hypothÃ¨se ?*]

Il n'y a que trÃ¨s **peu de preuves Ã  l'appui** de notre hypothÃ¨se parce que :
- Le modÃ¨le n'explique pas bien la rÃ©ponse (*faible R au carrÃ© ajustÃ©*)
- Le modÃ¨le n'est que lÃ©gÃ¨rement meilleur qu'un modÃ¨le sans variables prÃ©dictives (*F-test Ã  peine significatif*)
- L'estimation du paramÃ¨tre "logMass" est Ã  peine diffÃ©rente de 0 (*valeur de t Ã  peine significatif*)

???

- In this case, the F-test and t-test are equivalent because there is only one predictor variable)

---

# Trouver un meilleur modÃ¨le : oiseaux terrestres

*Peut-Ãªtre devrions-nous formuler une hypothÃ¨se plus prÃ©cise ?*

--

#### HypothÃ¨se

> Pour diffÃ©rentes espÃ¨ces d'oiseaux <span style="color:green">**terrestres**</span>, la **masse moyenne d'un individu a un effet sur l'abondance maximale** de l'espÃ¨ce, en raison de contraintes Ã©cologiques (sources de nourriture, disponibilitÃ© de l'habitat, etc.).

---

# Trouver un meilleur modÃ¨le : oiseaux terrestres

Exclure tous les oiseaux aquatiques (en utilisant `!`) et ajuster un modÃ¨le linÃ©aireÂ :

```{r}
lm3 <- lm(logMaxAbund~logMass, data=bird, subset=!bird$Aquatic)
# exclut les oiseaux aquatiques (!birdsAquatic == TRUE)
# ou de faÃ§on Ã©quivalente :
# lm3 <- lm(logMaxAbund~logMass, data=bird, subset=bird$Aquatic == 0)

lm3
```

---

# Trouver un meilleur modÃ¨le : oiseaux terrestres

```{r, eval=FALSE, fig.height=5.5, fig.width=7.5}
par(mfrow=c(2,2))
plot(lm3)
```

```{r, echo=FALSE, fig.height=5.5, fig.width=7.5}
par(mfrow=c(2,2), mar = c(4,4,2,1.1), oma =c(0,0,0,0))
plot(lm3)
```

.comment[.center[Conditions d'application respectÃ©es]]

---

# Trouver un meilleur modÃ¨le : oiseaux terrestres

.center[*Dans quelle mesure le modÃ¨le soutient-il notre hypothÃ¨se ?*]

```{r, comment=""}
summary(lm3)
```

---

# Trouver un meilleur modÃ¨le : oiseaux terrestres

.center[*Dans quelle mesure le modÃ¨le soutient-il notre hypothÃ¨se ?*]

Le modÃ¨le fournit des **preuves Ã  l'appui** de notre hypothÃ¨se, parce que :

- Le modÃ¨le est raisonnablement bien ajustÃ© aux donnÃ©es (*R au carrÃ© ajustÃ©*)
- Le modÃ¨le est clairement meilleur qu'un modÃ¨le sans variables prÃ©dictives (*F-test*)
- L'estimation du paramÃ¨tre "logMass" est clairement diffÃ©rente de 0 (*t-test*)


---

# DÃ©fi 2 ![:cube]()

Rassemblons tout les Ã©tapes :

<br>
1. Formuler une autre hypothÃ¨se similaire sur l'abondance maximale et la masse moyenne d'un individu, cette fois pour les **passereaux** ("passerine birds").
2. Ajuster un **modÃ¨le** pour Ã©valuer cette hypothÃ¨se, en utilisant les variables transformÃ©es (c'est-Ã -dire `logMaxAbund` et `logMass`). Sauvegarder le modÃ¨le sous le nom de `lm4`.
3. **VÃ©rifier les conditions d'application** du modÃ¨le linÃ©aire Ã  l'aide des graphiques diagnostics.
4. InterprÃ©ter les rÃ©sultats : Le modÃ¨le fournit-il des **preuves Ã  l'appui de l'hypothÃ¨se ?**


.comment[Indice : Comme les espÃ¨ces aquatiques, les passereaux (variable `Passerine` sont codÃ©es 0/1 (vÃ©rifier avec `str(bird)`)]

---

# DÃ©fi 2 - Solution ![:cube]()

#### HypothÃ¨se

> Pour diffÃ©rentes espÃ¨ces de <span style="color:green">**passereaux**</span>, la **masse moyenne d'un individu a un effet sur l'abondance maximale** de l'espÃ¨ce, en raison de contraintes Ã©cologiques (sources de nourriture, disponibilitÃ© de l'habitat, etc.).

---

# DÃ©fi 2 - Solution ![:cube]()

ajuster le modÃ¨le :

```{r}
lm4 <- lm(logMaxAbund ~ logMass, data=bird, subset=bird$Passerine == 1)
lm4
```

---

# DÃ©fi 2 - Solution ![:cube]()

VÃ©rifier les conditions d'application :

```{r, eval=FALSE}
par(mfrow=c(2,2))
plot(lm4)
```

```{r,fig.height=6, fig.width=8, echo=FALSE}
par(mfrow=c(2,2), mar = c(4,4,2,1.1), oma =c(0,0,0,0))
plot(lm4)
```

---

# DÃ©fi 2 - Solution ![:cube]()

Vaut-il la peine d'interprÃ©ter les rÃ©sultats ?

```{r, comment=""}
summary(lm4)
```

???

- Les rÃ©sultats du modÃ¨le ne doivent pas Ãªtre interprÃ©tÃ©s car les conditions d'application du modÃ¨le linÃ©aire ne sont pas respectÃ©es!

---

# RÃ©gression linÃ©aire avec R

.center[.small[
**Ã‰tape 1**   
Formuler et exÃ©cuter un modÃ¨le linÃ©aire basÃ© sur un hypothÃ¨se

**Ã‰tape 2**  
VÃ©rifier les conditions d'application du modÃ¨le linÃ©aire
]]

<br>

.pull-left[.center[![:faic](arrow-down)]] .pull-right[.center[![:faic](arrow-down)]]

.pull-left[.center[*Conditions sont satisfaits ?*]

.small[.center[**Ã‰tape 3**  ]
- Analyser les paramÃ¨tres de rÃ©gression
- Tracer le modÃ¨le
- Effectuer des tests de signification sur les estimations des paramÃ¨tres (si nÃ©cessaire)
]]

.pull-right[.center[*Conditions non satisfaites ?*]

.center[Envisager l'utilisation d'un *ModÃ¨le linÃ©aire gÃ©nÃ©ralisÃ©* (GLM) ou la transformation des donnÃ©es]

.pull-left[.center[![:faic](arrow-down)]] .pull-right[.center[![:faic](arrow-down)]]

.small[
.pull-left[
Utiliser un GLM mieux adaptÃ© aux donnÃ©es
]

.pull-right[
Retourner Ã  l'Ã‰tape 1 avec des variables transformÃ©es
]]]

---

# Noms de variables

Des termes diffÃ©rents sont utilisÃ©s pour la *rÃ©ponse* et le *prÃ©dicteur*, , en fonction du contexte et du domaine scientifique (les termes ne sont pas toujours synonymes).

<br>

.center[
|rÃ©sponse          | prÃ©dicteur       |
|:-----------------|:-----------------|
|var. expliquÃ©     |var. explicatif   |
|                  |covariable        |
|var. endogÃ¨ne     |var. exogÃ¨ne      |
|var. dÃ©pendante   |var. indÃ©pendante |
]

<br>

.center[
|response          | predictor        |
|:-----------------|:-----------------|
|                  |explanatory var.  |
|                  |covariate         |
|outcome           |                  |
|output var.       |input var.        |
|dependent var.    |independent var.  |
]


---

# ModÃ¨les linÃ©aires

.center[
![:scale 100%](images/schema_ttest.png)
]

---

class: inverse, center, middle

# ANOVA

## Test-t
## ANOVA Ã  un critÃ¨re de classification
## ANOVA Ã  deux critÃ¨res de classification

---
# ANOVA

Variable rÃ©ponse continue

**Variables explicatives catÃ©goriques**

- Deux niveaux ou plus (groupes)

.large[.center[Compare la variation intra-groupe et inter-groupe afin de dÃ©terminer si les moyennes des groupes diffÃ©rent]]

---
# ANOVA

.center[Compare la variation intra-groupe et inter-groupe afin de dÃ©terminer si les moyennes des groupes diffÃ¨rent]

```{r, echo = FALSE, fig.height=3, fig.width=6.5}
source('script/figAnova.R')
```

Somme des carrÃ©s : variance intra-traitement *vs* variance inter-traitement

Si variance inter traitements $>$ variance intra traitements:
  - la variable explicative a un effet plus important que l'erreur alÃ©atoire
  - variable explicative est donc susceptible d'influencer significativement la variable rÃ©ponse

---
# Types d'ANOVA

1. ANOVA Ã  un critÃ¨re de classification
  - Une variable explicative catÃ©gorique avec au moins 2 niveaux
  - S'il y a 2 niveaux, un **test de t** peut Ãªtre utilisÃ© alternativement

2. ANOVA Ã  deux critÃ¨res de classification
  - Deux variables explicatives catÃ©goriques ou plus
  - Chaque facteur peut avoir plusieurs niveaux
  - Les interactions entre chaque facteur doivent Ãªtre testÃ©es

--

Mesures rÃ©pÃ©tÃ©es ?
  - L'ANOVA peut Ãªtre utilisÃ©e pour des mesures rÃ©pÃ©tÃ©es, mais ce sujet n'est pas abordÃ© dans cet atelier
  - ModÃ¨le linÃ©aire mixte peut Ã©galement Ãªtre utilisÃ© pour ce type de donnÃ©es (voir l'atelier 6)

---
class: inverse, center, middle

# Test de t

---
# Test de t

- **Variable rÃ©ponse** ![:faic](arrow-right) quantitative
- **Variable explicative** ![:faic](arrow-right) qualitative avec **2 niveaux**

**conditions d'application**
- Les rÃ©sidus suivent une distribution normale
- Les variances des groupes sont homogÃ¨nes

.comment[Le test est plus robuste lorsque la taille de l'Ã©chantillon est plus Ã©levÃ©e et lorsque les groupes ont des tailles Ã©gales]

---
# ExÃ©cuter un test de t dans R

Vous pouvez utiliser la fonction `t.test()`

```r
t.test(Y ~ X2, data= data, alternative = "two.sided")
```

  - `Y`: variable rÃ©ponse
  - `X2`: facteur (2 niveaux)
  - `data`: nom du jeu de donnÃ©es
  - hypothÃ¨se `alternative` : `"two.sided"` (par dÃ©faut), `"less"`, ou `"greater"`

Le test de t est un modÃ¨le linÃ©aire et un cas spÃ©cifique de l'ANOVA avec un facteur Ã  2 niveaux

Vous pouvez donc aussi utiliser la fonction `lm()`

```r
lm.t < -lm(Y ~ X2, data = data)
anova(lm.t)
```

---
# ExÃ©cuter un test de t dans R

.large[Les oiseaux aquatiques sont-ils plus lourds que les oiseaux terrestres ?]

- Variable rÃ©ponse : `Bird mass` ![:faic](arrow-right) num: continue
- Variable explicative : `Aquatic` ![:faic](arrow-right) 2 niveaux : 1 ou 0 (oui ou non)

---
# ExÃ©cuter un test de t dans R

PremiÃ¨rement, visualiser les donnÃ©es Ã  l'aide de la fonction `boxplot()`

```{r eval=TRUE,fig.height=5.2, fig.width=6.5}
boxplot(logMass ~ Aquatic,
        data = bird, names = c("Non aquatique", "Aquatique"))
```

---
# ExÃ©cuter un test de t dans R

Testons l'homogÃ©nÃ©itÃ© des variances avec la fonction `var.test()`

```{r}
var.test(logMass ~ Aquatic, data = bird)
```

.comment[Le rapport des variances n'est pas statistiquement diffÃ©rent de 1, celles-ci peuvent donc Ãªtre considÃ©rÃ©es comme Ã©gales]

.comment[Nous pouvons maintenant procÃ©der au test de t !]

---
# ExÃ©cuter un test de t dans R

```{r}
ttest1 <- t.test(logMass ~ Aquatic, var.equal = TRUE, data = bird)

# Or use lm()
ttest.lm1 <- lm(logMass ~ Aquatic, data=bird)
```

.comment[SpÃ©cifie que l'homogÃ©nÃ©itÃ© des variances est respectÃ©e]

VÃ©rifiez que `t.test()` et `lm()` donnent le mÃªme modÃ¨le :

```{r}
ttest1$statistic^2
anova(ttest.lm1)$`F value`
# rÃ©ponse : F=60.3845 dans les deux cas
```

.comment[Lorsque la condition d'Ã©galitÃ© de variance est confirmÃ©e, t^2 = F]

---
# ExÃ©cuter un test de t dans R

Si $p<0,01$ (ou $0,05$ ), l'hypothÃ¨se de l'absence de diffÃ©rence entre les moyenne des 2 groupes (*H0*) peut Ãªtre rejetÃ©e, avec un risque de $0,01$ (ou $0,05$ ) de se tromper

.small[
```{r}
ttest1
```
]

.small[.comment[Il existe une diffÃ©rence entre la masse des oiseaux aquatiques et terrestres - `p-value`]]

.small[.comment[Regardez les moyennes des 2 groupes]]

---
# Non respect des conditions d'application

- **Correction de Welch** : lorsque les Ã©carts entre les groupes ne sont pas Ã©gaux (par dÃ©faut dans R !)
- **Test de Mann-Whitney** : l'Ã©quivalent **non paramÃ©trique** du test de t lorsque les conditions d'application ne sont pas respectÃ©es
- **Test de t appariÃ©** : lorsque les deux groupes ne sont **pas indÃ©pendants** (par exemple, des mesures sur la mÃªme personne rÃ©coltÃ©es lors de 2 annÃ©es diffÃ©rentes)

---
exclude:True
# Discussion de groupe

.large[Les oiseaux aquatiques sont-ils plus lourds que les oiseaux terrestres ?]

```{r}
# Unilateral t-test
uni.ttest1 <- t.test(logMass ~ Aquatic,
                     var.equal = TRUE,
                     data = bird,
                     alternative = "less")
```

.comment[Qu'avez-vous conclu ?]

---
exclude:True
# Discussion de groupe

```{r}
uni.ttest1
```

Oui, les oiseaux aquatiques sont plus lourds que les oiseaux terrestres :p-value = `r format(uni.ttest1$p.value, scientific=FALSE)`
---
# Sondage

.large[Avec un test de t, il est possible d'Ãªtre plus prÃ©cis et de donner une direction Ã  notre hypothÃ¨se avec `alternative`.] 
<br>
<br>
<br>
Nous voulons tester si **les oiseaux aquatiques sont plus lourds que les oiseaux terrestres **. 

Lequel devrait Ãªtre utilisÃ©? `alternative = "???"`

1.`"two.sided"`

2.`"less"`

3.`"greater"`

```{r,eval=F,echo=T}
# Unilateral t-test
uni.ttest1 <- t.test(logMass ~ Aquatic,
                     var.equal = TRUE,
                     data = bird,
                     alternative = "???")
```

---
# RÃ©ponse

.xsmall[
```{r}
# Unilateral t-test
uni.ttest1 <- t.test(logMass ~ Aquatic,
                     var.equal = TRUE,
                     data = bird,
                     alternative = "less")
uni.ttest1

```
]

Pourquoi `"greater"` n'aurait pas marchÃ©?

.comment[Indice: retournez Ã  vos donnÃ©es. Quelle est la nature de la variable Aquatic?]

???

Presenter notes: To understand this answer, we have to understand the dataset. Aquatic is binary variable, i.e. that 0 = terrestrial birds, and 1 = aquatic birds. By default, R will always test in this order. So, we are actually testing whether terrestrial birds are lighter than aquatic birds. This is also points out the importance to understand your dataset.

---
class: inverse, center, middle

# ANOVA

---
# Analyse de Variance (ANOVA)

GÃ©nÃ©ralisation du test de t Ã  $>2$ groupes, et/ou â‰¥ $2$ facteurs explicatifs

DÃ©composition de la variance observÃ©e de la variable rÃ©ponse en effets additifs d'un ou de plusieurs facteurs et de leurs interactions

<br>
$$Y = \underbrace{\mu}_{\Large{\text{moyenne globale de la variable rÃ©ponse}\atop\text{sur tous les individus}}} + \overbrace{\tau_{i}}^{\Large{\text{Le rÃ©sultat moyen sur}\atop\text{tous les individus du groupe i}}} + \underbrace{\epsilon}_{\text{RÃ©sidus}}$$

---
# Rappel : ANOVA

conditions d'application
- NormalitÃ© des rÃ©sidus
- L'Ã©galitÃ© de la variance inter-groupes

Test complÃ©mentaire
- Lorsque l'ANOVA dÃ©tecte une diffÃ©rence significative entre les groupes, l'analyse n'indique pas quel(s) groupe(s) diffÃ¨re(nt) de(s) l'autre(s)
- Un test couramment utilisÃ© *a posteriori* pour rÃ©pondre Ã  cette question est le **Test de Tukey**

---
# ExÃ©cuter une ANOVA dans R

##### Est-ce que l'abondance maximale dÃ©pend du rÃ©gime alimentaire ?
- Variable rÃ©ponse : **MaxAbund**  ![:faic](arrow-right) num: quantitative
- Variable explicative : **Diet** ![:faic](arrow-right) facteur avec 5 niveaux

```{r}
str(bird)
```

---
# Visualiser les donnÃ©es

Visualisons tout d'abord les donnÃ©es avec la fonction `boxplot()`

```{r, fig.height=5, fig.width=7,echo=-1}
par(mar = c(4, 4, 0.5, 1))
boxplot(logMaxAbund ~ Diet, data = bird,
  ylab = expression("log"[10]*"(Abondance maximale)"), xlab = 'RÃ©gime alimentaire')
```

---
# Visualiser les donnÃ©es

Nous pouvons changer l'ordre des niveaux afin qu'il suivent l'ordre croissant de leurs mÃ©dianes respectives en utilisant les fonctions `tapply()` et `sort()`

```{r, fig.height = 4.5, fig.width = 7, echo = -1}
par(mar = c(4, 4, .1, 1))
med <- sort(tapply(bird$logMaxAbund, bird$Diet, median))
boxplot(logMaxAbund ~ factor(Diet, levels = names(med)), data = bird,
        ylab = expression("log"[10]*"(Abondance maximale)"), xlab = 'RÃ©gime alimentaire')
```

---
# Visualiser les donnÃ©es


Une autre faÃ§on de visualiser graphiquement les tailles dâ€™effet est dâ€™utiliser la fonction `plot.design()`

.small[
```{r, fig.height=3.8, fig.width=6, echo=-1}
par(mar = c(4,4,.4,1))
plot.design(logMaxAbund ~ Diet, data = bird,
  ylab = expression("log"[10]*"(Abondance maximale)"))
```
]

.comment[Les niveaux d'un facteur le long d'une ligne verticale, et la valeur globale de la rÃ©ponse dans une ligne horizontale]

---
# ANOVA Ã  un critÃ¨re de classification dans R

Il est de nouveau possible d'utiliser la fonction `lm()`

```{r}
anov1 <- lm(logMaxAbund ~ Diet,
            data = bird)
```

Il y a aussi une fontion spÃ©cifique pour l'analyse de la variance dans R `aov()`

```{r}
aov1 <- aov(logMaxAbund ~ Diet,
            data = bird)
```

.comment[Essayez-les et comparez les sorties !]

---
# ExÃ©cuter une ANOVA

#### Ã€ un critÃ¨re de classification dans R

Comparer les sorties

```{r}
anova(anov1)
```
```{r}
summary(aov1)
```

---
# VÃ©rifier les conditions d'application

**Test de Bartlett**: Ã©galitÃ© de la variance entre les groupes

.small[
```{r}
bartlett.test(logMaxAbund ~ Diet, data = bird)
```
]
---
# VÃ©rifier les conditions d'application


**Test de Levene** pour l'homogÃ©nÃ©itÃ© de la variance:

.small[
```{r}
library(car)
leveneTest(logMaxAbund ~ Diet, data = bird)
```
]

.comment[Le test de Levene performe mieux, mais a une erreur de Type II un peu plus Ã©levÃ©e.]

---
#VÃ©rifier les conditions d'application

**Test de Shapiro-Wilk**:  normalitÃ© des rÃ©sidus

.small[
```{r}
shapiro.test(resid(anov1))
```
]

.comment[Les deux tests sont non-significatifs; les rÃ©sidus du modÃ¨le peuvent Ãªtre considÃ©rÃ©s normaux et les variances homogÃ¨nes]

---
# Et si les conditions d'application ne sont pas respectÃ©es...

**Transformer vos donnÃ©es** : pourrait Ã©galiser les variances et normaliser les rÃ©sidus, et peut convertir un effet multiplicatif en un effet additif

```{r eval=FALSE}
data$logY <- log10(data$Y)
```
* Voir le wiki de l'atelier 1 pour les rÃ¨gles de transformation de donnÃ©es
* rÃ©-exÃ©cuter votre modÃ¨le avec la variable transformÃ©e et vÃ©rifier Ã  nouveau les hypothÃ¨ses

**Test de Kruskal-Wallis**: Ã©quivalent non paramÃ©trique de l'ANOVA si vous ne pouvez pas
(*ou ne voulez pas*) transformer les donnÃ©es

```{r eval=FALSE}
kruskal.test(Y~X, data)
```

---
# Sorties de notre modÃ¨le ANOVA

Triage en ordre alphabÃ©tique des niveaux et comparaison au niveau de rÃ©fÃ©rence (`Insect`)

.xsmall[
```{r}
summary(anov1)
```
]

---
# Sorties de notre modÃ¨le ANOVA

D'autre part, si nous utilisons `lm()`

.pull-left2[
.small[
```{r}
summary.lm(aov1)
```
]]

.pull-right2[
<br><br>
.comment[DiffÃ©rence significative entre les groupes, mais nous ne savons pas lesquels !]]

---
# Test *a posteriori*

Lorsque l'ANOVA dÃ©tecte un effet significatif de la variable explicative, un test post-hoc avec la fonction `TukeyHSD()`, doit Ãªtre effectuÃ© pour dÃ©terminer quel(s) tratement(s) diffÃ¨re(nt)

.pull-left2[
.small[
```{r}
TukeyHSD(aov(anov1), ordered = TRUE)
```
]]

.pull-right2[
<br><br>
.comment[Seuls `Vertebrate` et `PlantInsect` diffÃ¨rent]
]

---
# ReprÃ©sentation graphique

ReprÃ©sentation graphique de l'ANOVA Ã  l'aide de la fonction `barplot()`

.xsmall[
```{r, fig.height=3, fig.width=7,echo=-1}
par(mar=c(3,3,0.5,0.5))
sd <- tapply(bird$logMaxAbund, bird$Diet, sd)
means <- tapply(bird$logMaxAbund, bird$Diet, mean)
n <- length(bird$logMaxAbund)
se <- 1.96*sd/sqrt(n)
bp <- barplot(means, ylim = c(0, max(bird$logMaxAbund) - 0.5))
epsilon = 0.1
segments(bp, means - se, bp, means + se, lwd=2) # barres verticales
segments(bp - epsilon, means - se, bp + epsilon, means - se, lwd = 2) # barres horizontales
segments(bp - epsilon, means + se, bp + epsilon, means + se, lwd = 2) # barres horizontales
```
]

---
class: inverse, center, middle

# ANOVA Ã  deux critÃ¨res de classification

---
# ANOVA Ã  deux critÃ¨res de classification

Plus d'un facteur

- ANOVA avec un facteur:

 `aov <- lm(Y ~ X, data)`

- ANOVA avec deux ou plus facteurs:

 `aov <- lm(Y ~ X * Z * ..., data)`

.comment[Lorsque vous utilisez le symbole "*" avec `lm()`, le modÃ¨le inclut les effets de chaque facteur sÃ©parÃ©ment, ainsi que leur interaction]
<br>
<br>
.comment[Lorsque vous utilisez le symbole "+" avec `lm()`, le modÃ¨le inclut les effets de
chaque facteur sÃ©parÃ©ment (pas d'interaction)]

`aov <- lm(Y ~ X + Z + ..., data)`

---
# ANOVA Ã  deux critÃ¨res de classification

.small[

Exemple d'interaction non significative

```r
aov <- lm(Y ~ X * Z, data)
summary(aov)
# Analysis of Variance Table
#
# Response: Y
# Df Sum Sq Mean Sq F value Pr(>F)
# X 4 5.1059 1.27647 3.0378 0.02669 *
# Z 1 0.3183 0.31834 0.7576 0.38870
# X:Z 3 2.8250 0.94167 2.2410 0.10689
# Residuals 45 18.9087 0.42019
# ---
# Signif. codes: 0 â€˜***â€™ 0.001 â€˜**â€™ 0.01 â€˜*â€™ 0.05 â€˜.â€™ 0.1 â€˜ â€™ 1
```

Selon le principe de **parcimonie**, vous voulez que votre modÃ¨le explique le plus possible de la variance observÃ©e dans les donnÃ©es, avec le moins de termes possible
- Enlever le terme d'interaction s'il n'est pas significatif, et rÃ©-exÃ©cuter le modÃ¨le

```r
aov <- lm(Y ~ X + Z, data)
```
]

---
exclude:true
# DÃ©fi 3 ![:cube]()

Testez si l'abondance maximale `log(MaxAbund)` varie Ã  la fois en fonction du rÃ©gime alimentaire (`Diet`) et de l'habitat (`Aquatic`).

.comment[INDICE: Examinez les facteurs Diet, Aquatic et leur interaction avec une ANOVA Ã  deux critÃ¨res de classification e.g. `lm(Y ~ A*B)`]

.comment[oÃ¹ A est le premier facteur, B le deuxiÃ¨me et "\*" dÃ©crit l'interaction]

---
# DÃ©fi 3 ![:cube]()

Testez si l'abondance maximale `log(MaxAbund)` varie Ã  la fois en fonction du rÃ©gime alimentaire (`Diet`) et de l'habitat (`Aquatic`).
<br>
<br>
.comment[INDICE: Assurez-vous d'ajouter une interaction avec `*`]
<br>
<br>
<br>
<br>
.large[
.center[
.alert[Salle de rÃ©union!]
]]

---
# ![:cube]()

.xsmall[
```{r}
anov2 <- lm(logMaxAbund ~ Diet*Aquatic, data = bird)
summary(anov2)
```
]

---
# DÃ©fi 3 - Solution ![:cube]()

.xsmall[
```{r}
anov2 <- lm(logMaxAbund ~ Diet*Aquatic, data = bird)
anova(anov2)
```
]

.comment[Le seul terme significatif du modÃ¨le est le facteur rÃ©gime alimentaire]

.comment[Selon le principe de parcimonie, nous devrions supprimer le terme d'interaction:]

```r
anov2 <- lm(logMaxAbund ~ Diet, data = bird)
```

---
# ModÃ¨les linÃ©aires

.center[
![:scale 100%](images/schema_ancova.png)
]

---
class: inverse, center, middle

# ANCOVA

---
# Analyse de covariance (ANCOVA)

- Combinaison de l'ANOVA et de la rÃ©gression linÃ©aire
- Les variables explicatives sont un mÃ©lange de variables quantitatives (covariable) et qualitatives (facteurs)

$$Y = \mu + \text{Effets principaux des facteurs} + \\
            \text{Interactions entre facteurs} + \\
            \text{Effets principaux des covariables} + \\
            \text{Interactions entre covariables et facteurs} + \epsilon$$

---
# Rappel : ANCOVA

En plus des conditions d'application des modÃ¨les linÃ©aires, les modÃ¨les **ANCOVA** doivent respecter :

- Les covariables ont toutes la **mÃªme Ã©tendue de valeurs**
- Les variables sont **fixes**
- Les variables catÃ©goriques et continues sont **indÃ©pendantes**

<br>

.small[
.comment[Un variable **fixe** est une variable d'intÃ©rÃªt pour une Ã©tude (e.g. la masse des oiseaux). En comparaison, une variable alÃ©atoire reprÃ©sente surtout une source de bruit qu'on veut contrÃ´ler (i.e. le site oÃ¹ les oiseaux ont Ã©tÃ© Ã©chantillonnÃ©s)]]

.small[.comment[*Voir l'atelier 6 sur les modÃ¨les linÃ©aires mixtes*]]

---
# Types d'ANCOVA

Vous pouvez avoir n'importe quel nombre de facteurs et / ou variables, mais lorsque leur nombre augmente, l'interprÃ©tation des rÃ©sultats devient de plus en plus complexe

<br>

ANCOVA frÃ©quemment utilisÃ©es

1. **Une covariable et un facteur**
2. Une covariable et deux facteurs
3. Deux covariables et un facteur

.small[.comment[Nous ne considÃ©rerons que le premier cas aujourd'hui, mais les deux autres sont similaires]]

---
# ANCOVA avec 1 covariable et 1 facteur

Objectifs de l'analyse :

1. DÃ©terminer l'effet du facteur et de la covariable sur â€‹â€‹la variable rÃ©ponse
2. DÃ©terminer l'effet du facteur sur la variable rÃ©ponse aprÃ¨s avoir enlevÃ© l'effet de la covariable
3. DÃ©terminer l'effet de la covariable sur la variable rÃ©ponse en contrÃ´lant l'effet du facteur

<br>

.center[.alert[Si vous avez une interaction significative entre votre facteur et votre covariable, vous ne pouvez pas atteindre ces objectifs !]]

---
# ANCOVA avec 1 covariable et 1 facteur

<br>

```{r,echo=FALSE,fig.height=3, fig.width=10}
## functions
f1 <- function(x, a, b) {
  return(x*a+b)
}
# conf for plot
col = rgb(118, 143, 175, maxColorValue = 255)
x <- 1:20
par(mfrow = c(1, 3), mar = c(1, 1, 6.5, 4))

# plot 1
plot(x, f1(x, a=1.1,b=2), ylim = c(0, 60), type = 'l', lwd = 2.5, xaxt = "n", yaxt = "n", xlab = "", ylab = "", bty='l', col = col)
lines(f1(x, a=1.1,b=17), lwd = 2.5, col = col)
lines(f1(x, a=0.6,b=22), lwd = 2.5, col = col)
lines(f1(x, a=1.1,b=40), lwd = 2.5, col = col)
mtext('Un niveau du facteur\n a une pente diffÃ©rente', side = 3, line = 2, cex = 1.5)
# plot 2
plot(x, f1(x, a=.5,b=2), ylim = c(0, 60), type = 'l', lwd = 2.5, xaxt = "n", yaxt = "n", xlab = "", ylab = "", bty='l', col = col)
lines(f1(x, a=1.1,b=17), lwd = 2.5, col = col)
lines(f1(x, a=1.1,b=22), lwd = 2.5, col = col)
lines(f1(x, a=0.01,b=40), lwd = 2.5, col = col)
mtext('Des nombreaux niveaux ont\n des pentes diffÃ©rentes', side = 3, line = 2, cex = 1.5)
# plot 3
plot(x, f1(x, a=1.1,b=2), ylim = c(0, 60), type = 'l', lwd = 2.5, xaxt = "n", yaxt = "n", xlab = "", ylab = "", bty='l', col = col)
lines(f1(x, a=1.1,b=17), lwd = 2.5, col = col)
lines(f1(x, a=1.1,b=22), lwd = 2.5, col = col)
lines(f1(x, a=1.1,b=40), lwd = 2.5, col = col)
mtext("Pas d'interaction", side = 3, line = 2, cex = 1.5)
```

.pull-left2[.center[.pull-left[![:faic](arrow-up)] .pull-right[![:faic](arrow-up)]]] .pull-right2[.center[![:faic](arrow-up)]]

.center[.pull-left2[.small[Si l'interaction est significative, vous aurez un scÃ©nario qui ressemble Ã  ceci]]]

.pull-right2[.small[Si votre covariable et votre facteur sont significatifs, vous avez un cas comme celui-ci]]

---
# Comparez ANCOVA - moyennes ajustÃ©es

Si vous voulez comparer les moyennes des diffÃ©rents facteurs, vous pouvez utiliser les
**moyennes ajustÃ©es**

La fonction `effect()` utilise les Ã©quations donnÃ©es par l'ANCOVA pour estimer les moyennes de chaque niveau, corrigÃ©es pour l'effet de la covariable

.small[
```{r eval=FALSE, warning=FALSE}
ancova.exemple <- lm(Y ~ X*Z, data=data) # X = quantitative; Z = qualitative
library(effects)
adj.means.ex <- effect('Z', ancova.exemple)
plot(adj.means.ex)
```
]

```{r,echo=FALSE, fig.height=3, fig.width=5}
# plot to simulate effects::effect() plot
a = 40; b =20; sd = 8
par(mar=c(4,4,.5,1))
plot(c(a, b), ylim = c(10, 50), xlim = c(0.9, 2.1), xlab = 'factor Z', ylab = 'Y', xaxt = 'n')
lines(c(a, b), col = 4, pch = 1.5)
segments(c(1, 2), c(a-sd, b-sd), c(1,2), c(a+sd, b+sd), lwd = 1.5, col = 'orange')
segments(c(1, 2) - .04, c(a, b) + sd, c(1, 2) + .04, c(a, b) + sd, lwd = 1.5, col = 'orange')
segments(c(1, 2) - .04, c(a, b) - sd, c(1, 2) + .04, c(a, b) - sd, lwd = 1.5, col = 'orange')
points(c(1, 2), c(a, b), pch = 16, col = 4)
axis(1, at = c(1, 2), labels = FALSE) # add ticks
mtext(c('Level 1', 'Level 2'), 1, at = 1:2, line = 0.5) # add labels to ticks
```

---
# ANCOVA avec 1 covariable et 1 facteur

- Si seulement votre facteur est significatif, Ã©liminer la covariable -> vous avez une **ANOVA**
- Si seulement votre covariable est significative, Ã©liminer le facteur -> vous avez une **rÃ©gression linÃ©aire simple**
- Si votre interaction covariable * facteur est significative, vous voudrez peut-Ãªtre tester quel(s) niveau(x) du facteur a(ont) des pentes diffÃ©rentes

.alert[VÃ©rifier vos conditions d'application ! ]

- TrÃ¨s similaire Ã  ce que vous avez fait prÃ©cÃ©demment

---
# ExÃ©cuter une ANCOVA dans R

##### L'abondance maximale varie-t-elle en fonction du rÃ©gime alimentaire et la masse des oiseaux ?

Variable rÃ©ponse : **MaxAbund** ![:faic](arrow-right) num : quantitative continue

Variable explicatives :
  - **Diet** ![:faic](arrow-right) facteur Ã  5 niveaux
  - **Mass** ![:faic](arrow-right) numÃ©rique continue

.small[
```{r}
str(bird)
```
]

---
exclude: true
# DÃ©fi 4 ![:cube]()

1- ExÃ©cutez un modÃ¨le pour tester les effets du rÃ©gime alimentaire (`Diet`), de la masse (`logMass`) ainsi que leur interaction sur l'abondance maximale des oiseaux (`logMaxAbund`)

```{r eval=FALSE}
ancova.exemple <- lm(Y~X*Z, data=data)
summary(ancova.exemple)
```

2- VÃ©rifiez si votre interaction est significative

```{r eval=FALSE}
ancova.exemple2 <- lm(Y~X+Z, data=data)
summary(ancova.exemple2)
```
---

# DÃ©fi 4 ![:cube]()

1- ExÃ©cutez un modÃ¨le pour tester les effets du rÃ©gime alimentaire (`Diet`), de la masse (`logMass`) ainsi que leur interaction sur l'abondance maximale des oiseaux (`logMaxAbund`)

<br>

2- VÃ©rifiez si votre interaction est significative
<br>
<br>
<br>
<br>

.large[
.center[
.alert[Salle de rÃ©union!]
]]
---
# DÃ©fi 4 - Solution ![:cube]()

<br>

```{r}
ancov1 <- lm(logMaxAbund ~ logMass*Diet,
             data = bird)
anova(ancov1)
```

Interaction entre `logMass` et `Diet` n'est pas significative

---
# DÃ©fi 4 - Solution ![:cube]()

Ã‰liminer le terme d'interaction, puis rÃ©-Ã©valuer le modÃ¨le contenant les effets simples de `logMass` et `Diet`

```{r}
ancov2 <- lm(logMaxAbund ~ logMass + Diet,
             data = bird)
anova(ancov2)
```

---

# ModÃ¨les linÃ©aires

.center[
![:scale 100%](images/schema_multReg.png)
]

---

class: inverse, center, middle

# RÃ©gression linÃ©aire multiple

---

# RÃ©gression linÃ©aire multiple
- **Variables explicatives** ![:faic](arrow-right) 2 ou plusieurs variables continues
- **Variable rÃ©ponse** ![:faic](arrow-right) 1 variable continue

.xsmall[Seule diffÃ©rence avec la rÃ©gression linÃ©aire simple : **plusieurs variables explicatives** sont incluses dans le modÃ¨le.] 

#### Variables

- $y$ : Variable rÃ©ponse (**continue**)
- $x$ : Plusieurs variables explicatives (**continues** ou **catÃ©goriques**)

#### Relation supposÃ©e

$$y_i = \beta_0 + \beta_1x_{1,i}+\beta_2x_{2,i}+\beta_3x_{3,i}+...+\beta_kx_{k,i} + \epsilon_i$$

- Le paramÃ¨tre $\beta_0$ est **l'ordonnÃ©e Ã  l'origine** (ou constante)
- Les paramÃ¨tre $\beta_1$ quantifie **l'effet** de $x$ sur $y$.
- Le rÃ©sidu $\epsilon_i$ reprÃ©sent la variation **non expliquÃ©e**
- La **valeur prÃ©dite** de $y_i$ se dÃ©finit comme : $\hat{y}_i = \beta_0 + \beta_1x_{1,i}+\beta_2x_{2,i}+\beta_3x_{3,i}+...+\beta_kx_{k,i}$.

---

# RÃ©gression linÃ©aire multiple


$$y_i = \beta_0 + \beta_1x_{1,i}+\beta_2x_{2,i}+\beta_3x_{3,i}+...+\beta_kx_{k,i} + \epsilon_i$$

$$\epsilon_i \sim \mathcal{N}(0,\,\sigma^2)$$


#### Conditions d'application

En plus des conditions d'application habituelles des modÃ¨les linÃ©aires :
- **Relation linÃ©aire** entre **chaque** variable explicative et la variable rÃ©ponse.
- Les variables explicatives sont indÃ©pendantes les unes des autres (il n'y a pas de **colinÃ©aritÃ©**).

---

# RÃ©gression linÃ©aire multiple


$$y_i = \beta_0 + \beta_1x_{1,i}+\beta_2x_{2,i}+\beta_3x_{3,i}+...+\beta_kx_{k,i} + \epsilon_i$$

$$\epsilon_i \sim \mathcal{N}(0,\,\sigma^2)$$



#### En cas de colinÃ©aritÃ©

- Garder seulement une des variables colinÃ©aires
- Essayer une analyse multidimensionnelle (voir l'atelier 9)
- Essayer une analyse pseudo-orthogonale

---


#  RÃ©gression linÃ©aire multiple dans R

En utilisant le jeu de donnÃ©es `Dickcissel` comparez l'importance relative du climat (`clTma`), de la productivitÃ© (`NDVI`) et de la couverture du sol (`grass`) comme prÃ©dicteurs de l'abondance de dickcissels (`abund`)

.small[
```{r, eval=TRUE}
Dickcissel = read.csv("data/dickcissel.csv")
str(Dickcissel)
```
]

---
# VÃ©rifier les conditions d'application

La colinÃ©aritÃ© :
- VÃ©rifier la colinÃ©aritÃ© de toutes les variables explicatives et d'intÃ©rÃªt

.small[
.pull-left[
```{r, fig.height=6, fig.width=7}
# select variables
var <- c('clTma', 'NDVI', 'grass', 'abund')
plot(Dickcissel[, var])
```
]]

.pull-right[
<br>
.small[.comment[
Si vous observez un patron entre vos deux variables explicatives, elles peuvent Ãªtre colinÃ©aires!

Vous devez Ã©viter ceci, sinon leurs effets sur la variable rÃ©ponse seront confondus
]]]

---
# RÃ©gression linÃ©aire multiple dans R

ExÃ©cuter la rÃ©gression multiple de l'abondance (`abund`) en fonction des variables `clTma + NDVI + grass`

```{r,eval=FALSE}
lm.mult <- lm(abund ~ clTma + NDVI + grass, data = Dickcissel)
summary(lm.mult)
```

VÃ©rifiez les autres conditions d'application, comme pour la rÃ©gression linÃ©aire simple

```{r,eval=FALSE,echo=-2}
par(mfrow = c(2, 2))
par(mfrow=c(2,2), mar = c(3.9,4,1.2,1.1), oma =c(0,0,0,0))
plot(lm.mult)
```

---
# RÃ©gression linÃ©aire multiple dans R

ExÃ©cuter la rÃ©gression multiple de l'abondance (`abund`) en fonction des variables `clTma + NDVI + grass`

.small[
```{r}
lm.mult <- lm(abund ~ clTma + NDVI + grass, data = Dickcissel)
summary(lm.mult)
```
]

---
# RÃ©gression linÃ©aire multiple dans R

VÃ©rifiez les autres conditions d'application, comme pour la rÃ©gression linÃ©aire simple

```{r, fig.height=5.5, fig.width=8,echo=-2}
par(mfrow = c(2, 2))
par(mfrow=c(2,2), mar = c(3.9,4,1.2,1.1), oma =c(0,0,0,0))
plot(lm.mult)
```

---

# Quel est le meilleur modÃ¨le ?

.small[
Souvenez-vous du principe de parcimonie: expliquer le plus de variation avec le plus petit nombre de termes dans votre modÃ¨le ![:faic](arrow-right) enlevez la variable qui est la moins significative
]


```{r}
summary(lm.mult)$coefficients
```

<br>

Les 3 variables sont importantes. On garde tout !

Le modÃ¨le explique 11.28% de la variabilitÃ© de l'abondance de dickcissels $RÂ²_{adj} = 0.11$.

--

.alert[Toutefois, ces informations ne sont pas valables car les conditions d'application du modÃ¨le linÃ©aire ne sont pas respectÃ©es.]


---
# Quel est le meilleur modÃ¨le ?

Il est important de noter que la variable rÃ©ponse ne varie pas de faÃ§on linÃ©aire avec les variables explicatives

```{r, fig.height=3.5, fig.width=11,echo=-1}
par(mfrow=c(1,3), mar=c(4, 4, 0.5, 0.5), cex = 1)
plot(abund ~ clTma, data = Dickcissel)
plot(abund ~ NDVI,  data = Dickcissel)
plot(abund ~ grass, data = Dickcissel)
```

.comment[Voir la **section avancÃ©e** sur la **rÃ©gression polynomiale** pour la solution !]

---
class: inverse, center, middle

# Optionnel

## *si le temps le permet*

---
# Optionnel

1. InterprÃ©tation des contrastes
2. ANOVA non Ã©quilibrÃ©e
3. RÃ©gression polynomiale
4. Partitionnement de la variation

---
exclude:true

class: inverse, center, middle

# RÃ©gression pas Ã  pas

---
exclude:true

# RÃ©gression pas Ã  pas

ExÃ©cuter un modÃ¨le avec tout dedans sauf les variables de "PrÃ©sent/absence"

La fonction `step()` soustrait un terme au modÃ¨le de faÃ§on itÃ©rative et sÃ©lectionne le meilleur modÃ¨le
  - c-Ã .d. le modÃ¨le avec le CritÃ¨re d'Information Akaike (AIC) le plus bas

.small[
```{r,eval=FALSE}
lm.full <- lm(abund ~ . - Present,
              data = Dickcissel)
lm.step <- step(lm.full)
```
]
```{r,include=FALSE}
lm.full <- lm(abund ~ . - Present,
              data = Dickcissel)
lm.step <- step(lm.full)
```

---
exclude:true

# RÃ©gression pas Ã  pas

.pull-left[
.tiny[
```{r eval=TRUE}
summary(lm.full)
```
]]

.pull-right[

Variables sÃ©lectionÃ©es par `step()`
.tiny[
```{r}
summary(lm.step)
```
]]

.small[.comment[Le modÃ¨le explique maintenant 31,44% de la variabilitÃ© de l'abondance de Dickcissel]]

---
class: inverse, center, middle

# InterprÃ©tation des contrastes

---
# InterprÃ©tation des contrastes

.small[
Les constrastes servent Ã  comparer chaque niveau du facteur Ã  un niveau de rÃ©fÃ©rence, et de dÃ©tecter des diffÃ©rences significatives entre chaque niveau.

L'estimation de l'ordonnÃ©e Ã  l'origine est le niveau de rÃ©fÃ©rence et correspond Ã  la moyenne du premier niveau (en ordre alphabÃ©tique) du facteur `Diet`

Calculez l'ordonnÃ©e Ã  l'origine de rÃ©fÃ©rence + l'ordonnÃ©e Ã  l'origine de chaque niveau de Diet .comment[*Que remarquez-vous ?*]

```{r}
tapply(bird$logMaxAbund, bird$Diet, mean)
coef(anov1)
coef(anov1)[1] + coef(anov1)[2] # InsectVert
coef(anov1)[1] + coef(anov1)[3] # Plant
```
]

---
# InterprÃ©tation des contrastes

Il se peut que vous vouliez dÃ©finir un niveau de rÃ©fÃ©rence diffÃ©rent

1. Comparez le niveau `Plant` Ã  tous les autres niveaux du facteur `Diet`

```{r,eval=FALSE}
bird$Diet2 <- relevel(bird$Diet, ref="Plant")
anov2 <- lm(logMaxAbund ~ Diet2, data = bird)
summary(anov2)
anova(anov2)
```

2. Ordonner les niveaux selon leur mÃ©diane

```{r,eval=FALSE}
bird$Diet2 <- factor(bird$Diet, levels=names(med))
anov2 <- lm(logMaxAbund ~ Diet2,
            data = bird)
summary(anov2)
anova(anov2)
```

.comment[Observez-vous un changement quant aux niveaux du facteur `Diet` qui sont significatifs ?]

---
# InterprÃ©tation des contrastes

.comment[Un point important Ã  remarquer Ã  propos du contraste par dÃ©faut dans R (`contr.treatment`) est qu'il n'est PAS orthogonal]

Pour Ãªtre orthogonal :
  - Pour Ãªtre orthogonal, les propriÃ©tÃ©s suivantes doivent Ãªtre respectÃ©es:
  - La somme du produit de deux colonnes Ã©gale 0

```{r}
sum(contrasts(bird$Diet)[,1])
sum(contrasts(bird$Diet)[,1]*contrasts(bird$Diet)[,2])
```

???

Note aux prÃ©sentateurs:Deux contrastes sont orthogonaux si la somme des produits de leurs coefficients est nulle. 

---
# InterprÃ©tation des contrastes

Changez les contrastes pour mettre les niveaux orthogonaux

.small[
```{r}
options(contrasts=c("contr.helmert", "contr.poly"))
sum(contrasts(bird$Diet)[,1])
sum(contrasts(bird$Diet)[,1]*contrasts(bird$Diet)[,2])
```
]
.pull-left[
.tiny[
```{r}
anov3 <- lm(logMaxAbund ~ Diet, data = bird)
summary(anov3)
```
]]
.pull-right[
.small[Les contrastes Helmert vont contraster le deuxiÃ¨me niveau avec le premier, le troisiÃ¨me avec la moyenne des deux premiers niveaux, etc.]
]

---
class: inverse, center, middle

# ANOVA non Ã©quilibrÃ©e

---
# ANOVA non Ã©quilibrÃ©e

Un jeu de donnÃ©es est considÃ©rÃ© non Ã©quilibrÃ© lorsque le nombre d'Ã©chantillons entre deux niveaux n'est pas Ã©gal.

Le jeu de donnÃ©es `Birdsdiet` est en rÃ©alitÃ© non Ã©quilibrÃ© (le nombre d'espÃ¨ces aquatiques n'Ã©gale pas le nombre d'espÃ¨ces non-aquatiques)

```{r}
table(bird$Aquatic)
```

Dans une telle situation, l'ordre des covariable affecte la calculation de la somme des carrÃ©s, et donc la valeur de `p`. 

Testons-le avec le jeu de donnÃ©es `Birdsdet`.

```{r}
unb.anov1 <- lm(logMaxAbund ~ Aquatic + Diet, data = bird)
unb.anov2 <- lm(logMaxAbund ~ Diet + Aquatic, data = bird)
```

---
# ANOVA non Ã©quilibrÃ©e

```{r}
anova(unb.anov1)
```

```{r}
anova(unb.anov2)
```

---
# ANOVA non Ã©quilibrÃ©e

Afin de rÃ¨gler ce problÃ¨me est de prendre une nouvelle approche pour tester les effets de chaque variable.

**Type I** : Teste les effets en sÃ©quentiel, en dÃ©butant avec la premiÃ¨re variable.

**Type II**: Teste les effets de chaque facteur, mais aprÃ¨s avoir tester l'autre facteur.

**Type III**: Teste les effets de chaque facteur, mais aprÃ¨s avoir tester l'autre facteur et l'intÃ©raction.

.comment[Le type I est celui par dÃ©fault dans R et qui crÃ©e le problÃ¨me avec des donnÃ©es non Ã©quilibrÃ©]

.alert[Si vous considÃ©rez utiliser le Type II ou III avec vos propres donnÃ©es, vous devriez en lire plus sur le sujet avant de choisir. Vous pouvez commencer avec ce] [**lien**](https://mcfromnz.wordpress.com/2011/03/02/anova-type-iiiiii-ss-explained/)

---

# ANOVA non Ã©quilibrÃ©e

Maintenant essayez une `Anova()` de type III

.pull-left[
.small[
```{r}
car::Anova(unb.anov1, type = "III")
```
]]
.pull-right[
.small[
```{r}
car::Anova(unb.anov2, type = "III")
```
]]

.comment[Que remarquez-vous en utilisant `Anova()` ?]

---
class: inverse, center, middle

# RÃ©gression polynomiale

---
# RÃ©gression polynomiale

Comme nous l'avons remarquÃ© dans la section sur la **rÃ©gression linÃ©aire multiple**, certaines variables semblent avoir des relations non-linÃ©aires avec la variable `MaxAbund`

Pour tester des relations non-linÃ©aires, des rÃ©gressions polynomiales de diffÃ©rents degrÃ©s sont comparÃ©es

- Un modÃ¨le polynÃ´mial ressemble Ã  ceci :

.center[$$\underbrace{2x^4}+\underbrace{3x}-\underbrace{2}$$]

.comment[Ce polynÃ´me a trois termes]

---
# RÃ©gression polynomiale

Pour un polynÃ´me avec une variable (comme $x$ ), le *degrÃ©* est l'exposant le plus Ã©levÃ© de cette variable

<br>
.center[*Nous avons ici un polynÃ´me de degrÃ© 4*]
$$2x^\overbrace{4} + 3x - 2$$

---
# RÃ©gression polynomiale

Lorsque vous connaissez le degrÃ©, vous pouvez lui donner un nom :

```{r echo=FALSE, warning=FALSE}

poly.reg=data.frame(degre = 0:5,
                    Nom = c("Constante","LinÃ©aire","Quadratique",
                             "Cubique","Quartique","Quintique"),
                    Example = c("\\(3\\)",
                                "\\(x+9\\)",
                                "\\(x^2-x+4\\)",
                                "\\(x^3-x^2+5\\)",
                                "\\(6x^4-x^3+x-2\\)",
                                "\\(x^5-3x^3+x^2+8\\)"))
knitr::kable(poly.reg, format = "html", escape=FALSE)
```

---
# RÃ©gression polynomiale

En utilisant le jeu de donnÃ©es `Dickcissel`, testez la relation non-linÃ©aire entre l'abondance et la tempÃ©rature en comparant trois modÃ¨les polynÃ´miaux groupÃ©s (de degrÃ©s 0, 1, and 3) :

```{r,echo=-c(4:6)}
lm.linear <- lm(abund ~ clDD, data = Dickcissel)
lm.quad   <- lm(abund ~ clDD + I(clDD^2), data = Dickcissel)
lm.cubic  <- lm(abund ~ clDD + I(clDD^2) + I(clDD^3), data = Dickcissel)
summ_lm.linear <- capture.output(summary(lm.linear))[c(9:12, 17, 18)]
summ_lm.quad <- capture.output(summary(lm.quad))[c(9:13, 18, 19)]
summ_lm.cubic <- capture.output(summary(lm.cubic))[c(9:14, 17, 18)]
```

---
# RÃ©gression polynomiale

- Comparez les modÃ¨les polynomiaux et dÃ©terminez quel modÃ¨le nichÃ© nous devrions sÃ©lectionner
- ExÃ©cutez un rÃ©sumÃ© de ce modÃ¨le, reportez l'Ã©quation de la rÃ©gression, les valeurs de p, et le R carrÃ© ajustÃ©

---
# RÃ©gression polynomiale

Comparez les modÃ¨les polynÃ´miaux; .comment[quel modÃ¨le nichÃ© nous devrions sÃ©lectionner ?]

ExÃ©cutez un rÃ©sumÃ© de ce modÃ¨le

.tiny[
```{r}
print(summ_lm.linear)
```
```{r}
print(summ_lm.quad)
```
```{r}
print(summ_lm.cubic)
```
]

---
class: inverse, center, middle

# Partitionnement de la variation

---
# Partitionnement de la variation

Certaines variables explicatives de la **rÃ©gression linÃ©aire multiple** Ã©taient fortement corrÃ©lÃ©es (c.-Ã -d.
multicolinÃ©aritÃ©)

La colinÃ©aritÃ© entre variables explicatives peut Ãªtre dÃ©tectÃ©e Ã  l'aide de critÃ¨res d'inflation de la variance (fonction `vif()` du packet `car`)
  - Les valeurs supÃ©rieures Ã  5 sont considÃ©rÃ©es colinÃ©aires

```{r warning=FALSE,message=FALSE}
mod <- lm(clDD ~ clFD + clTmi + clTma + clP + grass, data = Dickcissel)
car::vif(mod)
```

---
# Partitionnement de la variation
.small[
Utilisez `varpart()` afin de partitionner la variation de la variable `abund` avec toutes les variables de la couverture du paysage groupÃ©es ensemble et toutes les variables du climat groupÃ©es ensemble (laissez NDVI Ã  part)]

.pull-left2[
.tiny[
```{r warning=FALSE,message=FALSE}
library(vegan)
part.lm = varpart(Dickcissel$abund, Dickcissel[ ,c("clDD","clFD","clTmi","clTma","clP")],
                  Dickcissel[ ,c("broadleaf","conif","grass","crop", "urban","wetland")])
part.lm
```
]]
.pull-right2[
<br><br>
.small[.comment[**Note** : les variables colinÃ©aires n'ont pas besoin d'Ãªtre enlevÃ©es avant l'analyse]]
]

---
# Partitionnement de la variation

.pull-left[
.small[
```{r,fig.height=3.2,echo=-1}
par(mar=rep(0.5,4))
showvarparts(2)
```

```{r,eval=FALSE}
?showvarparts
# With two explanatory tables, the fractions
# explained uniquely by each of the two tables
# are â€˜[a]â€™ and â€˜[c]â€™, and their joint effect
# is â€˜[b]â€™ following Borcard et al. (1992).
```
]]

.pull-right[
.small[
```{r,fig.height=4,echo=-1}
par(mar=rep(0.5,4))
plot(part.lm,
     digits = 2,
     bg = rgb(48,225,210,80,
              maxColorValue=225),
     col = "turquoise4")
```
]]

.small[.comment[La proportion de la variation de la variable abund expliquÃ©e par le climat seulement est 28.5% (obtenu par X1|X2), par la couverture du paysage seulement est ~0% (X2|X1), et par les deux combinÃ©s est 2.4%]]

---
# Partitionnement de la variation

Tester si chaque fraction est significative

- Climat seul
```{r,eval=FALSE}
out.1 = rda(Dickcissel$abund,
            Dickcissel[ ,c("clDD", "clFD","clTmi","clTma","clP")],
            Dickcissel[ ,c("broadleaf","conif","grass","crop", "urban","wetland")])
```

- Couverture du paysage seul
```{r,eval=FALSE}
out.2 = rda(Dickcissel$abund,
            Dickcissel[ ,c("broadleaf","conif","grass","crop", "urban", "wetland")],
            Dickcissel[ ,c("clDD","clFD","clTmi", "clTma","clP")])

```

```{r,include=FALSE}
out.1 = rda(Dickcissel$abund,
            Dickcissel[ ,c("clDD", "clFD","clTmi","clTma","clP")],
            Dickcissel[ ,c("broadleaf","conif","grass","crop", "urban","wetland")])
out.2 = rda(Dickcissel$abund,
            Dickcissel[ ,c("broadleaf","conif","grass","crop", "urban", "wetland")],
            Dickcissel[ ,c("clDD","clFD","clTmi", "clTma","clP")])
```

---
# Partitionnement de la variation

.pull-left[
.small[
```{r}
# Climat seul
anova(out.1, step = 1000, perm.max = 1000)
```
]]

.pull-right[
.small[
```{r}
# Couverture du paysage seul
anova(out.2, step = 1000, perm.max = 1000)
```
]]

.comment[Conclusion: la fraction expliquÃ©e par la couverture du paysage n'est pas significative une fois que nous avons pris en compte l'effet du climat]

---
class: inverse, center, bottom

# Merci d'avoir participÃ© !

![:scale 50%](images/qcbs_logo.png)
